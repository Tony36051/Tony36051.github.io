<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CleanCode代码整洁之道(读书笔记)</title>
    <url>/2018/09/03/CleanCode%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93(%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0)/</url>
    <content><![CDATA[<p>衡量代码的唯一有效标准：WTF/min<br>陪女票复习, 带上Bob大叔的代码整洁之道, 一天看了120+页, 真是舒爽. </p>
<span id="more"></span>

<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="抽象层次"><a href="#抽象层次" class="headerlink" title="抽象层次"></a>抽象层次</h3><ol>
<li>函数内步骤在同一抽象层上.</li>
<li>Top-Down写法: 如写文章先写大纲(高抽象层次), 下个函数再写细节(低抽象层次)</li>
</ol>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><ol>
<li>参数越少越好</li>
<li>不要用标识参数(boolean flag): 根据flag取值, 分别做两件事, 违反”一个函数做一件事”. 应拆分为两个函数.</li>
<li>参数名可含参数的顺序, 减少记忆负担. 如 findByNameAndScore(name, score)</li>
</ol>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 笔记</title>
    <url>/2018/07/13/Git%20%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Git初始化动作，别名配置，待添加cheat sheet</p>
<span id="more"></span>

<h1 id="Git-笔记"><a href="#Git-笔记" class="headerlink" title="Git 笔记"></a>Git 笔记</h1><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config --global http.sslverify <span class="literal">false</span></span><br><span class="line">git config --global user.email <span class="string">&quot;tony36051@github.com&quot;</span></span><br><span class="line">git config --global user.name <span class="string">&quot;Tony36051&quot;</span></span><br><span class="line"></span><br><span class="line">git config --global http.proxy http://username:password@proxyhk.huawei.com:8080</span><br><span class="line">git config --global https.proxy http://username:password@proxyhk.huawei.com:8080</span><br><span class="line">git config --global --<span class="built_in">unset</span> http.proxy</span><br><span class="line">git config --global --<span class="built_in">unset</span> https.proxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># window显示中文</span></span><br><span class="line">git config --global core.quotepath <span class="literal">false</span></span><br></pre></td></tr></table></figure>


<h2 id="别名-快捷命令"><a href="#别名-快捷命令" class="headerlink" title="别名 快捷命令"></a>别名 快捷命令</h2><p>配置别名减少记忆，减少敲错。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config --global alias.st status</span><br><span class="line">git config --global alias.co checkout</span><br><span class="line">git config --global alias.ci commit</span><br><span class="line">git config --global alias.br branch</span><br><span class="line">git config --global alias.lg <span class="string">&quot;log --color --graph --pretty=format:&#x27;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#x27; --abbrev-commit&quot;</span></span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>Git</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>T1刷机Armbian经验</title>
    <url>/2021/03/02/T1%E5%88%B7%E6%9C%BAArmbian%E7%BB%8F%E9%AA%8C/</url>
    <content><![CDATA[<p>T1同时保留安卓和Armbian两个系统。</p>
<span id="more"></span>

<h1 id="刷机"><a href="#刷机" class="headerlink" title="刷机"></a>刷机</h1><h2 id="刷安卓"><a href="#刷安卓" class="headerlink" title="刷安卓"></a>刷安卓</h2><p>开晨星的刷机工具（USB_Burning_Tool），加载固件，USB双公头，root后在安卓的<code>终端模拟器</code>中用reboot update命令重启。<br>检测到机器后，开刷，等待完成就可以拔线进入安卓系统。</p>
<h2 id="刷Armbian"><a href="#刷Armbian" class="headerlink" title="刷Armbian"></a>刷Armbian</h2><p>使用老的内核镜像3.14，配套<code>gxm_q201_2g.dtb</code>，用<code>usb_image_tool</code>刷到的U盘后，修改BOOT盘，将<code>gxm_q201_2g.dtb</code>移动到BOOT的根目录改名为<code>dtb.img</code>。<br>我用的镜像名是<code>Armbian_5.44_S9xxx_Ubuntu_xenial_3.14.29_server</code><br>插入U盘，重启盒子，进入Armbian。默认账号root，默认密码是1234.<br>修改密码后，Ctrl+C跳过创建用户。<br>同时保留两个系统的关键是进入Armbian后，修改/root/install.sh文件为以下内容，内容转自恩山论坛大佬achaoge。<br>这里文件适用于首次安装Armbian，非首次安装请查看恩山上他的原贴。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Start copy system for DATA partition.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p /ddbr</span><br><span class="line"><span class="built_in">chmod</span> 777 /ddbr</span><br><span class="line"></span><br><span class="line">VER=`<span class="built_in">uname</span> -r`</span><br><span class="line"></span><br><span class="line">IMAGE_KERNEL=<span class="string">&quot;/boot/zImage&quot;</span></span><br><span class="line">IMAGE_INITRD=<span class="string">&quot;/boot/initrd.img-<span class="variable">$VER</span>&quot;</span></span><br><span class="line">PART_ROOT=<span class="string">&quot;/dev/data&quot;</span></span><br><span class="line">DIR_INSTALL=<span class="string">&quot;/ddbr/install&quot;</span></span><br><span class="line">IMAGE_DTB=<span class="string">&quot;/boot/dtb.img&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -f <span class="variable">$IMAGE_KERNEL</span> ] ; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Not KERNEL.  STOP install !!!&quot;</span></span><br><span class="line">    <span class="built_in">return</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -f <span class="variable">$IMAGE_INITRD</span> ] ; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Not INITRD.  STOP install !!!&quot;</span></span><br><span class="line">    <span class="built_in">return</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#edit by achaoge,</span></span><br><span class="line"><span class="comment">#disable 64bit and metadata_csum features for uboot compatibility</span></span><br><span class="line"><span class="comment">#ref: https://kshadeslayer.wordpress.com/2016/04/11/my-filesystem-has-too-many-bits/</span></span><br><span class="line">/sbin/resize2fs -s <span class="variable">$PART_ROOT</span></span><br><span class="line">/sbin/tune2fs -O ^metadata_csum <span class="variable">$PART_ROOT</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#echo &quot;Formatting DATA partition...&quot;</span></span><br><span class="line"><span class="comment">#umount -f $PART_ROOT</span></span><br><span class="line"><span class="comment">#mke2fs -F -q -t ext4 -m 0 $PART_ROOT</span></span><br><span class="line">e2fsck -f <span class="variable">$PART_ROOT</span></span><br><span class="line"><span class="comment">#echo &quot;done.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copying ROOTFS.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -d <span class="variable">$DIR_INSTALL</span> ] ; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">rm</span> -rf <span class="variable">$DIR_INSTALL</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$DIR_INSTALL</span></span><br><span class="line">mount -o rw <span class="variable">$PART_ROOT</span> <span class="variable">$DIR_INSTALL</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy BIN&quot;</span></span><br><span class="line">tar -cf - bin | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy BOOT&quot;</span></span><br><span class="line"><span class="comment">#mkdir -p $DIR_INSTALL/boot</span></span><br><span class="line">tar -cf - boot | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Create DEV&quot;</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$DIR_INSTALL</span>/dev</span><br><span class="line"><span class="comment">#tar -cf - dev | (cd $DIR_INSTALL; tar -xpf -)</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy ETC&quot;</span></span><br><span class="line">tar -cf - etc | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy HOME&quot;</span></span><br><span class="line">tar -cf - home | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy LIB&quot;</span></span><br><span class="line">tar -cf - lib | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Create MEDIA&quot;</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$DIR_INSTALL</span>/media</span><br><span class="line"><span class="comment">#tar -cf - media | (cd $DIR_INSTALL; tar -xpf -)</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Create MNT&quot;</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$DIR_INSTALL</span>/mnt</span><br><span class="line"><span class="comment">#tar -cf - mnt | (cd $DIR_INSTALL; tar -xpf -)</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy OPT&quot;</span></span><br><span class="line">tar -cf - opt | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Create PROC&quot;</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$DIR_INSTALL</span>/proc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy ROOT&quot;</span></span><br><span class="line">tar -cf - root | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Create RUN&quot;</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$DIR_INSTALL</span>/run</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy SBIN&quot;</span></span><br><span class="line">tar -cf - sbin | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy SELINUX&quot;</span></span><br><span class="line">tar -cf - selinux | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy SRV&quot;</span></span><br><span class="line">tar -cf - srv | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Create SYS&quot;</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$DIR_INSTALL</span>/sys</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Create TMP&quot;</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$DIR_INSTALL</span>/tmp</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy USR&quot;</span></span><br><span class="line">tar -cf - usr | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy VAR&quot;</span></span><br><span class="line">tar -cf - var | (<span class="built_in">cd</span> <span class="variable">$DIR_INSTALL</span>; tar -xpf -)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Copy fstab&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> <span class="variable">$DIR_INSTALL</span>/etc/fstab</span><br><span class="line"><span class="built_in">cp</span> -a /root/fstab <span class="variable">$DIR_INSTALL</span>/etc</span><br><span class="line"><span class="comment">#cp -a /boot/hdmi.sh $DIR_INSTALL/boot</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#add by achaoge 2018-06-22</span></span><br><span class="line"><span class="built_in">export</span> $(/usr/sbin/fw_printenv mac)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Modify files for N1 emmc boot&quot;</span></span><br><span class="line">/bin/sed -e <span class="string">&quot;/usb [23]/d&quot;</span> -e <span class="string">&#x27;s/fatload mmc 0 \([^ ]*\) \([^;]*\)/ext4load mmc 1:c \1 \/boot\/\2/g&#x27;</span> -i <span class="variable">$DIR_INSTALL</span>/boot/s905_autoscript.cmd</span><br><span class="line">/bin/sed -e <span class="string">&#x27;s/LABEL=ROOTFS/\/dev\/data/&#x27;</span> -e <span class="string">&quot;s/mac=.*/mac=<span class="variable">$&#123;mac&#125;</span>/&quot;</span> -i <span class="variable">$DIR_INSTALL</span>/boot/uEnv.ini</span><br><span class="line">/usr/bin/mkimage -C none -A arm -T script -d <span class="variable">$DIR_INSTALL</span>/boot/s905_autoscript.cmd <span class="variable">$DIR_INSTALL</span>/boot/s905_autoscript</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Emmc boot fixed end&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> <span class="variable">$DIR_INSTALL</span>/root/install.sh</span><br><span class="line"><span class="built_in">rm</span> <span class="variable">$DIR_INSTALL</span>/root/fstab</span><br><span class="line"><span class="built_in">rm</span> <span class="variable">$DIR_INSTALL</span>/usr/bin/ddbr</span><br><span class="line"><span class="built_in">rm</span> <span class="variable">$DIR_INSTALL</span>/usr/bin/ddbr_backup_nand</span><br><span class="line"><span class="built_in">rm</span> <span class="variable">$DIR_INSTALL</span>/usr/bin/ddbr_restore_nand</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /</span><br><span class="line"><span class="built_in">sync</span></span><br><span class="line"></span><br><span class="line">umount <span class="variable">$DIR_INSTALL</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;*******************************************&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Done copy ROOTFS&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;*******************************************&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#echo &quot;Writing new kernel image...&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#mkdir -p $DIR_INSTALL/aboot</span></span><br><span class="line"><span class="comment">#cd $DIR_INSTALL/aboot</span></span><br><span class="line"><span class="comment">#dd if=/dev/boot of=boot.backup.img</span></span><br><span class="line"><span class="comment">#abootimg -i /dev/boot &gt; aboot.txt</span></span><br><span class="line"><span class="comment">#abootimg -x /dev/boot</span></span><br><span class="line"><span class="comment">#abootimg -u /dev/boot -k $IMAGE_KERNEL</span></span><br><span class="line"><span class="comment">#abootimg -u /dev/boot -r $IMAGE_INITRD</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#echo &quot;done.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#if [ -f $IMAGE_DTB ] ; then</span></span><br><span class="line"><span class="comment">#    abootimg -u /dev/boot -s $IMAGE_DTB</span></span><br><span class="line"><span class="comment">#    echo &quot;Writing new dtb ...&quot;</span></span><br><span class="line"><span class="comment">#    dd if=&quot;$IMAGE_DTB&quot; of=&quot;/dev/dtb&quot; bs=262144 status=none &amp;&amp; sync</span></span><br><span class="line"><span class="comment">#    echo &quot;done.&quot;</span></span><br><span class="line"><span class="comment">#fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Write env bootargs&quot;</span></span><br><span class="line"><span class="comment">#/usr/sbin/fw_setenv initargs &quot;root=/dev/data rootflags=data=writeback rw console=ttyS0,115200n8 console=tty0 no_console_suspend consoleblank=0 fsck.repair=yes net.ifnames=0 mac=\$&#123;mac&#125;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Edit by achaoge 2018-06-22, for Phicomm N1 boot from emmc</span></span><br><span class="line">/usr/sbin/fw_setenv start_autoscript <span class="string">&quot;if usb start ; then run start_usb_autoscript; fi; if ext4load mmc 1:c 1020000 /boot/s905_autoscript; then autoscr 1020000; fi;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;*******************************************&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Complete copy OS to eMMC parted DATA&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;*******************************************&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="两边切换"><a href="#两边切换" class="headerlink" title="两边切换"></a>两边切换</h1><h2 id="Armbian切换安卓"><a href="#Armbian切换安卓" class="headerlink" title="Armbian切换安卓"></a>Armbian切换安卓</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> /boot/s905_autoscript /boot/s905_autoscript.bak</span><br></pre></td></tr></table></figure>

<h2 id="安卓切换Armbian"><a href="#安卓切换Armbian" class="headerlink" title="安卓切换Armbian"></a>安卓切换Armbian</h2><p>启动安卓的<code>终端模拟器</code>中，先su切换root用户，然后执行命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su</span><br><span class="line"><span class="built_in">mv</span> /data/boot/s905_autoscript.bak /data/boot/s905_autoscript </span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>diffy_mock_重构测试</title>
    <url>/2021/02/22/diffy_mock_%E9%87%8D%E6%9E%84%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><p>企业内部软件重构，接口的功能完全不变的情况下，切换数据库，或者使用元数据、多租户等技术。此时要求测试能快速全面的进行功能测试。</p>
<p>已有的接口自动化测试可以作为请求的发起端，接口的返回使用diffy进行断言。如果接口返回简单，需要检查数据库，将数据库查询使用接口实现，返回的数据行也作为接口的返回体，放入diffy做断言。</p>
<h2 id="原理图"><a href="#原理图" class="headerlink" title="原理图"></a>原理图</h2><p>diffy原版使用</p>
<pre class="mermaid">graph LR
a[proxy]-->c[candidate]
a-->b[primary]
a-->d[secondly]
c-->e[raw differences]
b-->e
b-->f[non-deterministic noise]
d-->f
e-->g[filtered differences]
f-->g</pre>
<p>录制primary、candidate的返回体，存储起来。wiremock-standalone存文件</p>
<pre class="mermaid">graph LR
a[proxy]-->h[wiremock-c]
h-->d[mock-c-data]
h-->c[candidate]
a-->i[wiremock-p]
i-->e[mock-p-data]
i-->b[primary]</pre>
<p>回放primary、candidate的返回体</p>
<pre class="mermaid">graph LR
a[proxy]-->c[wiremock-c]
a-->b[wiremock-p]
a-->d[secondly]
c-->e[raw differences]
b-->e
b-->f[non-deterministic noise]
d-->f
e-->g[filtered differences]
f-->g</pre>

<h1 id="试验命令cheatsheet"><a href="#试验命令cheatsheet" class="headerlink" title="试验命令cheatsheet"></a>试验命令cheatsheet</h1><p>启动primary服务</p>
<blockquote>
<p>java -jar diffy-mock-0.0.1-SNAPSHOT.jar –server.port=9990</p>
</blockquote>
<p>启动secondly服务</p>
<blockquote>
<p>java -jar diffy-mock-0.0.1-SNAPSHOT.jar –server.port=9991</p>
</blockquote>
<p>启动candidate服务</p>
<blockquote>
<p>java -jar diffy-mock-0.0.1-SNAPSHOT.jar –server.port=9992</p>
</blockquote>
<p>启动wiremock</p>
<blockquote>
<p>jave -jar .\wiremock-standalone-2.27.2.jar</p>
</blockquote>
<p>浏览器打开 <a href="http://localhost:8080/__admin/recorder/">http://localhost:8080/__admin/recorder/</a></p>
<p>配置record <a href="http://localhost:9990/">http://localhost:9990</a></p>
<p>自动化脚本配置http_proxy=<a href="http://localhost:8080,或者将服务器hostip改成localhost:8080也行，是的请求的流量能到wiremock，并录制">http://localhost:8080,或者将服务器hostip改成localhost:8080也行，是的请求的流量能到wiremock，并录制</a></p>
<p>请求完成后，点击stop，此时已经切换成回放模式。查看wiremock-standalone-2.27.2.jar目录能发现mapping目录，里面就是记录请求和返回的json。</p>
<p>启动diffy</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java -jar diffy-server.jar^</span><br><span class="line"> -candidate=localhost:9992^</span><br><span class="line"> -master.primary=localhost:8080^</span><br><span class="line"> -master.secondary=localhost:9991^</span><br><span class="line"> -service.protocol=http^</span><br><span class="line"> -serviceName=Mock-Service^</span><br><span class="line"> -proxy.port=:8880^</span><br><span class="line"> -admin.port=:8881^</span><br><span class="line"> -http.port=:8888^</span><br><span class="line"> -rootUrl=localhost:8888^</span><br><span class="line"> -excludeHttpHeadersComparison=true^</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>Diffy</tag>
      </tags>
  </entry>
  <entry>
    <title>移动光猫I-240EM和路由padavan配置方法</title>
    <url>/2021/02/14/%E7%A7%BB%E5%8A%A8%E5%85%89%E7%8C%ABI-240EM%E5%92%8C%E8%B7%AF%E7%94%B1padavan%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>移动几乎没有公网ip，开启ipv6当作公网ip</p>
<span id="more"></span>

<h1 id="光猫配置"><a href="#光猫配置" class="headerlink" title="光猫配置"></a>光猫配置</h1><h2 id="账号密码"><a href="#账号密码" class="headerlink" title="账号密码"></a>账号密码</h2><p>没找到漏洞，看别人的文章，直接猜中密码。</p>
<p>账号 CMCCAdmin<br>密码 aDm8H%MdA</p>
<h2 id="Internet设置"><a href="#Internet设置" class="headerlink" title="Internet设置"></a>Internet设置</h2><p>操作路径： 网络-宽带连接-Internet连接-链接名称选带有Internet的<br>关键点是ip模式要选择<code>IPv4&amp;IPv6</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">连接名称:	</span><br><span class="line">2_INTERNET_B_VID_41</span><br><span class="line">封装类型:	IPoE     PPPoE</span><br><span class="line">业务类型	</span><br><span class="line">INTERNET</span><br><span class="line">连接模式:	</span><br><span class="line">桥接</span><br><span class="line">   </span><br><span class="line">IP模式	</span><br><span class="line">IPv4&amp;IPv6</span><br><span class="line">启用 VLAN:	</span><br><span class="line">Vlan ID:	</span><br><span class="line">41</span><br><span class="line">802.1p:	</span><br><span class="line">0</span><br><span class="line">LAN 端口绑定:	LAN1 LAN2 LAN3 LAN4 </span><br></pre></td></tr></table></figure>

<h2 id="Lan设置"><a href="#Lan设置" class="headerlink" title="Lan设置"></a>Lan设置</h2><p>操作路径： 网络-LAN地址设置-IPV6设置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">IPV6 LAN侧主机设置</span><br><span class="line">DNS来源	</span><br><span class="line">家庭网关代理</span><br><span class="line">前缀来源	</span><br><span class="line">网络连接</span><br><span class="line">接口	</span><br><span class="line">无</span><br><span class="line"></span><br><span class="line">☑️ 启用DHCPv6服务器</span><br><span class="line">起始地址:	</span><br><span class="line">0:0:0:2</span><br><span class="line">结束地址:	</span><br><span class="line">0:0:0:255</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">地址信息是否通过DHCP获取 ☑️</span><br><span class="line">其他信息是否通过DHCP获取 ☑️</span><br><span class="line">RA报文最大自动发送时间	</span><br><span class="line">600</span><br><span class="line">RA报文最小自动发送时间	</span><br><span class="line">200</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="路由器设置"><a href="#路由器设置" class="headerlink" title="路由器设置"></a>路由器设置</h1><p>操作路径： 高级设置-外部网络(WAN)-IPv6设置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">IPv6 连接类型:	</span><br><span class="line">Native DHCPv6</span><br><span class="line">IPv6 硬件加速	</span><br><span class="line">Offload for LAN/WLAN</span><br><span class="line">选择 IPv6 外网接口:	</span><br><span class="line">WAN (ppp0)</span><br><span class="line">外网连接类型:	PPPoE</span><br><span class="line">IPv6 外网设置:</span><br><span class="line">获取 IPv6 外网地址:	</span><br><span class="line">Stateless: RA</span><br><span class="line">启用隐私扩展 (RFC 4941)	</span><br><span class="line">否 (*)</span><br><span class="line">DNSv6 外网设置</span><br><span class="line">自动获取 IPv6 DNS:	</span><br><span class="line">是</span><br><span class="line">IPv6 内网设置</span><br><span class="line">通过 DHCPv6 获取内网 IPv6 地址:	</span><br><span class="line">是</span><br><span class="line">启用 LAN 路由器通告	</span><br><span class="line">是</span><br><span class="line">启用 LAN DHCPv6 服务器:	</span><br><span class="line">Stateless (*)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>JMeter 跨线程组共享变量（单点登录Cookie无法保存）</title>
    <url>/2019/05/05/Automation/JMeter%20%E8%B7%A8%E7%BA%BF%E7%A8%8B%E7%BB%84%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%EF%BC%88%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95Cookie%E6%97%A0%E6%B3%95%E4%BF%9D%E5%AD%98%EF%BC%89/</url>
    <content><![CDATA[<p>我司采用单点登录用Cookie做身份认证，在进行JMeter性能测试时，仅使用HTTP Cookie Manager仍提示未登录。原因在于单点登录服务器的域名与待测试的服务器域名不一致，Cookie Manager不支持跨域Cookie。本文介绍两种方法来处理。</p>
<span id="more"></span>

<h1 id="JMeter-跨线程组共享变量（单点登录Cookie无法保存）"><a href="#JMeter-跨线程组共享变量（单点登录Cookie无法保存）" class="headerlink" title="JMeter 跨线程组共享变量（单点登录Cookie无法保存）"></a>JMeter 跨线程组共享变量（单点登录Cookie无法保存）</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>部分待测试的业务接口需要登录信息认证，根据Cookie确认身份，测试时候，业务接口报<code>403没有登录</code></p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>本来在线程组中加入登录的http请求就可以，但是登录接口的域名跟待测业务的域名不一样，导致默认的<code>Cookie Manager</code>忽略了Cookie，所以出现加入了Cookie Manager后还是无法处理跨域的Cookie。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>既然自带的<code>Cookie Manager</code>没法处理，就要写点脚本代码来运行了。思路如下</p>
<pre class="mermaid">graph TD
    A[登录请求]-->B[JSR233 Groovy脚本提取Cookie]
    B-->C[存储到线程组变量池]
    C-->D[HTTP消息头管理器加上Cookie]</pre>



<p><img src="groovy_cookie.png" alt="groovy获取cookie"></p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.StringReader;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line">String responseheaders = prev.getResponseHeaders();</span><br><span class="line">BufferedReader buffer_reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> StringReader(responseheaders));</span><br><span class="line">List&lt;String&gt; response_origin_list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (String line = buffer_reader.readLine(); line != <span class="literal">null</span>; line = buffer_reader.readLine()) &#123;</span><br><span class="line">    response_origin_list.add(line);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> origin_size = response_origin_list.size();</span><br><span class="line">String response_cookie = <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; origin_size; i++) &#123;</span><br><span class="line">    String[] cookie_item = response_origin_list[i].split(<span class="string">&quot;:&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (cookie_item[<span class="number">0</span>].equals(<span class="string">&quot;Set-Cookie&quot;</span>))</span><br><span class="line">        response_cookie += cookie_item[<span class="number">1</span>].trim() + <span class="string">&quot;;&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">String response_cookie_final = response_cookie.substring(<span class="number">0</span>, response_cookie.length() - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">vars.put(<span class="string">&quot;responsecookie&quot;</span>, response_cookie_final);</span><br></pre></td></tr></table></figure>

<p>简单分析一下上面的groovy脚本，跟Java基本一样，理解上不难。<code>prev</code>是内置的系统变量，<code>vars</code>也是像Map一样的内置变量，但是vars是线程组内可见。</p>
<p><img src="add_to_header_manager.png" alt="添加到HTTP_Header_Manager"></p>
<h2 id="改进方案"><a href="#改进方案" class="headerlink" title="改进方案"></a>改进方案</h2><p>上述的改造已经可以完成基本的性能测试，如果进行高压的长时间稳定性测试Cookie也不会超时，但是有可能把比较脆弱的登录接口压垮。</p>
<p>解决方法：将登陆接口单独开一个进程组，一分钟跑一次，得到的Cookie放到<code>properties</code>里面来进行跨线程组共享的目的。</p>
<blockquote>
<p>${__setProperty(newCookie,${responsecookie},)};</p>
</blockquote>
<p><img src="beanshell_properties.png" alt="beanshell_properties"></p>
<blockquote>
<p>${__property(newCookie)</p>
</blockquote>
<p><img src="add_to_header_manager2.png" alt="add_to_header_manager2"></p>
<p><strong>小提示</strong>：假如会话超时是1分钟，定时执行登录的线程组就行，这里如果用<code>Timer</code>的话就是先暂停后再登录，这样一开始就没有Cookie了。所以在登录之后，应该加一个Test Action来充当sleep。</p>
<p><img src="sleep_30s.png" alt="sleep_30s"></p>
<h2 id="遗留问题"><a href="#遗留问题" class="headerlink" title="遗留问题"></a>遗留问题</h2><p>如果cookie很长，会有性能问题，导致elapsed time和latency time变长。<br>后面发现我们项目的sso给的cookie都是一级域名的，不存在跨域问题。</p>
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwODA5MzQ2NDAsMTIzMjg3OTI3OCwtMT
Y4NjA3NDcyNF19
-->]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>JMeter</tag>
      </tags>
  </entry>
  <entry>
    <title>JMeter超大入参返回</title>
    <url>/2020/07/09/Automation/JMeter%E8%B6%85%E5%A4%A7%E5%85%A5%E5%8F%82%E8%BF%94%E5%9B%9E/</url>
    <content><![CDATA[<h1 id="JMeter超大入参返回"><a href="#JMeter超大入参返回" class="headerlink" title="JMeter超大入参返回"></a>JMeter超大入参返回</h1><h2 id="入参太大，StackOverFlow"><a href="#入参太大，StackOverFlow" class="headerlink" title="入参太大，StackOverFlow"></a>入参太大，StackOverFlow</h2><p>如果入参太大，比如几千行的json，http sample直接无法执行，查看日志显示StackOverFlow. 从hashcode方法开始抛出的，怀疑是放入本地变量了。<br>windows解决方案，新增文件%JMETER_HOME%\bin\setenv.bat，可以容纳近10m的入参。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> HEAP=-Xss10m</span><br></pre></td></tr></table></figure>

<h2 id="返回太大，Heap-OOM"><a href="#返回太大，Heap-OOM" class="headerlink" title="返回太大，Heap OOM"></a>返回太大，Heap OOM</h2><p>如果返回的内容太大，除了要禁用查看结果树、开启gzip压缩等，还可以调大堆区，这里同样给出windows解决方案。<br>windows解决方案，新增文件%JMETER_HOME%\bin\setenv.bat，亲测大约5m以下json返回，GUI不会崩。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> HEAP=-Xms4g -Xmx5g -XX:MaxMetaspaceSize=512m</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>JMeter</tag>
      </tags>
  </entry>
  <entry>
    <title>JMeter踩过的小坑，Cookie的domain和path</title>
    <url>/2019/05/13/Automation/JMeter%E8%B8%A9%E8%BF%87%E7%9A%84%E5%B0%8F%E5%9D%91/</url>
    <content><![CDATA[<h1 id="Cookie的domain和path"><a href="#Cookie的domain和path" class="headerlink" title="Cookie的domain和path"></a>Cookie的domain和path</h1><h2 id="domain"><a href="#domain" class="headerlink" title="domain"></a>domain</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Set-Cookie: login_sip=1D-8B-35; Path=/; Domain=.example.com</span><br></pre></td></tr></table></figure>
<p>SSO单点登录后，返回的头信息中应该包括若干条<code>Set-Cookie</code>，上述的Cookie说明此key-value的Cookie能用于*.example.com所有二级域名，<code>Path=/</code>表示后续所有路径都可以使用。<br>下面说的所有二级域名当然包括一级域名。</p>
<ul>
<li>Path=/; Domain=.example.com 所有二级域名，所有uri</li>
<li>Path=/; Domain=account.example.com 仅account.example.com这个二级域名可用，所有uri</li>
<li>Path=/openapi; Domain=.example.com 所有二级域名，仅匹配/openapi的uri</li>
</ul>
<h2 id="坑重现"><a href="#坑重现" class="headerlink" title="坑重现"></a>坑重现</h2><p>JMeter的<code>Server Name or IP</code>中，域名或ip后不应该添加任何东西，<code>perf.example.com</code>或<code>192.168.1.1</code>都是对的，以下都是错误的例子。</p>
<ul>
<li>perf.example.com/</li>
<li>perf.example.com/zoo</li>
<li>192.168.1.1:8080<br>如果填写的是<code>perf.example.com/</code>，就会出现错误信息：Not storing invalid cookie: &lt;aasso_login=””; Path=/; Domain=.example.com&gt; for URL <a href="http://perf.example.com//zoo/services/N">http://perf.example.com//zoo/services/N</a> (Illegal ‘domain’ attribute “example.com”. Domain of origin: “perf.example.com/“)</li>
</ul>
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTg4MDg3NTU0Myw4NjkzNDY1MTVdfQ==
-->]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>JMeter</tag>
      </tags>
  </entry>
  <entry>
    <title>Jmeter测试时间不准？开发拿Postman结果说事</title>
    <url>/2020/03/05/Automation/Jmeter%E6%B5%8B%E8%AF%95%E6%97%B6%E9%97%B4%E4%B8%8D%E5%87%86%EF%BC%9F%E5%BC%80%E5%8F%91%E6%8B%BFPostman%E7%BB%93%E6%9E%9C%E8%AF%B4%E4%BA%8B/</url>
    <content><![CDATA[<h1 id="Jmeter测试时间不准？开发拿Postman结果说事"><a href="#Jmeter测试时间不准？开发拿Postman结果说事" class="headerlink" title="Jmeter测试时间不准？开发拿Postman结果说事"></a>Jmeter测试时间不准？开发拿Postman结果说事</h1><h2 id="术语解释"><a href="#术语解释" class="headerlink" title="术语解释"></a>术语解释</h2><h3 id="Jmeter术语"><a href="#Jmeter术语" class="headerlink" title="Jmeter术语"></a>Jmeter术语</h3><p>Latency：请求发出到接收到第一个返回的字节的时间<br>Response time (= Sample time = Load time = Elapsed time)：请求发出到接收完最后一个字节的时间<br>可以看到响应时间总是比Latency大</p>
<h3 id="Postman术语"><a href="#Postman术语" class="headerlink" title="Postman术语"></a>Postman术语</h3><p>Socket Initialization: 打开socket时间，一般常数时间<br>DNS Lookup：将请求域名换成ip的时间，一般也很短，太慢也存在优化空间<br>TCP Handshake：TCP握手时间，受网络状态影响<br>Transfer Start：请求发出到接收到第一个返回的字节的时间。等于Jmeter的Latency，等于Chrome的TTFB（Time To First Byte)<br>Download：整个返回体的下载（接收）时间<br>Process：基本是常数时间，接收后Postman做请求头分离等时间</p>
<h2 id="场景复现"><a href="#场景复现" class="headerlink" title="场景复现"></a>场景复现</h2><p>同一个请求，返回体Postman显示900k，耗时大约300ms，Jmeter要500+ms。定位问题使用Dynatrace，发现服务器处理时间260+，接近Postman。此时开发就在嘟囔，测试的时间不知道怎么搞的。这时候作为测试负责人，心里窝火，但是事实摆在眼前。只能认真研究为啥。<br>首先，我们看下具体展开的时间</p>
<table>
<thead>
<tr>
<th>工具</th>
<th>总时间</th>
<th>TTFB</th>
<th>Download</th>
</tr>
</thead>
<tbody><tr>
<td>Postman</td>
<td>194</td>
<td>162</td>
<td>26</td>
</tr>
<tr>
<td>Jmeter</td>
<td>537</td>
<td>172</td>
<td>365</td>
</tr>
</tbody></table>
<p>TTFB/Latency时间差不多，在Download时间上差距很大，为什么Postman这么快呢？经前辈指点说Jmeter要手动添加gzip。<br>立马查看Jmeter请求的头和Postman请求的头，原来Postman的request header自动加上了Accept-Encoding: gzip, deflate，而JMeter没有。<br>打开JMeter的Debug级别日志可以看见返回体已经不是明文，实测一下：<br>工具|总时间|TTFB|Download<br>–|–|–|–<br>Postman|194|162|26<br>Jmeter with gzip|177|171|6</p>
<h2 id="扩展：-Accept-Encoding-amp-Content-Encoding"><a href="#扩展：-Accept-Encoding-amp-Content-Encoding" class="headerlink" title="扩展： Accept-Encoding &amp; Content-Encoding"></a>扩展： Accept-Encoding &amp; Content-Encoding</h2><p>HTTP 请求头 Accept-Encoding 会将客户端能够理解的内容编码方式——通常是某种压缩算法——进行通知（给服务端）。通过内容协商的方式，服务端会选择一个客户端提议的方式，使用并在响应头 Content-Encoding 中通知客户端该选择。</p>
<p>即使客户端和服务器都支持相同的压缩算法，在 identity 指令可以被接受的情况下，服务器也可以选择对响应主体不进行压缩。导致这种情况出现的两种常见的情形是：</p>
<p>要发送的数据已经经过压缩，再次进行压缩不会导致被传输的数据量更小。一些图像格式的文件会存在这种情况；<br>服务器超载，无法承受压缩需求导致的计算开销。通常，如果服务器使用超过80%的计算能力，微软建议不要压缩。</p>
<h2 id="建议-amp-讨论"><a href="#建议-amp-讨论" class="headerlink" title="建议&amp;讨论"></a>建议&amp;讨论</h2><ol>
<li>请求体可以常规地加上 Accept-Encoding: gzip, deflate </li>
<li>如果Sample Time在开启压缩后还是比Latency大很多，说明这个接口返回很大数据。此时我们要考虑服务器的内存使用量，因为大数据量返回的接口常规优化方式就是改大数据库一次的Fetch Size，此时服务器的内存占用量会大幅上升，严重时可以导致OOM。我们在回归性能问题单的同时，要观察服务器的内存使用量。</li>
<li>大数据量的接口从业务系统同步接口返回可能不是一个最佳的方案，会扰动业务系统的性能。应该通过别的途径，以非实时批处理的方式取大量数据更加符合分析统计的场景。</li>
<li>开发在优化时往往对Download Time没有特别好的优化方法，我们在确定返回体已经开启压缩后，可以用Latency作为指标。但是聚合报告聚合的是Sample Time，此时我们可以在<code>查看结果树</code> 或 <code>用表格查看结果</code> 中配置保存到csv文件，后期用Excel分析平均值或90%值。</li>
</ol>
]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>JMeter</tag>
      </tags>
  </entry>
  <entry>
    <title>postman请求前脚本，常用于生成token和时间戳</title>
    <url>/2020/08/21/Automation/postman-pre-request-script/</url>
    <content><![CDATA[<p>postman请求前脚本，常用于生成token和时间戳</p>
<span id="more"></span>

<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 构造post请求</span></span><br><span class="line"><span class="keyword">const</span> regRequest = &#123;</span><br><span class="line">	url : <span class="string">&#x27;http://kwe-beta.huawei.com/ApiCommonQuery/appToken/getRestAppDynamicToken&#x27;</span>,</span><br><span class="line">	method : <span class="string">&#x27;POST&#x27;</span>,</span><br><span class="line">	header : <span class="string">&#x27;Content-Type: application/json&#x27;</span>, <span class="comment">//注意要在Header中声明内容使用的类型</span></span><br><span class="line">	body : &#123;</span><br><span class="line">		mode : <span class="string">&#x27;raw&#x27;</span>, <span class="comment">// 使用raw(原始)格式</span></span><br><span class="line">		raw : <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(&#123;</span><br><span class="line">			<span class="string">&quot;appId&quot;</span> : <span class="string">&quot;com.huawei.unistar.hmc.md&quot;</span>,</span><br><span class="line">			<span class="string">&quot;credential&quot;</span> : <span class="string">&quot;RlJvdn5XQWkwK15hKnBZYnlkNkxAJEBQfjlsMzlCZzZGKlNyXWplTmdoYnQ3VWRsSyFXMTU0ODQwOTA4ODM1MA==&quot;</span></span><br><span class="line">		&#125;) <span class="comment">//要将JSON对象转为文本发送</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//发送请求</span></span><br><span class="line">pm.<span class="title function_">sendRequest</span>(regRequest, <span class="keyword">function</span> (<span class="params">err, res</span>) &#123;</span><br><span class="line">	<span class="variable language_">console</span>.<span class="title function_">log</span>(err ? err : res.<span class="title function_">json</span>()); <span class="comment">// 响应为JSON格式可以使用res.json()获取到JSON对象</span></span><br><span class="line">	<span class="title class_">Authorization</span> = res.<span class="title function_">json</span>().<span class="property">result</span>;</span><br><span class="line">	postman.<span class="title function_">setEnvironmentVariable</span>(<span class="string">&quot;Authorization&quot;</span>, <span class="title class_">Authorization</span>); <span class="comment">//将Authorization写入环境变量中</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="title class_">Date</span>.<span class="property"><span class="keyword">prototype</span></span>.<span class="property">Format</span> = <span class="keyword">function</span> (<span class="params">fmt</span>) &#123;</span><br><span class="line"><span class="keyword">var</span> o = &#123;</span><br><span class="line">        <span class="string">&quot;M+&quot;</span>: <span class="variable language_">this</span>.<span class="title function_">getMonth</span>() + <span class="number">1</span>, <span class="comment">//月份</span></span><br><span class="line">        <span class="string">&quot;d+&quot;</span>: <span class="variable language_">this</span>.<span class="title function_">getDate</span>(), <span class="comment">//日</span></span><br><span class="line">        <span class="string">&quot;H+&quot;</span>: <span class="variable language_">this</span>.<span class="title function_">getHours</span>(), <span class="comment">//小时</span></span><br><span class="line">        <span class="string">&quot;m+&quot;</span>: <span class="variable language_">this</span>.<span class="title function_">getMinutes</span>(), <span class="comment">//分</span></span><br><span class="line">        <span class="string">&quot;s+&quot;</span>: <span class="variable language_">this</span>.<span class="title function_">getSeconds</span>(), <span class="comment">//秒</span></span><br><span class="line">        <span class="string">&quot;q+&quot;</span>: <span class="title class_">Math</span>.<span class="title function_">floor</span>((<span class="variable language_">this</span>.<span class="title function_">getMonth</span>() + <span class="number">3</span>) / <span class="number">3</span>), <span class="comment">//季度</span></span><br><span class="line">        <span class="string">&quot;S&quot;</span>: <span class="variable language_">this</span>.<span class="title function_">getMilliseconds</span>() <span class="comment">//毫秒</span></span><br><span class="line">        &#125;;</span><br><span class="line"><span class="keyword">if</span> (<span class="regexp">/(y+)/</span>.<span class="title function_">test</span>(fmt)) fmt = fmt.<span class="title function_">replace</span>(<span class="title class_">RegExp</span>.<span class="property">$1</span>, (<span class="variable language_">this</span>.<span class="title function_">getFullYear</span>() + <span class="string">&quot;&quot;</span>).<span class="title function_">substr</span>(<span class="number">4</span> - <span class="title class_">RegExp</span>.<span class="property">$1</span>.<span class="property">length</span>));</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> k <span class="keyword">in</span> o)</span><br><span class="line">	<span class="keyword">if</span> (<span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="string">&quot;(&quot;</span> + k + <span class="string">&quot;)&quot;</span>).<span class="title function_">test</span>(fmt)) fmt = fmt.<span class="title function_">replace</span>(<span class="title class_">RegExp</span>.<span class="property">$1</span>, (<span class="title class_">RegExp</span>.<span class="property">$1</span>.<span class="property">length</span> == <span class="number">1</span>) ? (o[k]) : ((<span class="string">&quot;00&quot;</span> + o[k]).<span class="title function_">substr</span>((<span class="string">&quot;&quot;</span> + o[k]).<span class="property">length</span>)));</span><br><span class="line">	<span class="keyword">return</span> fmt;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> timeNow = <span class="keyword">new</span> <span class="title class_">Date</span>().<span class="title class_">Format</span>(<span class="string">&quot;yyyyMMddHHmmss&quot;</span>);</span><br><span class="line"></span><br><span class="line">postman.<span class="title function_">setGlobalVariable</span>(<span class="string">&quot;jobId&quot;</span>, timeNow);</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>postman</tag>
      </tags>
  </entry>
  <entry>
    <title>xpath用法杂记</title>
    <url>/2018/06/07/Automation/xpath%E7%94%A8%E6%B3%95%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>PageObject封装过程中难免大量使用xpath，记录一些比较好用的xpath。</p>
<span id="more"></span>
<h3 id="不-包含属性"><a href="#不-包含属性" class="headerlink" title="(不)包含属性"></a>(不)包含属性</h3><p>//tbody/tr[@class]</p>
<p>//tbody/tr[not(@class)]<br>//div[@componenttype and @class=’site-tree’]//input[@placeholder and not(@readonly)]</p>
<h3 id="相对路径找父子元素"><a href="#相对路径找父子元素" class="headerlink" title="相对路径找父子元素"></a>相对路径找父子元素</h3><p>//form[@class=’el-form’]/../../..</p>
<h3 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h3><p>/div[@componenttype and @class=’site-tree’]//input[@placeholder]</p>
<h3 id="根据文本定位"><a href="#根据文本定位" class="headerlink" title="根据文本定位"></a>根据文本定位</h3><h4 id="包含文本"><a href="#包含文本" class="headerlink" title="包含文本"></a>包含文本</h4><p>//span[contains(text(),’Switch Store’)]</p>
<h4 id="全等文本"><a href="#全等文本" class="headerlink" title="全等文本"></a>全等文本</h4><p>//dd[text()=’Malaysia Rep Office’]  </p>
<h4 id="文本长度"><a href="#文本长度" class="headerlink" title="文本长度"></a>文本长度</h4><p>//span[string-length(text())&gt;12]</p>
]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>xpath</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 导入导出 blob 类型的坑</title>
    <url>/2018/07/21/Database/MySQL%20%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%20blob%20%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%9D%91/</url>
    <content><![CDATA[<p>MySQL用Heidisql直接导出blob字段会出问题, 顺便记录mysqldump相关命令和注意点.</p>
<span id="more"></span>
<h1 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h1><p>最近在做Azkaban升级, 从2.5升到3.0, 在测试环境验证升级命令, 在迁移数据后发现启动不了Azkaban3.0. 经过艰难的debug, 发现blob字段二进制内容发生了变化. 原来我是直接用HeidiSQL直接导出到测试环境的验证库, 界面上看内容完全一样, 但是二进制内却发生了变化, 导致了GZIP格式错误, Azkaban的web工程无法启动</p>
<h1 id="mysqldump的注意事项"><a href="#mysqldump的注意事项" class="headerlink" title="mysqldump的注意事项"></a>mysqldump的注意事项</h1><h2 id="版本一致"><a href="#版本一致" class="headerlink" title="版本一致"></a>版本一致</h2><p>客户端的mysqldump要跟服务器端的mysqld版本完全一致. 我的服务器端是5.7, 客户端用5.6和8.0都失败了</p>
<h2 id="hex-blob参数"><a href="#hex-blob参数" class="headerlink" title="hex-blob参数"></a>hex-blob参数</h2><p>网文说如果不用<code>--hex-blob</code>参数, mysqldump和MySQL workbench都还是会导致blob字段错乱.</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows 安装 MySQL</title>
    <url>/2018/05/29/Database/Windows%20%E5%AE%89%E8%A3%85%20MySQL/</url>
    <content><![CDATA[<p>Windows 安装 MySQL安装笔记</p>
<span id="more"></span>

<h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><p><a href="http://dev.mysql.com/downloads/mysql/">http://dev.mysql.com/downloads/mysql/</a></p>
<p>，选择适合你的操作系统的版本，我是windows10 64位，选择Windows (x86, 64-bit), ZIP Archive，点“download”。页面跳转后选择“No thanks, just start my download.”</p>
<h1 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h1><p>下载完成后后，解压到本地目录，我解压到D:\mysql-5.7.16-winx64</p>
<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>复制目录下“my-default.ini”文件，重命名为”my.ini”。修改为以下配置，注意对应修改路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line"># Remove leading # and set to the amount of RAM for the most important data</span><br><span class="line"># cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.</span><br><span class="line">innodb_buffer_pool_size = 128M</span><br><span class="line"></span><br><span class="line"># Remove leading # to turn on a very important data integrity option: logging</span><br><span class="line"># changes to the binary log between backups.</span><br><span class="line"># log_bin</span><br><span class="line"></span><br><span class="line"># These are commonly set, remove the # and set as required.</span><br><span class="line">basedir = &quot;D:\mysql-5.7.16-winx64/&quot;</span><br><span class="line">datadir = &quot;D:\mysql-5.7.16-winx64/data/&quot;</span><br><span class="line">tmpdir = &quot;D:\mysql-5.7.16-winx64/data/&quot;</span><br><span class="line">socket = &quot;D:\mysql-5.7.16-winx64/data/mysql.sock&quot;</span><br><span class="line">log-error = &quot;D:\mysql-5.7.16-winx64/data/mysql_error.log&quot;</span><br><span class="line">innodb_data_home_dir = &quot;D:\mysql-5.7.16-winx64/data/&quot;</span><br><span class="line">port = 3306</span><br><span class="line"></span><br><span class="line"># Remove leading # to set options mainly useful for reporting servers.</span><br><span class="line"># The server defaults are faster for transactions and fast SELECTs.</span><br><span class="line"># Adjust sizes as needed, experiment to find the optimal values.</span><br><span class="line">join_buffer_size = 128M</span><br><span class="line">sort_buffer_size = 2M</span><br><span class="line">read_rnd_buffer_size = 2M </span><br><span class="line"></span><br><span class="line">sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER</span><br><span class="line">character-set-server = utf8mb4</span><br><span class="line">collation-server = utf8mb4_unicode_ci</span><br><span class="line"></span><br><span class="line">[client]</span><br><span class="line">default-character-set=utf8</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h1><p>因为没有data目录下的mysql数据，所以需要先初始化。<br>打开cmd，跳转到目录下bin目录中</p>
<figure class="highlight bat"><table><tr><td class="code"><pre><span class="line">mysqld --initialize --user=mysql --console</span><br></pre></td></tr></table></figure>

<p>该命令会生成基础的管理数据表，注意控制台cmd的返回，会有一个随机生成的密码，复制一下，备用</p>
<h1 id="设置windows服务"><a href="#设置windows服务" class="headerlink" title="设置windows服务"></a>设置windows服务</h1><p>还是在MySQL目录下的bin目录，使用cmd，执行以下命令将MySQL注册为Windows的服务</p>
<blockquote>
<p>mysqld install MySQL</p>
</blockquote>
<p>接着打开MySQL服务，在cmd输入以下命令</p>
<blockquote>
<p>net start mysql</p>
</blockquote>
<h1 id="修改密码"><a href="#修改密码" class="headerlink" title="修改密码"></a>修改密码</h1><blockquote>
<p>mysql -uroot -p</p>
</blockquote>
<p> 输入刚才记下的随机密码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set password = password(&#x27;root&#x27;);  # root就是你的新密码</span><br><span class="line">quit;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Windows 安装 MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>画瓢系列：玩具级别的电商系统的基本功能设计</title>
    <url>/2020/05/22/Dev/piao-shop-design/</url>
    <content><![CDATA[<p>业务先行，先抄一个业务功能的设计。</p>
<span id="more"></span>

<h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><h2 id="商品模块"><a href="#商品模块" class="headerlink" title="商品模块"></a>商品模块</h2><ol>
<li>商品添加</li>
<li>规格设置</li>
<li>上下架<h3 id="界面描述"><a href="#界面描述" class="headerlink" title="界面描述"></a>界面描述</h3>A. 商品采用列表分页展示，列表上方有搜索功能。<br>列表头：商品id，图片，名称，分类，价格，销量，库存，排序，上下架状态，操作列（编辑，删除，拼团）<br>B. 商品新增、规格设置<br>名称、单位、排序、销量、重量、缩略图、多图<h3 id="表结构设计"><a href="#表结构设计" class="headerlink" title="表结构设计"></a>表结构设计</h3><code>product_brand</code></li>
</ol>
<ul>
<li>id 自增，pk</li>
<li>name 品牌名称</li>
<li>logo_url 品牌logo</li>
<li>sort_id 排序，默认999</li>
<li>status 0：停用；1：启用</li>
</ul>
<p><code>product_category</code></p>
<ul>
<li>id 自增，pk</li>
<li>name</li>
<li>pid 父分类id</li>
<li>sort_id 排序，默认999</li>
<li>status 0：停用；1：启用</li>
</ul>
<h2 id="订单模块"><a href="#订单模块" class="headerlink" title="订单模块"></a>订单模块</h2><ol>
<li>购物车</li>
<li>下单</li>
<li>支付</li>
<li>发货</li>
<li>收货</li>
<li>评价</li>
<li>退款</li>
</ol>
<h2 id="用户模块"><a href="#用户模块" class="headerlink" title="用户模块"></a>用户模块</h2><ol>
<li>登录</li>
<li>注册</li>
<li>会员卡</li>
<li>充值</li>
</ol>
<h2 id="营销模块"><a href="#营销模块" class="headerlink" title="营销模块"></a>营销模块</h2><ol>
<li>积分</li>
<li>优惠券</li>
<li>分销</li>
<li>砍价</li>
<li>拼团</li>
<li>秒杀</li>
</ol>
<h1 id="表结构"><a href="#表结构" class="headerlink" title="表结构"></a>表结构</h1><h2 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> IF <span class="keyword">EXISTS</span> `<span class="keyword">user</span>`;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `<span class="keyword">user</span>`  (</span><br><span class="line">  `id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT COMMENT <span class="string">&#x27;ID&#x27;</span>,</span><br><span class="line">  `avatar_id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;头像&#x27;</span>,</span><br><span class="line">  `email` <span class="type">varchar</span>(<span class="number">255</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;邮箱&#x27;</span>,</span><br><span class="line">  `enabled` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;状态：1启用、0禁用&#x27;</span>,</span><br><span class="line">  `password` <span class="type">varchar</span>(<span class="number">255</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;密码&#x27;</span>,</span><br><span class="line">  `username` <span class="type">varchar</span>(<span class="number">255</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;用户名&#x27;</span>,</span><br><span class="line">  `dept_id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;部门名称&#x27;</span>,</span><br><span class="line">  `phone` <span class="type">varchar</span>(<span class="number">255</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;手机号码&#x27;</span>,</span><br><span class="line">  `job_id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;岗位名称&#x27;</span>,</span><br><span class="line">  `create_time` datetime(<span class="number">0</span>) <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;创建日期&#x27;</span>,</span><br><span class="line">  `last_password_reset_time` datetime(<span class="number">0</span>) <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;最后修改密码的日期&#x27;</span>,</span><br><span class="line">  `nick_name` <span class="type">varchar</span>(<span class="number">255</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `sex` <span class="type">varchar</span>(<span class="number">255</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`) <span class="keyword">USING</span> BTREE,</span><br><span class="line">  <span class="keyword">UNIQUE</span> INDEX `UK_kpubos9gc2cvtkb0thktkbkes`(`email`) <span class="keyword">USING</span> BTREE,</span><br><span class="line">  <span class="keyword">UNIQUE</span> INDEX `username`(`username`) <span class="keyword">USING</span> BTREE,</span><br><span class="line">  INDEX `FK5rwmryny6jthaaxkogownknqp`(`dept_id`) <span class="keyword">USING</span> BTREE,</span><br><span class="line">  INDEX `FKfftoc2abhot8f2wu6cl9a5iky`(`job_id`) <span class="keyword">USING</span> BTREE,</span><br><span class="line">  INDEX `FKpq2dhypk2qgt68nauh2by22jb`(`avatar_id`) <span class="keyword">USING</span> BTREE,</span><br><span class="line">  <span class="keyword">CONSTRAINT</span> `FK5rwmryny6jthaaxkogownknqp` <span class="keyword">FOREIGN</span> KEY (`dept_id`) <span class="keyword">REFERENCES</span> `dept` (`id`) <span class="keyword">ON</span> <span class="keyword">DELETE</span> RESTRICT <span class="keyword">ON</span> <span class="keyword">UPDATE</span> RESTRICT,</span><br><span class="line">  <span class="keyword">CONSTRAINT</span> `FKfftoc2abhot8f2wu6cl9a5iky` <span class="keyword">FOREIGN</span> KEY (`job_id`) <span class="keyword">REFERENCES</span> `job` (`id`) <span class="keyword">ON</span> <span class="keyword">DELETE</span> RESTRICT <span class="keyword">ON</span> <span class="keyword">UPDATE</span> RESTRICT,</span><br><span class="line">  <span class="keyword">CONSTRAINT</span> `FKpq2dhypk2qgt68nauh2by22jb` <span class="keyword">FOREIGN</span> KEY (`avatar_id`) <span class="keyword">REFERENCES</span> `user_avatar` (`id`) <span class="keyword">ON</span> <span class="keyword">DELETE</span> RESTRICT <span class="keyword">ON</span> <span class="keyword">UPDATE</span> RESTRICT</span><br><span class="line">) ENGINE <span class="operator">=</span> InnoDB AUTO_INCREMENT <span class="operator">=</span> <span class="number">7</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="operator">=</span> utf8 <span class="keyword">COLLATE</span> <span class="operator">=</span> utf8_general_ci COMMENT <span class="operator">=</span> <span class="string">&#x27;系统用户&#x27;</span> ROW_FORMAT <span class="operator">=</span> Compact;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>画瓢</tag>
      </tags>
  </entry>
  <entry>
    <title>重构</title>
    <url>/2020/12/11/Dev/refactoring/</url>
    <content><![CDATA[<p>之前看了重构的书，最近在公司内部自学网站学习重构的课程，简单记录一些核心要点。</p>
<span id="more"></span>

<h1 id="重构"><a href="#重构" class="headerlink" title="重构"></a>重构</h1><h2 id="代码坏味道"><a href="#代码坏味道" class="headerlink" title="代码坏味道"></a>代码坏味道</h2><ol>
<li>冗余和重复： 重复代码、过多注释、夸夸其谈未来性（过度设计）</li>
<li>局部膨胀： 过长的参数列表</li>
<li>耦合不良： 发散式变化（某一模块因多种原因被修改），霰弹式修改（一个功能修改多处代码）</li>
<li>结构不良： switch多处现身、新增状态码新增分支（违反开闭原则）、分支做多件事（违反单一职责）、临时变量（值域仅用于部分方法间传参）</li>
</ol>
<h2 id="重构手法"><a href="#重构手法" class="headerlink" title="重构手法"></a>重构手法</h2><p><strong>十六字真言</strong>：</p>
<ul>
<li>旧的不变</li>
<li>新的创建</li>
<li>一步切换</li>
<li>旧的再见</li>
</ul>
<p>小步修改，及时反馈。所谓反馈就是测试。</p>
<h3 id="简化语句"><a href="#简化语句" class="headerlink" title="简化语句"></a>简化语句</h3><ol>
<li>合并表达式。确认表达式没有副作用，抽函数表含义；顺序执行可用“或”，嵌套if可用“与”来合并</li>
<li>移动语句。</li>
<li>卫语句代替嵌套，提前返回。一般针对非核心逻辑</li>
</ol>
<h3 id="重组函数"><a href="#重组函数" class="headerlink" title="重组函数"></a>重组函数</h3><ol>
<li>查询和修改函数分离。无副作用的函数需要更少的操心。</li>
<li>已明确参数取代参数。如果参数决定不同执行逻辑，直接代为调用不同的函数。</li>
<li>提炼函数。提取功能，<strong>提升复用性</strong>；函数名描述用途，提升可读性；</li>
<li>内联函数。消除多余的间接性，方便后续重构。</li>
</ol>
<h3 id="重组数据"><a href="#重组数据" class="headerlink" title="重组数据"></a>重组数据</h3><ol>
<li>拆分变量： 变量多次赋值，且赋值的意义不同。</li>
<li>提炼类： 单一职责</li>
<li>内联类： 消除多余间接性，以便按照其他方向进一步拆分。</li>
<li>类继承系列： 函数上移/下移，字段上移/下移，移除子类/子类代替类型码，构造函数本体上移</li>
</ol>
<h2 id="重构遗留系统"><a href="#重构遗留系统" class="headerlink" title="重构遗留系统"></a>重构遗留系统</h2><ol>
<li>分析待拆分模块和db，“同一类型数据只有一处修改”</li>
<li>删除跨模块写库操作，将jion等类型上移到应用层，注意性能下降</li>
<li>待拆分模块提供API给其他模块使用</li>
<li>拷贝新增模块，读老库，原系统中原模块不动</li>
<li>其他模块调用新模块，架空原模块。（方便切回）</li>
<li>db数据迁移，原schema不删</li>
<li>调用新schema</li>
<li>删除原schema</li>
</ol>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>重构</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring 依赖版本查询</title>
    <url>/2022/09/02/Dev/spring-dependency-versions/</url>
    <content><![CDATA[<p>记录Springboot、Springcloud以及周边依赖的版本查询方法</p>
<span id="more"></span>

<h1 id="Springboot-周边依赖"><a href="#Springboot-周边依赖" class="headerlink" title="Springboot 周边依赖"></a>Springboot 周边依赖</h1><p>举例： <a href="https://docs.spring.io/spring-boot/docs/2.7.3/reference/html/dependency-versions.html">https://docs.spring.io/spring-boot/docs/2.7.3/reference/html/dependency-versions.html</a></p>
<h1 id="StringCloud-与-Springboot-依赖"><a href="#StringCloud-与-Springboot-依赖" class="headerlink" title="StringCloud 与 Springboot 依赖"></a>StringCloud 与 Springboot 依赖</h1><p><a href="https://start.spring.io/actuator/info">https://start.spring.io/actuator/info</a></p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
  </entry>
  <entry>
    <title>vscode配置for VUE</title>
    <url>/2018/07/14/Dev/vscode%E9%85%8D%E7%BD%AEfor%20VUE/</url>
    <content><![CDATA[<p>测试开发要做点什么东东,几乎就是全栈的节奏了, 记录一下vscode的一些配置</p>
<span id="more"></span>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;editor.formatOnSave&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;editor.tabSize&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;javascript.format.insertSpaceAfterFunctionKeywordForAnonymousFunctions&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;javascript.implicitProjectConfig.checkJs&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;javascript.validate.enable&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;prettier.singleQuote&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;prettier.semi&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;vetur.format.defaultFormatter.html&quot;</span><span class="punctuation">:</span> <span class="string">&quot;js-beautify-html&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;eslint.autoFixOnSave&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;eslint.validate&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;javascript&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;javascriptreact&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;language&quot;</span><span class="punctuation">:</span> <span class="string">&quot;vue&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;autoFix&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>开发VUE</category>
      </categories>
      <tags>
        <tag>VUE</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>画瓢系列：山寨一下公司的IT能力，做一个玩具级别的电商系统</title>
    <url>/2020/05/11/Dev/%E7%94%BB%E7%93%A2%E7%B3%BB%E5%88%97%EF%BC%9A%E5%B1%B1%E5%AF%A8%E4%B8%80%E4%B8%8B%E5%85%AC%E5%8F%B8%E7%9A%84IT%E8%83%BD%E5%8A%9B%EF%BC%8C%E5%81%9A%E4%B8%80%E4%B8%AA%E7%8E%A9%E5%85%B7%E7%BA%A7%E5%88%AB%E7%9A%84%E7%94%B5%E5%95%86%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>在菊厂中做着卑微的螺丝钉，日常经常使用很多很多IT的系统、框架、公共能力，接触的微服务架构。每天都只是简单地使用，了解特性，总是对其中的实现和原理抱有很大的好奇。</p>
<span id="more"></span>

<h1 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h1><ol>
<li>大厂螺丝钉，日常盲人摸象</li>
<li>不想被人小看，这也不懂，哪也不懂</li>
</ol>
<h1 id="决定"><a href="#决定" class="headerlink" title="决定"></a>决定</h1><p>我要把接触到的IT底层设施、代码框架、服务架构、API治理、消息队列、异步任务、灰度发布等经常接触的概念，用开源的组件尽量山寨一些轮子，起码能摸清楚轮子能转能载的原理。跟架构师大佬聊天不会只有“一脸懵逼、两个不懂”了</p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>画瓢</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Gist代码笔记</title>
    <url>/2018/08/16/Java/Java%20Gist%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>工作中主要用Java和Python, 有些用法老是忘记, 做个小笔记.</p>
<span id="more"></span>
<h1 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h1><h2 id="Collection转数组"><a href="#Collection转数组" class="headerlink" title="Collection转数组"></a>Collection转数组</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Foo[] foos = x.toArray(<span class="keyword">new</span> <span class="title class_">Foo</span>[x.size()]);</span><br></pre></td></tr></table></figure>
<h1 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h1><h2 id="RestTemplate"><a href="#RestTemplate" class="headerlink" title="RestTemplate"></a>RestTemplate</h2><p>服务提供方返回体是<code>Page&lt;XXXResource&gt;</code>, 需要使用exchange方法搭配ParameterizedTypeReference</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">HttpHeaders</span> <span class="variable">requestHeaders</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HttpHeaders</span>();</span><br><span class="line">requestHeaders.add(<span class="string">&quot;Authorization&quot;</span>, <span class="string">&quot;bearer &quot;</span> + uuid);  </span><br><span class="line">HttpEntity&lt;String&gt; requestEntity = <span class="keyword">new</span> <span class="title class_">HttpEntity</span>&lt;&gt;(<span class="literal">null</span>, requestHeaders);</span><br><span class="line">ParameterizedTypeReference&lt;Page&lt;LaunchResource&gt;&gt; typeReference = <span class="keyword">new</span> <span class="title class_">ParameterizedTypeReference</span>&lt;Page&lt;LaunchResource&gt;&gt;() &#123;&#125;;</span><br><span class="line">ResponseEntity&lt;Page&lt;LaunchResource&gt;&gt; responseEntity = restTemplate.exchange(url, HttpMethod.GET, requestEntity, parameterizedTypeReference);</span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java生成javacore和heapdump文件</title>
    <url>/2019/06/14/Java/Java%E7%94%9F%E6%88%90javacore%E5%92%8Cheapdump%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<p>现网有服务量大的服务，一次OOM后只留下了javacore文件，heapdump没有生成，这次去另一台一样职责的机器上检查取一下javacore和heap dump文件。</p>
<span id="more"></span>
<h2 id="什么是javacore"><a href="#什么是javacore" class="headerlink" title="什么是javacore"></a>什么是javacore</h2><ul>
<li>javacore是java应用程序在某个时间点的<strong>线程转储文件</strong>，通常也称为<strong>Thead Dump</strong>，是个文本文档</li>
<li>记录了整个JVM的运行情况(线程, 垃圾回收, JVM运行参数, 内存地址等信息)<h3 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h3>诊断程序问题,其中比较典型的包括线程阻塞, CPU使用率过高, JVM Crash, 堆内存不足和类装载等问题</li>
</ul>
<h3 id="命名"><a href="#命名" class="headerlink" title="命名"></a>命名</h3><p>通常以txt方式结尾,名称格式主要是以javacore开头, <strong>加上日期,产生的时间,当时的线程编号</strong>,如javacore.20100719.003424.299228.txt(<strong>Unix</strong>)</p>
<h3 id="生成方式"><a href="#生成方式" class="headerlink" title="生成方式"></a>生成方式</h3><ul>
<li><p>手动生成</p>
<ul>
<li>jstack： jstack -l 37320 &gt; /tmp/threadDump.txt</li>
<li>jcmd：jcmd 100373 Thread.print -l=true &gt; /tmp/$HOSTNAME-threadDump.txt</li>
<li>JVisualVM：图形化工具</li>
<li>Java Mission Control：oracle jdk自带图形化工具</li>
<li>kill -3 :在 VM 处理此信号后，VM 会继续运行。</li>
</ul>
</li>
<li><p>发送中断signal<br>  AIX和Linux: SIGQUIT,  <strong>kill -3 PID</strong><br>  Windows: Ctrl+Break, DrAdmin in WAS(未验证过)</p>
</li>
<li><p>系统在异常时自动throw(<strong>程序不一定退出</strong>)<br>  严重的本地调用出错<br>  内存不足(例如 OutOfMemory)</p>
<h3 id="策略分析"><a href="#策略分析" class="headerlink" title="策略分析"></a>策略分析</h3></li>
<li><p>  数百K的纯文本,最好借助工具,例如<code>jca</code>分析工具</p>
</li>
<li><p><strong>采集连续的多个时间点的javacore,方便对比(手动)</strong><br>  一般的线程执行都会非常快，如果出现某个资源的阻塞，在短时间内的两个javacore，该线程的堆栈会变化不大。 或多次javacore的线程都集中在等待某些资源。</p>
</li>
<li><p>  了解app的性质,基本处理流程</p>
</li>
<li><p>  app相关的处理能力(以前的数据,用于对比)</p>
</li>
<li><p>  问题出现时,多了解周边情况(cpu,io,外围),记录现状</p>
</li>
<li><p>  <strong>对thread状态进行分类,业务分布情况,资源等待情况(细化)</strong></p>
</li>
<li><p>  如有必要,获取heapdump分析(oom)</p>
</li>
</ul>
<h2 id="什么是Heap-Dump"><a href="#什么是Heap-Dump" class="headerlink" title="什么是Heap Dump"></a>什么是Heap Dump</h2><p>HeapDump文件是一个二进制文件，它保存了某一时刻JVM堆中对象使用情况，这种文件需要相应的工具进行分析，如IBM Heap Analyzer这类工具。这类文件最重要的作用就是分析系统中是否存在内存溢出的情况。<br>Heap Dump的格式有很多种，而且不同的格式包含的信息也可能不一样。但总的来说，Heap Dump一般都包含了一个堆中的Java Objects, Class等基本信息。同时，当你在执行一个转储操作时，往往会<strong>触发一次GC</strong>，所以你转储得到的文件里包含的信息通常是有效的内容（包含比较少，或没有垃圾对象了） 。</p>
<h3 id="生成方式-1"><a href="#生成方式-1" class="headerlink" title="生成方式"></a>生成方式</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dump live会触发full gc；all就没gc，线上系统慎用</span></span><br><span class="line">jmap -dump:live,format=b,file=/tmp/<span class="variable">$HOSTNAME</span>-heap.hprof &lt;pid&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">jcmd &lt;pid&gt; GC.heap_dump /tmp/heap.hprof <span class="comment"># 触发full gc</span></span><br><span class="line">jcmd 100373 GC.heap_dump /tmp/<span class="variable">$HOSTNAME</span>-heap-live.hprof <span class="comment"># 会触发full gc</span></span><br><span class="line">jcmd 100373 GC.heap_dump -all=<span class="literal">true</span> /tmp/<span class="variable">$HOSTNAME</span>-heap-all.hprof <span class="comment"># 不会触发full gc</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>JVM参数 -XX:+HeapDumpOnOutOfMemoryError  当OutOfMemoryError发生时自动生成 Heap Dump 文件。</p>
</li>
<li><p>jvisualvm</p>
</li>
<li><p>JProfile</p>
</li>
<li><p>Eclipse memory analyzer（jmat）</p>
<h3 id="分析工具"><a href="#分析工具" class="headerlink" title="分析工具"></a>分析工具</h3><p>IBM HeapAnalyzer</p>
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTMwNzY2ODg4MiwyMDM5MDMwNDc0LDk5OT
M0NDcwMCw2NjI1MTU3OSwtNTA2NDI1MTMzLC0zOTIwOTQ3MDcs
LTE4MzA3MjI1MDcsOTY2ODc4MTM0LDEyNDU0ODE2MzMsMzkwMz
cxMTYzXX0=</li>
<li><p>-&gt;</p>
</li>
</ul>
]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java远程调试</title>
    <url>/2018/07/21/Java/Java%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/</url>
    <content><![CDATA[<p>迁移升级Azkaban时候发现根据文档升级总是报错, 抛出的错误只有sql错误, 没有更具体的错误, 此时只能祭出远程调试大法了.</p>
<span id="more"></span>
<h1 id="相关软件环境说明"><a href="#相关软件环境说明" class="headerlink" title="相关软件环境说明"></a>相关软件环境说明</h1><p>IDE: IDEA 201702 社区版<br>调试对象: azkaban-web-server-3.0.0</p>
<h1 id="方法说明"><a href="#方法说明" class="headerlink" title="方法说明"></a>方法说明</h1><ol>
<li>IDEA打开工程对应的源代码</li>
<li>右上角打开”Run/Debug Configurations”</li>
<li>绿色+号, 选择Remote远程</li>
<li>Name随便填写, Settings中, 填写Host和Port</li>
<li>将”Command line arguments for running remote JVM”的JVM参数添加到远程服务器的启动命令中<br>其中, <code>suspend=y</code>代表进程等待IDEA连上JVM再启动进程, 方便调试一闪即逝的启动错误.</li>
<li>IDEA的源代码中打断点</li>
<li>启动远端java进程</li>
<li>点击IDEA的debug按钮<h1 id="额外说明"><a href="#额外说明" class="headerlink" title="额外说明"></a>额外说明</h1></li>
<li>有时候竟然没有断点在源代码中, 只能对着源代码单步调试了T_T</li>
<li>如果要进入第三方包, 也可以在File-Project Structure-Modules-绿色加号-Library添加源代码的jar包, 打断点, 或者单步步进相关函数</li>
</ol>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>画瓢-Springboot骨架</title>
    <url>/2020/05/11/Java/MyBatisPlus%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E5%99%A8generator%E5%9C%A8Postgres%E6%95%B0%E6%8D%AE%E5%BA%93%E6%97%A0%E6%B3%95%E7%94%9F%E6%88%90/</url>
    <content><![CDATA[<p>在菊厂中做着卑微的螺丝钉，日常经常使用很多很多IT的系统、框架、公共能力，接触的微服务架构。每天都只是简单地使用，了解特性，总是对其中的实现和原理抱有很大的好奇。画瓢系列第一章就是Java web常用Springboot骨架的尝试。直接抄袭公司的东西是不对的，直接用开源的组件模拟一下大概的意思应该是可以的。</p>
<span id="more"></span>

<h1 id="葫芦：spring-boot-api-project-seed"><a href="#葫芦：spring-boot-api-project-seed" class="headerlink" title="葫芦：spring-boot-api-project-seed"></a>葫芦：spring-boot-api-project-seed</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>一个基于Spring Boot &amp; MyBatis的种子项目，用于快速构建中小型API、RESTful API项目。<br><a href="https://github.com/lihengming/spring-boot-api-project-seed">https://github.com/lihengming/spring-boot-api-project-seed</a></p>
<p>直接clone不是画瓢，而是买葫芦了，所以我打算按照他的思路，组装属于我的瓢。<br>先去掉代码生成，直到我也写了十几个工程项目之后，再考虑加上。<br>不太喜欢Fastjson，要换掉。</p>
<h1 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h1>]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>画瓢</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>MyBatisPlus 代码生成器generator在Postgres数据库无法生成</title>
    <url>/2021/01/21/Java/mybatisplus-generator-on-postgres/</url>
    <content><![CDATA[<p>MyBatis-Plus的代码生成器generator用示例代码无法在postgres数据库表上生成代码，原因是没设置schemaName。</p>
<span id="more"></span>

<h1 id="关键点"><a href="#关键点" class="headerlink" title="关键点"></a>关键点</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">DataSourceConfig</span> <span class="variable">dataSourceConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataSourceConfig</span>();</span><br><span class="line">dataSourceConfig.setDbType(DbType.POSTGRE_SQL);  </span><br><span class="line">dataSourceConfig.setSchemaName(<span class="string">&quot;mybatisplus&quot;</span>);  <span class="comment">// 少了这行</span></span><br></pre></td></tr></table></figure>


]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>springboot多profiles环境配置</title>
    <url>/2018/07/13/Java/springboot%E5%A4%9Aprofiles%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>spring boot开发通常由多个环境, 不同环境用的数据库密码等都不一样, 怎么可以灵活切换呢? 最简单方法可以用spring boot的profiles切换方法.</p>
<span id="more"></span>
<h1 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h1><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span>  </span><br><span class="line"> <span class="attr">profiles:.active:</span> <span class="string">dev</span>  </span><br><span class="line">  <span class="attr">datasource:</span>  </span><br><span class="line"> <span class="attr">username:</span> <span class="string">root</span>  </span><br><span class="line">      <span class="attr">password:</span> <span class="string">huawei123</span>  </span><br><span class="line">      <span class="attr">driver-class-name:</span> <span class="string">com.mysql.jdbc.Driver</span>  </span><br><span class="line">  <span class="attr">jpa:</span>  </span><br><span class="line"> <span class="attr">open-in-view:</span> <span class="literal">true</span>  </span><br><span class="line">    <span class="attr">show-sql:</span> <span class="literal">true</span>  </span><br><span class="line">    <span class="attr">hibernate:</span>  </span><br><span class="line"> <span class="attr">ddl-auto:</span> <span class="string">create</span> <span class="comment">#validate  </span></span><br><span class="line">  <span class="attr">properties:</span>  </span><br><span class="line"> <span class="attr">hibernate: dialect:</span> <span class="string">com.huawei.unistar.ailog.MySQL5DialectUTF8</span> <span class="comment"># MySQL5DialectUTF8  </span></span><br><span class="line">  <span class="attr">aop:</span>  </span><br><span class="line"> <span class="attr">auto:</span> <span class="literal">true</span> <span class="comment"># Add @EnableAspectJAutoProxy.  default: true  </span></span><br><span class="line">  <span class="attr">proxy-target-class:</span> <span class="literal">false</span> <span class="comment"># Whether subclass-based (CGLIB) proxies are to be created (true) as opposed to standard Java interface-based proxies (false).  </span></span><br><span class="line">  <span class="attr">logging:.level:.org:.hibernate:.type:</span> <span class="string">debug</span>  </span><br><span class="line"><span class="meta">---  </span></span><br><span class="line"><span class="attr">spring.profiles:</span> <span class="string">dev</span>  </span><br><span class="line"><span class="attr">spring:.datasource:.url:</span> <span class="string">jdbc:mysql://mysql:3306/ailog?characterEncoding=utf-8&amp;useSSL=false</span>  </span><br><span class="line"><span class="meta">---  </span></span><br><span class="line"><span class="attr">spring.profiles:</span> <span class="string">prod</span>  </span><br><span class="line"><span class="attr">spring:.datasource:.url:</span> <span class="string">jdbc:mysql://localhost:3306/ailog?characterEncoding=utf-8&amp;useSSL=false</span></span><br></pre></td></tr></table></figure>
<ol>
<li>用<code>---</code>分隔多块配置</li>
<li>spring.profiles: {name} 是profile的名字</li>
<li>最上面没有特殊标记, 或有active标记的一节是默认的, 会被默认加载. 可以将公共的配置放那.</li>
<li><code>spring:.datasource:.url</code> 中<code>.datasource</code>应该是yml语法的一种缩写语法</li>
</ol>
<h1 id="怎么应用"><a href="#怎么应用" class="headerlink" title="怎么应用"></a>怎么应用</h1><h2 id="命令行"><a href="#命令行" class="headerlink" title="命令行"></a>命令行</h2><p>ref :<a href="https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#howto-set-active-spring-profiles">https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#howto-set-active-spring-profiles</a><br>用系统变量<code>spring.profiles.active</code>穿进去</p>
<blockquote>
<p>java -jar -Dspring.profiles.active=prod /tmp/ailog.jar</p>
</blockquote>
<p>或用环境变量<code>SPRING_PROFILES_ACTIVE</code></p>
<blockquote>
<p>export SPRING_PROFILES_ACTIVE=prod &amp;&amp; java -jar /tmp/ailog.jar</p>
</blockquote>
<p> 网络上说可以<code>java -jar /tmp/ailog.jar --spring.profiles.active=prod</code>的方式启用prod的profile, 我实测<strong>不行</strong>! springboot 2.0.3</p>
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTA3MzQ5NTYwNF19
-->]]></content>
      <categories>
        <category>开发springboot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title>拦截器+信号量做接口429限流</title>
    <url>/2020/06/19/Java/%E6%8B%A6%E6%88%AA%E5%99%A8+%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%81%9A%E6%8E%A5%E5%8F%A3429%E9%99%90%E6%B5%81/</url>
    <content><![CDATA[<h1 id="高可用之接口限流"><a href="#高可用之接口限流" class="headerlink" title="高可用之接口限流"></a>高可用之接口限流</h1><h2 id="限流方案"><a href="#限流方案" class="headerlink" title="限流方案"></a>限流方案</h2><ol>
<li>请求存消息队列，实例根据自己处理能力，拉取消息消费</li>
<li>线程池控制，排满线程池队就直接失败</li>
<li>请求拦截器，维护一个信号量控制同时并发处理数，超出排队值(require排队)就返回429状态码</li>
</ol>
<h2 id="信号量方案"><a href="#信号量方案" class="headerlink" title="信号量方案"></a>信号量方案</h2><p>Spring管理唯一bean，内含唯一的限流拦截器。以下是关键变量<br>Semaphore current_model_semaphore 所有请求都共用一个信号量；<br>int semaphoreSize 信号量有多少permits<br>int semaphoreMaxQueueSize 设定多少请求可以排队，超了就抛异常了<br>List<String> apiFilterList 哪些URL需要拦截<br>ConcurrentMap&lt;String, AtomicInteger&gt; concurrents 接口对应有多少个当前处理数<br>Boolean returnTooManyRequestError 是否启用429返回</p>
<h2 id="处理逻辑"><a href="#处理逻辑" class="headerlink" title="处理逻辑"></a>处理逻辑</h2><ol>
<li>判断当前请求的url是否匹配apiFilterList其中一个，不匹配返回filter chain后续处理</li>
<li>如果未启动429返回，则阻塞地获取信号量。获取成功则继续处理，超时会触发 InterruptedException ，捕捉后抛业务异常</li>
<li>如果请求头没有标识本次请求为最后一次重试，调用tryAcquire()获取信号量的permits，如果没有现成可用的permits，立即返回，接着就返回429状态码，结束请求</li>
<li>如果已达最大重试次数，那么本次请求应该更加“倔强”地等。如果排队获取信号量的线程还没达到设定的最长semaphoreMaxQueueSize，那么就acquire等待。如果队伍已满，只能放弃等待直接返回429.</li>
<li>所有acquire()后，在finally块做信号量的release()</li>
</ol>
<pre class="mermaid">graph TB
    1{判断当前请求的url是否匹配apiFilterList其中一个}
    2[拦截器返回交给filter chian后续处理]
    3{是否启用429返回}
    4{acquire阻塞地获取信号量}
    5[捕获InterruptedException后抛业务异常]
    6[正常走业务逻辑]
    7{是否达到最大重试次数}
    8{tryAcquire有无现成的permits}
    9[快速失败返回429]
    10{是否达到最大排队长度}


    1--无需限流-->2
    1--需要限流-->3
    3--未启用429-->4
    4--超时-->5
    4--成功获取-->6
    3--启用429-->7
    7--否-->8
    8--无-->9
    8--有-->6
    7--是-->10
    10--是-->9
    10--否-->4</pre>]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>画瓢-Springboot骨架</title>
    <url>/2020/05/11/Java/%E7%94%BB%E7%93%A2-Springboot%E9%AA%A8%E6%9E%B6/</url>
    <content><![CDATA[<p>在菊厂中做着卑微的螺丝钉，日常经常使用很多很多IT的系统、框架、公共能力，接触的微服务架构。每天都只是简单地使用，了解特性，总是对其中的实现和原理抱有很大的好奇。画瓢系列第一章就是Java web常用Springboot骨架的尝试。直接抄袭公司的东西是不对的，直接用开源的组件模拟一下大概的意思应该是可以的。</p>
<span id="more"></span>

<h1 id="葫芦：spring-boot-api-project-seed"><a href="#葫芦：spring-boot-api-project-seed" class="headerlink" title="葫芦：spring-boot-api-project-seed"></a>葫芦：spring-boot-api-project-seed</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>一个基于Spring Boot &amp; MyBatis的种子项目，用于快速构建中小型API、RESTful API项目。<br><a href="https://github.com/lihengming/spring-boot-api-project-seed">https://github.com/lihengming/spring-boot-api-project-seed</a></p>
<p>直接clone不是画瓢，而是买葫芦了，所以我打算按照他的思路，组装属于我的瓢。<br>先去掉代码生成，直到我也写了十几个工程项目之后，再考虑加上。<br>不太喜欢Fastjson，要换掉。</p>
<h1 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h1>]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>画瓢</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>内网使用pip</title>
    <url>/2018/03/21/Python/pip%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h1 id="离线安装pip包"><a href="#离线安装pip包" class="headerlink" title="离线安装pip包"></a>离线安装pip包</h1><h2 id="pip安装"><a href="#pip安装" class="headerlink" title="pip安装"></a>pip安装</h2><p>暂略</p>
<h2 id="下载包而不安装"><a href="#下载包而不安装" class="headerlink" title="下载包而不安装"></a>下载包而不安装</h2><p>该命令会下载whl包，包括被依赖的包</p>
<blockquote>
<p>pip install &lt;包名&gt; -d &lt;目录&gt; 或 pip install -d &lt;目录&gt; -r requirements.txt<br>pip install oauthlib -d .\oauthlib<br>新版pip： pip download -d DIR somepackage</p>
</blockquote>
<h2 id="安装全部包"><a href="#安装全部包" class="headerlink" title="安装全部包"></a>安装全部包</h2><blockquote>
<p>pip install –no-index –find-links=DIR -r requirements.txt</p>
</blockquote>
<h1 id="内网使用"><a href="#内网使用" class="headerlink" title="内网使用"></a>内网使用</h1><p>windows环境下，建立全局配置文件C:\ProgramData\pip\pip.ini</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">timeout = 3</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">proxy = http://username:password@proxy.example.com:port</span><br></pre></td></tr></table></figure>
<p>不知为啥，就算配置上trust-host、证书，在我司内网环境下用pypi的源依旧会报证书验证错误<code>SSL3_GET_SERVER_CERTIFICATE</code>。</p>
<!--stackedit_data:
eyJoaXN0b3J5IjpbNTgzMjM4NjQ3XX0=
-->]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title>pycharm 简单使用</title>
    <url>/2018/09/20/Python/pycharm%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>PyCharm是写python工程的利器, 如果是分析数据或单文件的python作业用Jupiter会更合适.</p>
<span id="more"></span>

<h1 id="版本选择"><a href="#版本选择" class="headerlink" title="版本选择"></a>版本选择</h1><p>免费的社区: <a href="https://www.jetbrains.com/pycharm/download">https://www.jetbrains.com/pycharm/download</a></p>
<p>如果已经有JetBrain家的Idea又不想另外安装一个IDE, 可以在Idea上安装python插件, 功能几乎一样.</p>
<h1 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h1><h2 id="选择python环境"><a href="#选择python环境" class="headerlink" title="选择python环境"></a>选择python环境</h2><p>在创建项目和项目的setting都可以修改python解释器. 以下分别是在pycharm创建新环境和使用已有环境的截图.</p>
<p>使用默认安装到个人使用的Anaconda的安装目录一般在C:\Users&lt;username&gt;\Anaconda3, 在安装目录下有envs记录各环境, 其下目录名就是环境名</p>
<p><img src="%E5%88%9B%E5%BB%BA%E6%96%B0%E7%8E%AF%E5%A2%83.png"></p>
<p>选择Existing interpreter可以选择本地安装的python.exe文件, 可以在python安装目录/Anaconda目录, 但使用独立环境的话, 选择的是环境内的python.exe文件.</p>
<p><img src="%E9%80%89%E6%8B%A9conda%E7%8E%AF%E5%A2%83.png" alt="选择本地Conda环境中的解释器"></p>
<h2 id="模板文件"><a href="#模板文件" class="headerlink" title="模板文件"></a>模板文件</h2><p>File - Settings - Editor - File and Code Templates, 选择python scripts. 填入如下模板:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Created by $USER on $DATE</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>第一行在Linux环境中使用尤为方便, 可以./main.py即可执行有x权限的文件. 第二行说明了文档的编码格式, 基本是固定utf-8了. 第三行纯粹就是给人看的, 并无功能性.</p>
<h2 id="试试Hello-World"><a href="#试试Hello-World" class="headerlink" title="试试Hello World"></a>试试Hello World</h2><p>新建python文件, 然后将pass修改为print(‘hello world’)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Created by Tony on 2018/9/21</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;hello world&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>第一次运行点击绿色按钮即可, 之后可以使用快捷键<code>shift+F10</code></p>
<h2 id="文字缩放"><a href="#文字缩放" class="headerlink" title="文字缩放"></a>文字缩放</h2><p>现在的屏幕分辨率众多, 在不同机器上时常需要放大缩小代码, 如果默认并未打开滚轮缩放, 可以如下设定:</p>
<p>File - Settings - Editor - General - Mouse - Change font size(Zoom) with Ctrl+Mouse Wheel, 勾选上即可</p>
]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python3与Anaconda环境管理</title>
    <url>/2018/09/19/Python/python3%E4%B8%8EAnaconda%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>python安装和环境管理 on windows</p>
<span id="more"></span>

<h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><h2 id="python2-vs-python3"><a href="#python2-vs-python3" class="headerlink" title="python2 vs python3"></a>python2 vs python3</h2><p>时至今日, 除非维护python2代码, 不再建议使用python2开始新项目. </p>
<p>python3没有烦人的字符串编码问题, 这个理由已经足够了.</p>
<h2 id="32位-vs-64位"><a href="#32位-vs-64位" class="headerlink" title="32位 vs 64位"></a>32位 vs 64位</h2><p>我建议32位即可, 64位需要的内存较多, 适合硬件内存很大, 数据量很大的运算. </p>
<p>另一方面因为不少偏门的第三方库并没有编译64位的链接库, 用32位能遇到更少的兼容性问题.</p>
<h2 id="安装路径"><a href="#安装路径" class="headerlink" title="安装路径"></a>安装路径</h2><p>本文环境在windows下, 建议无论安装什么软件都不要在路径上留有空格和中文, 因为总有一些偏门的库并没有考虑空格或中文字符, 导致加载库或引用文件时候报错.</p>
<h1 id="环境管理"><a href="#环境管理" class="headerlink" title="环境管理"></a>环境管理</h1><p>有些时候, 需要在同一台机器上维护python2的代码, 同时又要切换到python3开发新项目代码.</p>
<h2 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h2><p>如需要进行机器学习, 数据科学的学习, 建议使用Anaconda. 虽然Anaconda的安装包不小, 但里面包含的工具也较为丰富, 还有图形界面可以操作.</p>
<h2 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h2><p>清华的源: <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</a></p>
<p>Anaconda3对应python3, 选择exe的安装版本. Anaconda自带python, 所以这里选择版本跟上文一样. 由此一来, 都不用自己手动安装python了.</p>
<p>安装过程中, 如果选择仅安装给个人使用, 推荐用默认路径; 如果要安装在D盘, 建议选择安装给所有人使用.</p>
<h2 id="包管理改国内源"><a href="#包管理改国内源" class="headerlink" title="包管理改国内源"></a>包管理改国内源</h2><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure>

<p>或者修改配置文件</p>
<blockquote>
<p>C:\Users&lt;username&gt;.condarc</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line"><span class="comment">#  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span></span><br><span class="line">  - defaults</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show channel URLs when displaying what is going to be downloaded and</span></span><br><span class="line"><span class="comment"># in &#x27;conda list&#x27;. The default is False.</span></span><br><span class="line">show_channel_urls: True</span><br><span class="line">allow_other_channels: True</span><br><span class="line"></span><br><span class="line">proxy_servers:</span><br><span class="line">    http: http://domain\username:password@corp.com:8080</span><br><span class="line">    https: http://domain\username:password@corp.com:8080</span><br><span class="line">ssl_verify: False</span><br></pre></td></tr></table></figure>



<h3 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h3><h4 id="增删查改环境"><a href="#增删查改环境" class="headerlink" title="增删查改环境"></a>增删查改环境</h4><p>conda create -n rf python=3.6  创建名为rf 的环境, 版本为python3.6</p>
<p>conda info -e  命令查看已有的环境</p>
<p>conda remove -n env_name –all来删除指定的环境（如果不添–all参数，而是指明某个库名，则是删除该库）</p>
<p>conda create –name new_env_name –clone old_env_name 复制一个环境</p>
<p><img src="commands.png" alt="命令示例"></p>
<h4 id="包管理"><a href="#包管理" class="headerlink" title="包管理"></a>包管理</h4><p>activate rf   进入某个环境(rf), 可以看到提示符最左侧已经变化</p>
<p>deactivate 退出环境</p>
<p>conda list 当前环境所有包</p>
<p>conda install -n rf robotframework   在rf环境中安装robotframework包</p>
<p>pip install robotframework   在activate激活rf环境后, 也可以直接使用pip命令</p>
<h4 id="导入导出分享"><a href="#导入导出分享" class="headerlink" title="导入导出分享"></a>导入导出分享</h4><p>activate target_env  切换到目标环境</p>
<p>conda env export &gt; environment.yml 导出成为yml文件</p>
<p>conda env create -f environment.yml 导入yml</p>
]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Robot Framework</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次python调试excel读取错误</title>
    <url>/2019/01/31/Python/%E8%AE%B0%E4%B8%80%E6%AC%A1python%E8%B0%83%E8%AF%95excel%E8%AF%BB%E5%8F%96%E9%94%99%E8%AF%AF/</url>
    <content><![CDATA[<p>日常工作之一就是帮助合作方解决自动化问题, 今天的问题是python写的Robotframework扩展库ExcelRobot在读取xlsx报错, 同样的文件昨天还是OK的. 带着疑惑开始debug</p>
<span id="more"></span>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>将Robotframework的执行日志调到trace, 获取报告如下:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;D:\python\lib\site-packages\robotframework_excel-1.0.0b4-py2.7.egg\ExcelRobot\base.py&quot;</span>, line 33, <span class="keyword">in</span> open_excel</span><br><span class="line">    self.reader = ExcelReader(file_path, self.date_format, self.number_format, self.bool_format)</span><br><span class="line">  File <span class="string">&quot;D:\python\lib\site-packages\robotframework_excel-1.0.0b4-py2.7.egg\ExcelRobot\reader.py&quot;</span>, line 21, <span class="keyword">in</span> __init__</span><br><span class="line">    self._workbook = open_workbook(self.file_path, formatting_info=self.is_xls, on_demand=True)</span><br><span class="line">  File <span class="string">&quot;D:\python\lib\site-packages\xlrd\__init__.py&quot;</span>, line 143, <span class="keyword">in</span> open_workbook</span><br><span class="line">    ragged_rows=ragged_rows,</span><br><span class="line">  File <span class="string">&quot;D:\python\lib\site-packages\xlrd\xlsx.py&quot;</span>, line 808, <span class="keyword">in</span> open_workbook_2007_xml</span><br><span class="line">    x12book.process_stream(zflo, <span class="string">&#x27;Workbook&#x27;</span>)</span><br><span class="line">  File <span class="string">&quot;D:\python\lib\site-packages\xlrd\xlsx.py&quot;</span>, line 265, <span class="keyword">in</span> process_stream</span><br><span class="line">    meth(self, elem)</span><br><span class="line">  File <span class="string">&quot;D:\python\lib\site-packages\xlrd\xlsx.py&quot;</span>, line 391, <span class="keyword">in</span> do_sheet</span><br><span class="line">    bk._sheet_visibility.append(visibility_map[state])</span><br></pre></td></tr></table></figure>
<p>从日志可以看到, 在打开文件的时候就报错了, 大约在do_sheet中, 在取<code>visibility_map</code>时发生<code>KeyError: &#39;null&#39;</code></p>
<h2 id="走读代码"><a href="#走读代码" class="headerlink" title="走读代码"></a>走读代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">do_sheet</span>(<span class="params">self, elem</span>):</span><br><span class="line">    bk = self.bk</span><br><span class="line">    sheetx = bk.nsheets</span><br><span class="line">    <span class="comment"># print elem.attrib</span></span><br><span class="line">    rid = elem.get(U_ODREL + <span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">    sheetId = <span class="built_in">int</span>(elem.get(<span class="string">&#x27;sheetId&#x27;</span>))</span><br><span class="line">    name = unescape(ensure_unicode(elem.get(<span class="string">&#x27;name&#x27;</span>)))</span><br><span class="line">    reltype = self.relid2reltype[rid]</span><br><span class="line">    target = self.relid2path[rid]</span><br><span class="line">    <span class="comment"># 此处省略几行</span></span><br><span class="line">    state = elem.get(<span class="string">&#x27;state&#x27;</span>)</span><br><span class="line">    visibility_map = &#123;</span><br><span class="line">        <span class="literal">None</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&#x27;visible&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&#x27;hidden&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;veryHidden&#x27;</span>: <span class="number">2</span></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>在调试器查看对象的属性<code>elem.items()</code>, 返回的list(tuple)中, 有这么一项<code>(&#39;state&#39;, &#39;null&#39;)</code> 跟日志一致. 为什么会有这个属性呢, 查看了xlrd最新的代码, 在visibility_map里面确实只有这几个key啊, 不存在<code>null</code>这个key.</p>
<h2 id="打开excel看看"><a href="#打开excel看看" class="headerlink" title="打开excel看看"></a>打开excel看看</h2><p>众所周知, xlsx文件其实外层是一个zip压缩格式, 用7z直接打开或将后缀名改为zip解压即可. docx和pptx也一样.<br>在<code>xl/workbook.xml</code>文件中, 可以看到如下内容</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">workbook</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://schemas.openxmlformats.org/spreadsheetml/2006/main&quot;</span> <span class="attr">xmlns:r</span>=<span class="string">&quot;http://schemas.openxmlformats.org/officeDocument/2006/relationships&quot;</span> <span class="attr">xmlns:mc</span>=<span class="string">&quot;http://schemas.openxmlformats.org/markup-compatibility/2006&quot;</span> <span class="attr">xmlns:x15</span>=<span class="string">&quot;http://schemas.microsoft.com/office/spreadsheetml/2010/11/main&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">fileVersion</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://schemas.openxmlformats.org/spreadsheetml/2006/main&quot;</span> <span class="attr">appName</span>=<span class="string">&quot;xl&quot;</span> <span class="attr">lastEdited</span>=<span class="string">&quot;6&quot;</span> <span class="attr">lowestEdited</span>=<span class="string">&quot;6&quot;</span> <span class="attr">rupBuild</span>=<span class="string">&quot;14420&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">workbookPr</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://schemas.openxmlformats.org/spreadsheetml/2006/main&quot;</span> <span class="attr">defaultThemeVersion</span>=<span class="string">&quot;124226&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bookViews</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://schemas.openxmlformats.org/spreadsheetml/2006/main&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">workbookView</span> <span class="attr">xWindow</span>=<span class="string">&quot;0&quot;</span> <span class="attr">yWindow</span>=<span class="string">&quot;0&quot;</span> <span class="attr">windowWidth</span>=<span class="string">&quot;17208&quot;</span> <span class="attr">windowHeight</span>=<span class="string">&quot;10512&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bookViews</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">sheets</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">sheet</span> <span class="attr">name</span>=<span class="string">&quot;A Material&quot;</span> <span class="attr">sheetId</span>=<span class="string">&quot;2&quot;</span> <span class="attr">state</span>=<span class="string">&quot;null&quot;</span> <span class="attr">r:id</span>=<span class="string">&quot;rId66cdf1e0-93bc-4c96-9369-4f0664e2752b&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">sheets</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">definedNames</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://schemas.openxmlformats.org/spreadsheetml/2006/main&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">definedName</span> <span class="attr">name</span>=<span class="string">&quot;_xlnm._FilterDatabase&quot;</span> <span class="attr">localSheetId</span>=<span class="string">&quot;0&quot;</span> <span class="attr">hidden</span>=<span class="string">&quot;1&quot;</span>&gt;</span>&#x27;A Material&#x27;!$A$1:$O$1<span class="tag">&lt;/<span class="name">definedName</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">definedNames</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">calcPr</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://schemas.openxmlformats.org/spreadsheetml/2006/main&quot;</span> <span class="attr">calcId</span>=<span class="string">&quot;0&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">workbook</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>可以看到sheet这个节点真的有属性state, 其值为null, 根据xlrd的标准来看, 这个值不对. 询问了测试人员, 没有对该文件修改, 从系统直接下载一份新的文件, 也是有这个属性. 至此基本实锤了是开发写错了.<br>那么, 开发又是怎么写错的呢? 我们再去看看java端的代码, 由于没有开发的代码库, 盲猜一下.</p>
<h2 id="溯源POI"><a href="#溯源POI" class="headerlink" title="溯源POI"></a>溯源POI</h2><p>在Java世界说到操作excel, POI是首选, 那么查看一下文档, 发现有几个可以操作sheet也是否可见的接口</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span>	<span class="title function_">setSheetHidden</span><span class="params">(<span class="type">int</span> sheetIx, <span class="type">boolean</span> hidden)</span></span><br><span class="line">Hide or unhide a sheet.</span><br><span class="line"><span class="keyword">void</span>	<span class="title function_">setSheetVisibility</span><span class="params">(<span class="type">int</span> sheetIx, SheetVisibility visibility)</span></span><br><span class="line">Hide or unhide a sheet.</span><br></pre></td></tr></table></figure>
<p>从入参来看, 不可能是setSheetHidden, 以为Java必须要设初始值, 而原始类型的hidden的值只能是true/false, 基本确定开发用的是下面的变量.<br>由于还没问开发, 目前就先到这里吧.</p>
<!--stackedit_data:
eyJoaXN0b3J5IjpbOTkwMjQ2MzU1LDcwNDkxNTEwOF19
-->]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title>工单分类-keras笔记</title>
    <url>/2018/12/04/ai/%E5%B7%A5%E5%8D%95%E5%88%86%E7%B1%BB-keras%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>之前参加公司内的文本分类（工单分类）比赛，记录中间过程。</p>
<span id="more"></span>

<h1 id="工具准备"><a href="#工具准备" class="headerlink" title="工具准备"></a>工具准备</h1><h2 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h2><p>Anaconda安装好后, 如果jupyter插件没有显示, 请确认是否安装到对应的环境里了</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 配置清华的源</span></span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls <span class="built_in">yes</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建虚拟环境</span></span><br><span class="line">conda create -n py3 python=3 ipykernel</span><br><span class="line"><span class="comment"># 激活环境</span></span><br><span class="line">conda activate py3</span><br><span class="line"><span class="comment"># 安装jupyter</span></span><br><span class="line">pip install -U jupyter</span><br><span class="line"><span class="comment"># 将环境写入ipython的kernel中</span></span><br><span class="line">python -m ipykernel install --user --name py3 --display-name <span class="string">&quot;py3&quot;</span></span><br><span class="line"><span class="comment"># 安装jupyter插件</span></span><br><span class="line">pip install jupyter_contrib_nbextensions</span><br><span class="line">jupyter contrib nbextension install --user</span><br><span class="line">pip install jupyter_nbextensions_configurator</span><br><span class="line">jupyter nbextensions_configurator <span class="built_in">enable</span> --user</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除环境</span></span><br><span class="line">deactivate</span><br><span class="line">conda <span class="built_in">env</span> remove -n py3</span><br><span class="line">conda remove -n py3 --all</span><br></pre></td></tr></table></figure>
<h2 id="远程访问jupyter"><a href="#远程访问jupyter" class="headerlink" title="远程访问jupyter"></a>远程访问jupyter</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jupyter notebook password</span><br><span class="line">jupyter notebook --generate-config</span><br><span class="line">vim xxx.py</span><br><span class="line">c.NotebookApp.ip=<span class="string">&#x27;0.0.0.0&#x27;</span></span><br><span class="line">c.NotebookApp.open_browser = False</span><br><span class="line"><span class="comment">#c.NotebookApp.port =8888 #可自行指定一个端口, 访问时使用该端口</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="pip配置"><a href="#pip配置" class="headerlink" title="pip配置"></a>pip配置</h2><ul>
<li>  Unix:<code>$HOME/.config/pip/pip.conf</code></li>
<li>  Mac:  <code>$HOME/Library/Application Support/pip/pip.conf</code></li>
<li>  Windows：<code>%APPDATA%\pip\pip.ini</code>，<code>%APPDATA%</code>的实际路径我电脑上是<code>C:\Users\user_xxx\AppData\Roaming</code>，可在cmd里执行<code>echo %APPDATA%</code>命令查看</li>
</ul>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[global]</span></span><br><span class="line"><span class="attr">proxy</span>=http://<span class="number">100.100</span>.<span class="number">154.250</span>:<span class="number">3128</span></span><br><span class="line"><span class="attr">index-url</span> = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"><span class="attr">trusted-host</span>=tuna.tsinghua.edu.cn</span><br></pre></td></tr></table></figure>
<h2 id="临时pip"><a href="#临时pip" class="headerlink" title="临时pip"></a>临时pip</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python.exe -m pip install numpy --proxy=<span class="string">&quot;proxy.com:8080&quot;</span></span><br></pre></td></tr></table></figure>

<h1 id="文本清洗"><a href="#文本清洗" class="headerlink" title="文本清洗"></a>文本清洗</h1><h2 id="术语实体"><a href="#术语实体" class="headerlink" title="术语实体"></a>术语实体</h2><p>有字典最好, 没有的话从训练集挖掘一下. 没啥作用</p>
<ol>
<li>按工单类型(标签)将工单内容连接在一起, 分词后做word count, 高频词汇中应该有术语, 添加到字典中, 让分词器不要清理.</li>
<li>分词之后直接tfidf扔线性分类器, 然后看被过滤的stop_word. 应该可以看CountVectorizer的高频词.</li>
</ol>
<h2 id="提取关键字"><a href="#提取关键字" class="headerlink" title="提取关键字"></a>提取关键字</h2><p>最后用的HanLP分词</p>
<ol>
<li>词频获取, jiaba.extract_tags</li>
<li>TextRank, jieba.textrank</li>
<li>jieba.cut(cut_all=True)</li>
<li>jieba.cut_for_search()</li>
<li>pseg.cut() 按词性过滤</li>
<li>pseg.cut() 按词性过滤后, 紧密关联, 按char划分取(1,8) gram</li>
</ol>
<h1 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras_preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line">texts = [<span class="string">&#x27;手机 偶尔 充 不 进 电&#x27;</span>, <span class="string">&#x27;酷狗 打开 提示 检测 不到 sd 卡&#x27;</span>, <span class="string">&#x27;平板 连接 wifi 无法 上网&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;华为 p 20 耗电 太快 \u200b\u200b&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;耗电 快 7月 中旬 网点 换 了 电池 现在 又 耗电 快 一早 上 两 小时 百分之 30 mate 8 全 网通 64 保外 付费 更换 的 保修期&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;p 20 电信卡 使用 通话质量 不好 ， 有 杂音&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;查询 长沙 的 售后 网点 地址 和 联系方式 手机 有 质量 问题 屏幕 与 机身 分离 了 没有人 为 导致 的 也 没有 摔 过&#x27;</span></span><br><span class="line"> <span class="string">&#x27;后 壳 碎裂&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;plus 标配 版 中国移动 全 网通 定制 版本 3 gb + 32 gb ( toronto-tl 10 ) trt-tl 10 充满 电 用 四 五小 时 ， 主要 看 视频&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;v 8 打电话 过程 中 断 移动&#x27;</span>]</span><br><span class="line"></span><br><span class="line">tt = Tokenizer(num_words=<span class="number">20</span>, oov_token=<span class="string">&#x27;&lt;/s&gt;&#x27;</span>)</span><br><span class="line">tt.fit_on_texts(texts)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(tt.word_counts),<span class="built_in">len</span>(tt.word_index))</span><br><span class="line">seq = tt.texts_to_sequences(texts)</span><br><span class="line"><span class="keyword">for</span> (a,b) <span class="keyword">in</span> <span class="built_in">zip</span>(texts, seq):</span><br><span class="line">    <span class="built_in">print</span>(a,b)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">104 105</span><br><span class="line">手机 偶尔 充 不 进 电 [4, 19, 1, 1, 1, 5]</span><br><span class="line">酷狗 打开 提示 检测 不到 sd 卡 [1, 1, 1, 1, 1, 1, 1]</span><br><span class="line">平板 连接 wifi 无法 上网 [1, 1, 1, 1, 1]</span><br><span class="line">华为 p 20 耗电 太快 ​​ [1, 6, 7, 2, 1, 1]</span><br><span class="line">耗电 快 7月 中旬 网点 换 了 电池 现在 又 耗电 快 一早 上 两 小时 百分之 30 mate 8 全 网通 64 保外 付费 更换 的 保修期 [2, 8, 1, 1, 9, 1, 10, 1, 1, 1, 2, 8, 1, 1, 1, 1, 1, 1, 1, 11, 12, 13, 1, 1, 1, 1, 3, 1]</span><br><span class="line">p 20 电信卡 使用 通话质量 不好 ， 有 杂音 [6, 7, 1, 1, 1, 1, 14, 15, 1]</span><br><span class="line">查询 长沙 的 售后 网点 地址 和 联系方式 手机 有 质量 问题 屏幕 与 机身 分离 了 没有人 为 导致 的 也 没有 摔 过后 壳 碎裂 [1, 1, 3, 1, 9, 1, 1, 1, 4, 15, 1, 1, 1, 1, 1, 1, 10, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1]</span><br><span class="line">plus 标配 版 中国移动 全 网通 定制 版本 3 gb + 32 gb ( toronto-tl 10 ) trt-tl 10 充满 电 用 四 五小 时 ， 主要 看 视频 [1, 1, 1, 1, 12, 13, 1, 1, 1, 16, 1, 16, 1, 17, 18, 1, 17, 18, 1, 5, 1, 1, 1, 1, 14, 1, 1, 1]</span><br><span class="line">v 8 打电话 过程 中 断 移动 [1, 11, 1, 1, 1, 1, 1]</span><br></pre></td></tr></table></figure>
<h2 id="观察"><a href="#观察" class="headerlink" title="观察"></a>观察</h2><ol>
<li>num_words参数限制了转换后的word_index为[1,20]</li>
<li>所有低频的词都认为是oov_token(</s>)了</li>
<li>统计词频的word_count比word_index少一项, 就是没有统计</s>的词频. 如果统计了, 应该是词频最高的词之一了.</li>
<li>实际上是将低频词(词频在前num_words开外)的词都认为是一个词(低频词), 在词向量里面用一个在0的正态分布随机向量代替, 即预训练权重中unk未知词.</li>
</ol>
<h1 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h1><p>在训练过程中, 常需要查看train/val的loss图, 看是否拟合/过拟合.</p>
<h2 id="训练过程中画图-TensorBoard"><a href="#训练过程中画图-TensorBoard" class="headerlink" title="训练过程中画图 TensorBoard"></a>训练过程中画图 TensorBoard</h2><p>新建一个类, 封装TensorBoard的callback, keras实现.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TrainValTensorBoard</span>(<span class="title class_ inherited__">TensorBoard</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, log_dir=<span class="string">&#x27;./logs&#x27;</span>, **kwargs</span>):</span><br><span class="line">        self.val_log_dir = os.path.join(log_dir, <span class="string">&#x27;validation&#x27;</span>)</span><br><span class="line">        training_log_dir = os.path.join(log_dir, <span class="string">&#x27;training&#x27;</span>)</span><br><span class="line">        <span class="built_in">super</span>(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_model</span>(<span class="params">self, model</span>):</span><br><span class="line">        <span class="keyword">if</span> context.executing_eagerly():</span><br><span class="line">            self.val_writer = tf.contrib.summary.create_file_writer(self.val_log_dir)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.val_writer = tf.summary.FileWriter(self.val_log_dir)</span><br><span class="line">        <span class="built_in">super</span>(TrainValTensorBoard, self).set_model(model)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_write_custom_summaries</span>(<span class="params">self, step, logs=<span class="literal">None</span></span>):</span><br><span class="line">        logs = logs <span class="keyword">or</span> &#123;&#125;</span><br><span class="line">        val_logs = &#123;k.replace(<span class="string">&#x27;val_&#x27;</span>, <span class="string">&#x27;&#x27;</span>): v <span class="keyword">for</span> k, v <span class="keyword">in</span> logs.items() <span class="keyword">if</span> <span class="string">&#x27;val_&#x27;</span> <span class="keyword">in</span> k&#125;</span><br><span class="line">        <span class="keyword">if</span> context.executing_eagerly():</span><br><span class="line">            <span class="keyword">with</span> self.val_writer.as_default(), tf.contrib.summary.always_record_summaries():</span><br><span class="line">                <span class="keyword">for</span> name, value <span class="keyword">in</span> val_logs.items():</span><br><span class="line">                    tf.contrib.summary.scalar(name, value.item(), step=step)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> name, value <span class="keyword">in</span> val_logs.items():</span><br><span class="line">                summary = tf.Summary()</span><br><span class="line">                summary_value = summary.value.add()</span><br><span class="line">                summary_value.simple_value = value.item()</span><br><span class="line">                summary_value.tag = name</span><br><span class="line">                self.val_writer.add_summary(summary, step)</span><br><span class="line">        self.val_writer.flush()</span><br><span class="line"></span><br><span class="line">        logs = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> logs.items() <span class="keyword">if</span> <span class="keyword">not</span> <span class="string">&#x27;val_&#x27;</span> <span class="keyword">in</span> k&#125;</span><br><span class="line">        <span class="built_in">super</span>(TrainValTensorBoard, self)._write_custom_summaries(step, logs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_train_end</span>(<span class="params">self, logs=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(TrainValTensorBoard, self).on_train_end(logs)</span><br><span class="line">        self.val_writer.close()</span><br></pre></td></tr></table></figure>
<p>使用上就在callbacks列表中加入类的实例即可.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.train <span class="keyword">import</span> AdamOptimizer</span><br><span class="line"></span><br><span class="line">tf.enable_eager_execution()</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train = x_train.reshape(<span class="number">60000</span>, <span class="number">784</span>)</span><br><span class="line">x_test = x_test.reshape(<span class="number">10000</span>, <span class="number">784</span>)</span><br><span class="line">x_train = x_train.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x_test = x_test.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x_train /= <span class="number">255</span></span><br><span class="line">x_test /= <span class="number">255</span></span><br><span class="line">y_train = y_train.astype(<span class="built_in">int</span>)</span><br><span class="line">y_test = y_test.astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">784</span>,)))</span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, optimizer=AdamOptimizer(), metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">10</span>,</span><br><span class="line">          validation_data=(x_test, y_test),</span><br><span class="line">          callbacks=[TrainValTensorBoard(write_graph=<span class="literal">False</span>)])</span><br></pre></td></tr></table></figure>
<h1 id="事后画图-keras的history"><a href="#事后画图-keras的history" class="headerlink" title="事后画图: keras的history"></a>事后画图: keras的history</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># define the function</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LossHistory</span>(keras.callbacks.Callback):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_train_begin</span>(<span class="params">self, logs=&#123;&#125;</span>):</span><br><span class="line">        self.losses = &#123;<span class="string">&#x27;batch&#x27;</span>: [], <span class="string">&#x27;epoch&#x27;</span>: []&#125;</span><br><span class="line">        self.accuracy = &#123;<span class="string">&#x27;batch&#x27;</span>: [], <span class="string">&#x27;epoch&#x27;</span>: []&#125;</span><br><span class="line">        self.val_loss = &#123;<span class="string">&#x27;batch&#x27;</span>: [], <span class="string">&#x27;epoch&#x27;</span>: []&#125;</span><br><span class="line">        self.val_acc = &#123;<span class="string">&#x27;batch&#x27;</span>: [], <span class="string">&#x27;epoch&#x27;</span>: []&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_batch_end</span>(<span class="params">self, batch, logs=&#123;&#125;</span>):</span><br><span class="line">        self.losses[<span class="string">&#x27;batch&#x27;</span>].append(logs.get(<span class="string">&#x27;loss&#x27;</span>))</span><br><span class="line">        self.accuracy[<span class="string">&#x27;batch&#x27;</span>].append(logs.get(<span class="string">&#x27;acc&#x27;</span>))</span><br><span class="line">        self.val_loss[<span class="string">&#x27;batch&#x27;</span>].append(logs.get(<span class="string">&#x27;val_loss&#x27;</span>))</span><br><span class="line">        self.val_acc[<span class="string">&#x27;batch&#x27;</span>].append(logs.get(<span class="string">&#x27;val_acc&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_epoch_end</span>(<span class="params">self, batch, logs=&#123;&#125;</span>):</span><br><span class="line">        self.losses[<span class="string">&#x27;epoch&#x27;</span>].append(logs.get(<span class="string">&#x27;loss&#x27;</span>))</span><br><span class="line">        self.accuracy[<span class="string">&#x27;epoch&#x27;</span>].append(logs.get(<span class="string">&#x27;acc&#x27;</span>))</span><br><span class="line">        self.val_loss[<span class="string">&#x27;epoch&#x27;</span>].append(logs.get(<span class="string">&#x27;val_loss&#x27;</span>))</span><br><span class="line">        self.val_acc[<span class="string">&#x27;epoch&#x27;</span>].append(logs.get(<span class="string">&#x27;val_acc&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss_plot</span>(<span class="params">self, loss_type</span>):</span><br><span class="line">        iters = <span class="built_in">range</span>(<span class="built_in">len</span>(self.losses[loss_type]))</span><br><span class="line">        <span class="comment">#创建一个图</span></span><br><span class="line">        plt.figure()</span><br><span class="line">        <span class="comment"># acc</span></span><br><span class="line">        plt.plot(iters, self.accuracy[loss_type], <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;train acc&#x27;</span>)<span class="comment">#plt.plot(x,y)，这个将数据画成曲线</span></span><br><span class="line">        <span class="comment"># loss</span></span><br><span class="line">        plt.plot(iters, self.losses[loss_type], <span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;train loss&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> loss_type == <span class="string">&#x27;epoch&#x27;</span>:</span><br><span class="line">            <span class="comment"># val_acc</span></span><br><span class="line">            plt.plot(iters, self.val_acc[loss_type], <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;val acc&#x27;</span>)</span><br><span class="line">            <span class="comment"># val_loss</span></span><br><span class="line">            plt.plot(iters, self.val_loss[loss_type], <span class="string">&#x27;k&#x27;</span>, label=<span class="string">&#x27;val loss&#x27;</span>)</span><br><span class="line">        plt.grid(<span class="literal">True</span>)<span class="comment">#设置网格形式</span></span><br><span class="line">        plt.xlabel(loss_type)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;acc-loss&#x27;</span>)<span class="comment">#给x，y轴加注释</span></span><br><span class="line">        plt.legend(loc=<span class="string">&quot;upper right&quot;</span>)<span class="comment">#设置图例显示位置</span></span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个实例LossHistory</span></span><br><span class="line">history = LossHistory()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.fit(X_train, Y_train,</span><br><span class="line">            batch_size=batch_size, nb_epoch=nb_epoch,</span><br><span class="line">            verbose=<span class="number">1</span>,</span><br><span class="line">            validation_data=(X_test, Y_test),</span><br><span class="line">            callbacks=[history])<span class="comment">#callbacks回调，将数据传给history</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history.loss_plot(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">history.loss_plot(<span class="string">&#x27;batch&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins 使用笔记</title>
    <url>/2018/04/25/ops/Jenkins%20%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>记录Jenkins上使用的经验，另外在公司内部使用Jenkins会遇到一些代理问题，记录一些解决方法。</p>
<span id="more"></span>

<h1 id="代理问题"><a href="#代理问题" class="headerlink" title="代理问题"></a>代理问题</h1><ol>
<li>配置代理后，由于默认使用https取插件仓库，切换为http协议即可<br>在<a href="http://localhost:8083/pluginManager/advanced%E4%B8%AD%EF%BC%8C%E5%8D%87%E7%BA%A7%E7%AB%99%E7%82%B9%E7%9A%84url%E5%8E%BB%E6%8E%89https%E7%9A%84s%EF%BC%8C%E7%94%A8http%E5%8D%8F%E8%AE%AE%EF%BC%8C%E7%84%B6%E5%90%8E%E6%8F%90%E4%BA%A4%E4%B8%80%E4%B8%8B%EF%BC%8C%E8%8E%B7%E5%8F%96%E4%B8%80%E4%B8%8B%E5%8F%AF%E9%80%89%E6%8F%92%E4%BB%B6">http://localhost:8083/pluginManager/advanced中，升级站点的url去掉https的s，用http协议，然后提交一下，获取一下可选插件</a></li>
<li>安装忽略ssl证书的插件<code>Skip Certificate Check</code></li>
<li><code>git plugin</code>需要配置忽略ssl：git config –global http.sslVerify “false”</li>
</ol>
<h1 id="常用插件"><a href="#常用插件" class="headerlink" title="常用插件"></a>常用插件</h1><ol>
<li>Subversion Plug-in 公司还在使用SVN，在Repository URL后记得加<code>@HEAD</code></li>
<li>Robot Framework plugin 集成RobotFramework的好插件</li>
<li>Build User Vars Plugin 将用户变为变量</li>
<li>Build Name Setter Plugin 可以将构建名中插入变量</li>
</ol>
<h1 id="WebHook-自动构建"><a href="#WebHook-自动构建" class="headerlink" title="WebHook 自动构建"></a>WebHook 自动构建</h1><h2 id="推送Jenkins自动构建"><a href="#推送Jenkins自动构建" class="headerlink" title="推送Jenkins自动构建"></a>推送Jenkins自动构建</h2><p>每次本地提交代码后, 还要到jenkins上点一下构建, 这很不先进.<br>git: gogs(docker)<br>jenkins: blue-ocean(docker)<br>ide: idea</p>
<p>实际上就是jenkins接收gogs发出的post请求, 所以才叫”web” hook</p>
<ol>
<li>jenkins安装插件gogs</li>
<li>jenkins项目配置-触发构建器选”Build when a change is pushed to Gogs”</li>
<li>在gogs的仓库设置中配置web hook, 密码可以不设, 其他默认, 地址如下格式:<blockquote>
<p><a href="http://10.75.76.163:8083/gogs-webhook/?job=AILog">http://10.75.76.163:8083/gogs-webhook/?job=AILog</a></p>
</blockquote>
</li>
</ol>
<h1 id="部署后启动启动远程服务器"><a href="#部署后启动启动远程服务器" class="headerlink" title="部署后启动启动远程服务器"></a>部署后启动启动远程服务器</h1><h2 id="免密登录"><a href="#免密登录" class="headerlink" title="免密登录"></a>免密登录</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">ssh-keygen <span class="comment">#一路回车即可</span></span><br><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub user@server</span><br></pre></td></tr></table></figure>

<h2 id="maven构建"><a href="#maven构建" class="headerlink" title="maven构建"></a>maven构建</h2><p>选择Invoke top-level Maven targets<br>package<br>-Dmaven.test.skip=true</p>
<h2 id="停止任务"><a href="#停止任务" class="headerlink" title="停止任务"></a>停止任务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh root@remote_host <span class="string">&quot;pkill -f ailog.jar &quot;</span> || <span class="literal">true</span></span><br><span class="line">scp <span class="variable">$&#123;WORKSPACE&#125;</span>/target/ailog.jar root@remote_host:/tmp/ailog.jar</span><br><span class="line">ssh root@remote_host <span class="string">&quot;cd /tmp; nohup java -jar -Dspring.profiles.active=prod /tmp/ailog.jar &gt; /tmp/ailog.log &amp;&quot;</span></span><br></pre></td></tr></table></figure>

<ol>
<li><code>|| true</code> 可以让该命令的执行结果返回成功, 让后续步骤可以继续</li>
<li>pkill -f可以匹配部分启动命令,然后kill之. 如果没有找到会返回失败</li>
<li>nohup &amp; 可以使进程后台执行. 重定向结果能让ssh马上返回<br>如果是本地执行命令, 需要这样:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pkill -f excelhelper || <span class="literal">true</span></span><br><span class="line">BUILD_ID=dontKillMe <span class="built_in">nohup</span> java -jar <span class="variable">$&#123;WORKSPACE&#125;</span>/excelhelper/target/excelhelper-1.0-SNAPSHOT.jar &gt; /tmp/excelhelper.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Zabbix 实践</title>
    <url>/2018/03/12/ops/Zabbix%20%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<h1 id="Zabbix实践"><a href="#Zabbix实践" class="headerlink" title="Zabbix实践"></a>Zabbix实践</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>zabbix安装需要3大块，server负责整理数据，agent采集数据，web负责展示与GUI配置。<br>server和web都依赖关系型数据库，这里以mysql为例，也是docker形式。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name mysql --restart=always \</span><br><span class="line">-v /home/tony/mysql_data:/var/lib/mysql \</span><br><span class="line">-p 3306:3306 \</span><br><span class="line">-e MYSQL_ROOT_PASSWORD=huawei123 \</span><br><span class="line">-d mysql:5.6</span><br></pre></td></tr></table></figure>
<h3 id="Server端"><a href="#Server端" class="headerlink" title="Server端"></a>Server端</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name zabbix-server-mysql --restart always \</span><br><span class="line">--<span class="built_in">link</span> mysql:mysql_host \</span><br><span class="line">-p 10051:10051 \</span><br><span class="line">-e DB_SERVER_HOST=<span class="string">&quot;mysql_host&quot;</span> \</span><br><span class="line">-e MYSQL_USER=<span class="string">&quot;root&quot;</span> \</span><br><span class="line">-e MYSQL_PASSWORD=<span class="string">&quot;huawei123&quot;</span> \</span><br><span class="line">-v /home/tony/zabbix/externalscripts:/usr/lib/zabbix/externalscripts \</span><br><span class="line">-d zabbix/zabbix-server-mysql</span><br></pre></td></tr></table></figure>
<h3 id="Web端"><a href="#Web端" class="headerlink" title="Web端"></a>Web端</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name zabbix-web-nginx-mysql \</span><br><span class="line">--restart always \</span><br><span class="line">--<span class="built_in">link</span> mysql:mysql_host \</span><br><span class="line">--<span class="built_in">link</span> zabbix-server-mysql:zabbix-server-mysql \</span><br><span class="line">-p 81:80 \</span><br><span class="line">-e DB_SERVER_HOST=<span class="string">&quot;mysql_host&quot;</span> \</span><br><span class="line">-e MYSQL_USER=<span class="string">&quot;root&quot;</span> \</span><br><span class="line">-e MYSQL_PASSWORD=<span class="string">&quot;huawei123&quot;</span> \</span><br><span class="line">-e ZBX_SERVER_HOST=<span class="string">&quot;zabbix-server-mysql&quot;</span> \</span><br><span class="line">-e PHP_TZ=<span class="string">&quot;Asia/Shanghai&quot;</span> \</span><br><span class="line">-v /home/tony/zabbix/msyh.ttf:/usr/share/zabbix/fonts/graphfont.ttf \</span><br><span class="line">-d zabbix/zabbix-web-nginx-mysql:latest</span><br></pre></td></tr></table></figure>
<h3 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h3><p>Agent用原生的rpm包安装，centos7.2下直接安装无依赖。生产环境要离线安装，找到以下仓库 <a href="http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/">http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/</a><br>笔者在编辑时候，版本号为3.4，<a href="http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-get-3.4.7-1.el7.x86_64.rpm">zabbix-get-3.4.7-1.el7.x86_64.rpm</a></p>
<blockquote>
<p>sudo rpm -ivh zabbix-get-3.4.7-1.el7.x86_64.rpm</p>
</blockquote>
<p>默认路径</p>
<blockquote>
<p>/etc/zabbix  #配置<br>/var/log/zabbix  #日志<br>sudo systemctl restart zabbix-agent.service    #systemd 重启</p>
</blockquote>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="判断进程是否存在、获取进程号"><a href="#判断进程是否存在、获取进程号" class="headerlink" title="判断进程是否存在、获取进程号"></a>判断进程是否存在、获取进程号</h3><p>使用UserParameter功能，能在agent端执行自定义命令，命令的返回值会送到server作为键值对应的数值。</p>
<h4 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h4><ol>
<li>在Agent端/etc/zabbix/zabbix_agentd.d/目录下新建参数自定义命令。<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/zabbix/zabbix_agentd.d/userparameter_script.conf</span><br><span class="line">UserParameter=ps[*],ps -ef | grep <span class="variable">$1</span> | grep -v zabbix | <span class="built_in">wc</span> -l</span><br><span class="line">UserParameter=pid[*],ps -ef | grep <span class="string">&quot;<span class="variable">$1</span>&quot;</span> | grep -v grep | sed -r <span class="string">&#x27;s/ +/ /g&#x27;</span> | <span class="built_in">cut</span> -d <span class="string">&quot; &quot;</span> -f 2</span><br></pre></td></tr></table></figure></li>
<li>在web端配置监控项，可以是active或passive，键值ps[NameNode]，对应地会在agent端执行命令ps -ef | grep NameNode | grep -v zabbix | wc -l</li>
<li>server端收到对应的返回值，正常来说是1。</li>
</ol>
<h3 id="Hadoop参数"><a href="#Hadoop参数" class="headerlink" title="Hadoop参数"></a>Hadoop参数</h3><h4 id="流程-1"><a href="#流程-1" class="headerlink" title="流程"></a>流程</h4><ol>
<li>server端执行外部检查，外部检查调用zabbix/externalscripts目录下执行系统命令（如调用 python get_dfs_info.py master1 50070）。</li>
<li>调用系统命令后，被调用程序应使用zabbix-sender给server端发送相关数据。<br>这里发送的是文本文件，每行一条记录，空格划分三列，第一列是被监控机器在web上显示的hostname，第二列是键值，第三列是具体的数据。</li>
<li>zabbix-server监控项用zabbix采集器，键值对应发送文件的第二列，数据类型要区分整数和字符串等。<h4 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Expecting the following arguments in order -</span></span><br><span class="line"><span class="comment"># &lt;host&gt; = hostname/ip-address of Hadoop cluster NameNode server.</span></span><br><span class="line"><span class="comment">#        This is made available as a macro in host configuration.</span></span><br><span class="line"><span class="comment"># &lt;port&gt; = Port # on which the NameNode metrics are available (default = 50070)</span></span><br><span class="line"><span class="comment">#        This is made available as a macro in host configuration.</span></span><br><span class="line"><span class="comment"># &lt;name_in_zabbix&gt; = Name by which the Hadoop NameNode is configured in Zabbix.</span></span><br><span class="line"><span class="comment">#        This is made available as a macro in host configuration.</span></span><br><span class="line"><span class="comment"># &lt;monitor_type&gt; is the parameter (NN or DFS) you want to monitor.</span></span><br><span class="line"><span class="comment">#--------------------------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">COMMAND_LINE=<span class="string">&quot;<span class="variable">$0</span> $*&quot;</span> </span><br><span class="line"><span class="built_in">export</span> SCRIPT_NAME=<span class="string">&quot;<span class="variable">$0</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">usage</span></span>() &#123;</span><br><span class="line">   <span class="built_in">echo</span> <span class="string">&quot;Usage: <span class="variable">$SCRIPT_NAME</span> &lt;host&gt; &lt;port&gt; &lt;name_in_zabbix&gt; &lt;monitor_type&gt;&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -ne 4 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    usage ;</span><br><span class="line">    <span class="built_in">exit</span> ;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># First 2 parameters are required for connecting to Hadoop NameNode</span></span><br><span class="line"><span class="comment"># The 3th parameter HADOOP_NAME_IN_ZABBIX is required to be sent back to Zabbix to identify the </span></span><br><span class="line"><span class="comment"># Zabbix host/entity for which these metrics are destined.</span></span><br><span class="line"><span class="comment"># The 4th parameter MONITOR_TYPE is to specify the type to monitoring(NN or DFS)</span></span><br><span class="line"><span class="comment">#--------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="built_in">export</span> CLUSTER_HOST=<span class="variable">$1</span></span><br><span class="line"><span class="built_in">export</span> METRICS_PORT=<span class="variable">$2</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_NAME_IN_ZABBIX=<span class="variable">$3</span></span><br><span class="line"><span class="built_in">export</span> MONITOR_TYPE=<span class="variable">$4</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Set the data output file and the log fle from zabbix_sender</span></span><br><span class="line"><span class="comment">#--------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="built_in">export</span> DATA_FILE=<span class="string">&quot;/tmp/<span class="variable">$&#123;HADOOP_NAME_IN_ZABBIX&#125;</span>_<span class="variable">$&#123;MONITOR_TYPE&#125;</span>.txt&quot;</span></span><br><span class="line"><span class="built_in">export</span> JSON_FILE=<span class="string">&quot;/tmp/<span class="variable">$&#123;HADOOP_NAME_IN_ZABBIX&#125;</span>_<span class="variable">$&#123;MONITOR_TYPE&#125;</span>.json&quot;</span></span><br><span class="line"><span class="built_in">export</span> BAK_DATA_FILE=<span class="string">&quot;/tmp/<span class="variable">$&#123;HADOOP_NAME_IN_ZABBIX&#125;</span>_<span class="variable">$&#123;MONITOR_TYPE&#125;</span>_bak.txt&quot;</span></span><br><span class="line"><span class="built_in">export</span> LOG_FILE=<span class="string">&quot;/tmp/<span class="variable">$&#123;HADOOP_NAME_IN_ZABBIX&#125;</span>.log&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Use python to get the metrics data from Hadoop NameNode and use screen-scraping to extract</span></span><br><span class="line"><span class="comment"># metrics. </span></span><br><span class="line"><span class="comment"># The final result of screen scraping is a file containing data in the following format -</span></span><br><span class="line"><span class="comment"># &lt;HADOOP_NAME_IN_ZABBIX&gt; &lt;METRIC_NAME&gt; &lt;METRIC_VALUE&gt;</span></span><br><span class="line"><span class="comment">#--------------------------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># python `dirname $0`/zabbix-hadoop.py $CLUSTER_HOST $METRICS_PORT $DATA_FILE $HADOOP_NAME_IN_ZABBIX $MONITOR_TYPE</span></span><br><span class="line">wget -q -O <span class="variable">$DATA_FILE</span> http://<span class="variable">$CLUSTER_HOST</span>:<span class="variable">$METRICS_PORT</span>/jmx?qry=Hadoop:*</span><br><span class="line"></span><br><span class="line">sh `<span class="built_in">dirname</span> <span class="variable">$0</span>`/JSON.sh -l &lt; <span class="variable">$DATA_FILE</span> &gt; <span class="variable">$JSON_FILE</span></span><br><span class="line"><span class="comment">#NN &gt; JvmMetrics</span></span><br><span class="line">heap_memory_used=<span class="string">&quot;`grep &#x27;MemHeapUsedM&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">heap_memory=<span class="string">&quot;`grep &#x27;MemHeapCommittedM&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">max_heap_memory=<span class="string">&quot;`grep &#x27;MemHeapMaxM&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">non_heap_memory_used=<span class="string">&quot;`grep &#x27;MemNonHeapUsedM&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">commited_non_heap_memory=<span class="string">&quot;`grep &#x27;MemNonHeapCommittedM&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">all_memory_used=`awk <span class="string">&#x27;BEGIN&#123;print $heap_memory_used + $non_heap_memory_used&#125;&#x27;</span>`</span><br><span class="line"><span class="comment">#NN &gt; NameNodeStatus</span></span><br><span class="line">namenode_state=<span class="string">&quot;`grep &#x27;tag.HAState&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line"><span class="comment">#NN &gt; NameNodeInfo</span></span><br><span class="line">start_time=<span class="string">&quot;`grep &#x27;BlockDeletionStartTime&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">hadoop_version=`grep <span class="string">&#x27;SoftwareVersion&#x27;</span> <span class="variable">$JSON_FILE</span> | sed -n <span class="string">&#x27;1,1p&#x27;</span> | <span class="built_in">cut</span> -f 2 | <span class="built_in">cut</span> -d \&quot; -f 2`</span><br><span class="line"><span class="comment"># DFS &gt; FSNamesystemState</span></span><br><span class="line">live_nodes=<span class="string">&quot;`grep &#x27;NumLiveDataNodes&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span> </span><br><span class="line">dead_nodes=<span class="string">&quot;`grep &#x27;NumDeadDataNodes&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span> </span><br><span class="line">decommissioning_nodes=<span class="string">&quot;`grep &#x27;NumDecommissioningDataNodes&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">under_replicated_blocks=<span class="string">&quot;`grep &#x27;UnderReplicatedBlocks&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line"><span class="comment"># DFS &gt; NameNodeInfo</span></span><br><span class="line">files_and_directorys=<span class="string">&quot;`grep &#x27;TotalFiles&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">blocks=<span class="string">&quot;`grep &#x27;TotalBlocks&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">configured_capacity=<span class="string">&quot;`grep &#x27;\&quot;Total\&quot;&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">dfs_used=<span class="string">&quot;`grep &#x27;CapacityUsed&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">dfs_used_persent=<span class="string">&quot;`grep &#x27;PercentUsed&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">non_dfs_used=<span class="string">&quot;`grep &#x27;NonDfsUsedSpace&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">dfs_remaining=<span class="string">&quot;`grep &#x27;Free&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">dfs_remaining_persent=<span class="string">&quot;`grep &#x27;PercentRemaining&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line">datanodes_usages=<span class="string">&quot;`grep &#x27;NodeUsage&#x27; <span class="variable">$JSON_FILE</span> | sed -n &#x27;1,1p&#x27; | cut -f 2`&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$HADOOP_NAME_IN_ZABBIX</span> heap_memory_used <span class="variable">$heap_memory_used</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> heap_memory <span class="variable">$heap_memory</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> max_heap_memory <span class="variable">$max_heap_memory</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> non_heap_memory_used <span class="variable">$non_heap_memory_used</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> commited_non_heap_memory <span class="variable">$commited_non_heap_memory</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> all_memory_used <span class="variable">$all_memory_used</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> namenode_state <span class="variable">$namenode_state</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> start_time <span class="variable">$start_time</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> hadoop_version <span class="variable">$hadoop_version</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> live_nodes <span class="variable">$live_nodes</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> dead_nodes <span class="variable">$dead_nodes</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> decommissioning_nodes <span class="variable">$decommissioning_nodes</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> under_replicated_blocks <span class="variable">$under_replicated_blocks</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> files_and_directorys <span class="variable">$files_and_directorys</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> blocks <span class="variable">$blocks</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> configured_capacity <span class="variable">$configured_capacity</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> dfs_used <span class="variable">$dfs_used</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> dfs_used_persent <span class="variable">$dfs_used_persent</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> non_dfs_used <span class="variable">$non_dfs_used</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> dfs_remaining <span class="variable">$dfs_remaining</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> dfs_remaining_persent <span class="variable">$dfs_remaining_persent</span></span></span><br><span class="line"><span class="string"><span class="variable">$HADOOP_NAME_IN_ZABBIX</span> datanodes_usages <span class="variable">$datanodes_usages</span>&quot;</span> &gt; <span class="variable">$DATA_FILE</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Check the size of $DATA_FILE. If it is not empty, use zabbix_sender to send data to Zabbix.</span></span><br><span class="line"><span class="comment">#--------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="keyword">if</span> [[ -s <span class="variable">$DATA_FILE</span> ]]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">   zabbix_sender -vv -z 127.0.0.1 -i <span class="variable">$DATA_FILE</span> 2&gt;&gt;<span class="variable">$LOG_FILE</span> 1&gt;&gt;<span class="variable">$LOG_FILE</span></span><br><span class="line">   <span class="built_in">echo</span>  -e <span class="string">&quot;Successfully executed <span class="variable">$COMMAND_LINE</span>&quot;</span> &gt;&gt;<span class="variable">$LOG_FILE</span></span><br><span class="line">   <span class="built_in">mv</span> <span class="variable">$DATA_FILE</span> <span class="variable">$BAK_DATA_FILE</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">&quot;OK&quot;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">&quot;Error in executing <span class="variable">$COMMAND_LINE</span>&quot;</span> &gt;&gt; <span class="variable">$LOG_FILE</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">&quot;ERROR&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># debug: sh cluster-hadoop-plugin.sh 10.41.236.209 50070 master1 DFS</span></span><br></pre></td></tr></table></figure>
<h4 id="监控项-示例"><a href="#监控项-示例" class="headerlink" title="监控项 示例"></a>监控项 <small>示例</small></h4>外部检查：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cluster-hadoop-plugin.sh <span class="variable">$&#123;HADOOP_NAMENODE_HOST&#125;</span> <span class="variable">$&#123;HADOOP_NAMENODE_METRICS_PORT&#125;</span> <span class="variable">$&#123;ZABBIX_NAME&#125;</span> DFS</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>监控项<br>Zabbix采集器：键值live_nodes </p>
<h2 id="如何调试"><a href="#如何调试" class="headerlink" title="如何调试"></a>如何调试</h2><h3 id="agent机器进入zabbix用户调试"><a href="#agent机器进入zabbix用户调试" class="headerlink" title="agent机器进入zabbix用户调试"></a>agent机器进入zabbix用户调试</h3><p>如果需要在被监控机器执行脚本获取监控数据，可以使用UserParameter功能，Agent将会在被监控机器上以zabbix用户执行对应的命令。经常会出现权限问题等，调试时需要切换用户，以下是切换用户的命令：</p>
<blockquote>
<p>sudo su -s /bin/bash zabbix</p>
</blockquote>
]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>连接池监控</title>
    <url>/2020/02/14/ops/%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9B%91%E6%8E%A7/</url>
    <content><![CDATA[<h1 id="连接池"><a href="#连接池" class="headerlink" title="连接池"></a>连接池</h1><p>数据源是各种数据库，甚至你可以认为excel都是一个数据源。连接池是为了复用连接数据源的链接的管理池。<br>连接池的监控可以反应一部分的业务高峰，形成告警。持续的监控指标也能作为应用崩溃的复盘数据。</p>
<h2 id="监控原理"><a href="#监控原理" class="headerlink" title="监控原理"></a>监控原理</h2><p>公司平台使用普罗米修斯采集Java暴露的JMX数据，作为产品研发团队，只需要在程序启动后，将每个数据源包装一个Listener，多个数据源打包成map，交给<code>MBeanExporter</code></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">MBeanExporter</span> <span class="variable">exporter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MBeanExporter</span>();</span><br><span class="line"><span class="comment">// 探测模式 0不自动 1当前IOC容器查找组件 2 根据的策略进行探测</span></span><br><span class="line">exporter.setAutodetectMode(<span class="number">0</span>);</span><br><span class="line">Map&lt;String, AtomikosDataSourceBean&gt; dataSources = <span class="literal">null</span>; <span class="comment">// 自行获取</span></span><br><span class="line">Map&lt;String, Object&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, Object&gt;();</span><br><span class="line"><span class="keyword">for</span> (String key : dataSources.keySet()) &#123;</span><br><span class="line">    <span class="type">AtomikosDataSourceBean</span> <span class="variable">dataSrouce</span> <span class="operator">=</span> dataSources.get(key);</span><br><span class="line">    <span class="type">DataSourceListener</span> <span class="variable">listener</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataSourceListener</span>(dataSrouce);</span><br><span class="line">    map.put(<span class="string">&quot;Catalina:type=DatasourceConnectionPool,name=&quot;</span> + dataSrouce.getUniqueResourceName(), listener);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">exporter.setBeans(map);</span><br><span class="line">exporter.afterPropertiesSet();</span><br><span class="line">exporter.afterSingletonsInstantiated();</span><br></pre></td></tr></table></figure>

<h2 id="指标设置"><a href="#指标设置" class="headerlink" title="指标设置"></a>指标设置</h2><p>样例代码中，指标的计算是这样的：<br>最大上限： maxSize<br>当前创建： poolSize（池中总连接）<br>空闲数： available（池中可用连接）<br>已使用： poolSize - available<br>利用率： (poolSize - available) / poolSize</p>
<p>一开始我是觉得不太合理，监控的时候，不太好监控。仔细思考一下，也可以组合一下用当前暴露的指标做监控：</p>
<ol>
<li>当前创建&gt;90 (硬指标，不方便)</li>
<li>利用率在多个采集周期都&gt;90% （持续高涨，当前创建数应该会增加）</li>
</ol>
<p>其实如果不是非常学院派，常人理解的指标应该是这样计算：<br>最大上限： maxSize<br>当前创建： poolSize<br>空闲数： maxSize - poolSize<br>已使用： poolSize - available<br>利用率： poolSize / maxSize</p>
]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title>亚马逊自动下单 Selenium 自动化</title>
    <url>/2018/08/20/projects/Amazon-automatic-order/</url>
    <content><![CDATA[<p>朋友老婆做亚马逊电商，总有人跟卖，做一个自动下单的工具，将部分入门的跟卖卖家的库存给买掉。新建账号，虚假付款信息，订单可以锁定数个小时。主要的诉求就是从注册购物付款，全自动。接口自动化因为安全和加密的原因，分析起来比较费劲，所以使用的GUI的自动化，选型用的是熟悉的Selenium而没用 puppeteer</p>
<span id="more"></span>

<h1 id="亚马逊自动下单-Selenium-自动化"><a href="#亚马逊自动下单-Selenium-自动化" class="headerlink" title="亚马逊自动下单 Selenium 自动化"></a>亚马逊自动下单 Selenium 自动化</h1><h2 id="业务流程"><a href="#业务流程" class="headerlink" title="业务流程"></a>业务流程</h2><p>跟大部分工程一样，都是从业务流程开始，有一个清楚的流程，能很好指导代码开发。</p>
<p>比如新注册用户会提示是否使用prime账号，如果研究业务流程的时候用老号就发现不了。自动化中间多出一个页面，就走不下去了</p>
<h2 id="Page-Object-山寨版"><a href="#Page-Object-山寨版" class="headerlink" title="Page Object 山寨版"></a>Page Object 山寨版</h2><p>没有完全使用标准的Page Object设计模式，只是将xpath提取为变量，在部分重复的页面（很少）抽象出有业务含义的动作。比如下面的填写收货地址</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Address</span>(<span class="title class_ inherited__">BaseSelenium</span>):</span><br><span class="line">    ADDRESS_BOOK_ENTRY_XPATH = <span class="string">&quot;//div[@id=&#x27;address-book-entry-0&#x27;]&quot;</span></span><br><span class="line">    DELIVER_BUTTON_PATH = ADDRESS_BOOK_ENTRY_XPATH + <span class="string">&quot;/div[contains(@class,&#x27;ship-to-this-address&#x27;)]/span/a&quot;</span></span><br><span class="line">    FULL_NAME_INPUT_XPATH = <span class="string">&quot;(//form)[1]//input[@id=&#x27;enterAddressFullName&#x27;]&quot;</span></span><br><span class="line">    ADDR_LINE_1_INPUT_XPATH = <span class="string">&quot;(//form)[1]//input[@id=&#x27;enterAddressAddressLine1&#x27;]&quot;</span></span><br><span class="line">    CITY_INPUT_XPATH = <span class="string">&quot;(//form)[1]//input[@id=&#x27;enterAddressCity&#x27;]&quot;</span></span><br><span class="line">    PROVINCE_SELECT_PATH = <span class="string">&quot;(//form)[1]//select[@id=&#x27;enterAddressStateOrRegion&#x27;]&quot;</span></span><br><span class="line">    PROVINCE_OPTION_PATH = <span class="string">&quot;(//form)[1]//select[@id=&#x27;enterAddressStateOrRegion&#x27;]/option[text()=&#x27;&#123;&#125;&#x27;]&quot;</span></span><br><span class="line">    POSTAL_INPUT_XPATH = <span class="string">&quot;(//form)[1]//input[@id=&#x27;enterAddressPostalCode&#x27;]&quot;</span></span><br><span class="line">    TEL_INPUT_ID = <span class="string">&quot;(//form)[1]//input[@id=&#x27;enterAddressPhoneNumber&#x27;]&quot;</span></span><br><span class="line">    SHIP_TO_THIS_ADDR = <span class="string">&quot;(//form)[1]//input[@name=&#x27;shipToThisAddress&#x27;]&quot;</span></span><br><span class="line">    SHIPPING_OPTIONS_CONTINUE_BUTTON = <span class="string">&quot;(//input[@type=&#x27;submit&#x27;])[1]&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, driver</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(driver)</span><br><span class="line"></span><br><span class="line">        self.cf = configparser.ConfigParser()</span><br><span class="line">        self.cf.read(<span class="string">&#x27;config.ini&#x27;</span>)</span><br><span class="line">        self.name = self.cf.get(<span class="string">&quot;buyer&quot;</span>, <span class="string">&quot;name&quot;</span>)</span><br><span class="line">        self.address = self.cf.get(<span class="string">&quot;buyer&quot;</span>, <span class="string">&quot;address&quot;</span>)</span><br><span class="line">        self.city = self.cf.get(<span class="string">&quot;buyer&quot;</span>, <span class="string">&quot;city&quot;</span>)</span><br><span class="line">        self.province = self.cf.get(<span class="string">&quot;buyer&quot;</span>, <span class="string">&quot;province&quot;</span>)</span><br><span class="line">        self.post = self.cf.get(<span class="string">&quot;buyer&quot;</span>, <span class="string">&quot;post&quot;</span>)</span><br><span class="line">        self.tel = self.cf.get(<span class="string">&quot;buyer&quot;</span>, <span class="string">&quot;tel&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">enter_shipping_address</span>(<span class="params">self</span>):</span><br><span class="line">        logger = get_logger(<span class="string">&#x27;addr&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> self._check_exists_by_xpath_with_wait(Address.ADDRESS_BOOK_ENTRY_XPATH, self.checking_wait):</span><br><span class="line">            logger.info(<span class="string">&quot;选择已有的地址&quot;</span>)</span><br><span class="line">            self._click_by_xpath(Address.DELIVER_BUTTON_PATH)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            logger.info(<span class="string">&quot;填写送货地址&quot;</span>)</span><br><span class="line">            self._input_by_xpath(Address.FULL_NAME_INPUT_XPATH, self.name)</span><br><span class="line">            self._input_by_xpath(Address.ADDR_LINE_1_INPUT_XPATH, self.address)</span><br><span class="line">            self._input_by_xpath(Address.CITY_INPUT_XPATH, self.city)</span><br><span class="line">            self._input_by_xpath(Address.POSTAL_INPUT_XPATH, self.post)</span><br><span class="line">            self._input_by_xpath(Address.TEL_INPUT_ID, self.tel)</span><br><span class="line">            self._click_by_xpath(Address.PROVINCE_SELECT_PATH)</span><br><span class="line">            self._click_by_xpath(Address.PROVINCE_OPTION_PATH.<span class="built_in">format</span>(self.province))</span><br><span class="line">            self._click_by_xpath(Address.SHIP_TO_THIS_ADDR)</span><br><span class="line">        <span class="comment"># choose your shipping options</span></span><br><span class="line">        logger.info(<span class="string">&quot;送货信息完毕，点击继续&quot;</span>)</span><br><span class="line">        self._click_by_xpath(Address.SHIPPING_OPTIONS_CONTINUE_BUTTON)</span><br></pre></td></tr></table></figure>

<h2 id="Selenium-简单封装"><a href="#Selenium-简单封装" class="headerlink" title="Selenium 简单封装"></a>Selenium 简单封装</h2><p>大部分操作都是点击和输入，还有大量就是判断页面元素是否存在。</p>
<p>又因为亚马逊是海外网站，访问速度非常感人，也很不稳定，所以在等待条件上也需要非常小心设计，大部分debug时间都在处理等待问题。</p>
<p>本来看着页面设计基本都有id和name，打算偷懒不用xpath，后面发现复杂的页面元素还是xpath出马，适用面广，以后再有这样的工程，就一个xpath打天下算了。</p>
<p>设计了两个超时时间，<code>implicitly_wait</code>和<code>checking_wait</code>，一个是默认的等待时间，用于等待页面加载一会需要操作的元素，另一个是用来检查元素是否存在，判断当前页面究竟是哪个，这种情况通常页面已经基本加载完成，所以比前者短一些。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> configparser</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoSuchElementException, TimeoutException</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BaseSelenium</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, driver</span>):</span><br><span class="line">        self._driver = driver</span><br><span class="line">        self.cf = configparser.ConfigParser()</span><br><span class="line">        self.cf.read(<span class="string">&#x27;config.ini&#x27;</span>)</span><br><span class="line">        self.implicitly_wait = <span class="built_in">int</span>(self.cf.get(<span class="string">&quot;selenium&quot;</span>, <span class="string">&quot;implicitly_wait&quot;</span>))</span><br><span class="line">        self.checking_wait = <span class="built_in">int</span>(self.cf.get(<span class="string">&quot;selenium&quot;</span>, <span class="string">&quot;checking_wait&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_wait_and_get_element_by_id</span>(<span class="params">self, <span class="built_in">id</span>, wait_in_sec=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">return</span> WebDriverWait(self._driver, wait_in_sec <span class="keyword">if</span> wait_in_sec <span class="keyword">else</span> self.implicitly_wait).until(</span><br><span class="line">            EC.visibility_of_element_located((By.ID, <span class="built_in">id</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_wait_and_get_element_by_xpath</span>(<span class="params">self, xpath, wait_in_sec=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">return</span> WebDriverWait(self._driver, wait_in_sec <span class="keyword">if</span> wait_in_sec <span class="keyword">else</span> self.implicitly_wait).until(</span><br><span class="line">            EC.visibility_of_element_located((By.XPATH, xpath)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_check_exists_by_id_without_wait</span>(<span class="params">self, <span class="built_in">id</span></span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self._driver.find_element_by_id(<span class="built_in">id</span>)</span><br><span class="line">        <span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_check_exists_by_xpath_with_wait</span>(<span class="params">self, xpath, wait_in_sec=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            WebDriverWait(self._driver, wait_in_sec <span class="keyword">if</span> wait_in_sec <span class="keyword">else</span> self.implicitly_wait).until(</span><br><span class="line">                EC.visibility_of_element_located((By.XPATH, xpath)))</span><br><span class="line">        <span class="keyword">except</span> (NoSuchElementException, TimeoutException):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_input_by_id</span>(<span class="params">self, <span class="built_in">id</span>, text</span>):</span><br><span class="line">        element = self._wait_and_get_element_by_id(<span class="built_in">id</span>)</span><br><span class="line">        element.send_keys(text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_click_by_id</span>(<span class="params">self, <span class="built_in">id</span></span>):</span><br><span class="line">        element = self._wait_and_get_element_by_id(<span class="built_in">id</span>)</span><br><span class="line">        element.click()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_input_by_xpath</span>(<span class="params">self, xpath, text</span>):</span><br><span class="line">        element = self._wait_and_get_element_by_xpath(xpath)</span><br><span class="line">        element.send_keys(text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_click_by_xpath</span>(<span class="params">self, xpath</span>):</span><br><span class="line">        element = self._wait_and_get_element_by_xpath(xpath)</span><br><span class="line">        element.click()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">go_url</span>(<span class="params">self, url</span>):</span><br><span class="line">        self._driver.get(url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_url</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._driver.current_url</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_wait_until_clickable_by_xpath</span>(<span class="params">self, xpath, wait_in_sec=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            WebDriverWait(self._driver, wait_in_sec <span class="keyword">if</span> wait_in_sec <span class="keyword">else</span> self.implicitly_wait).until(</span><br><span class="line">                EC.element_to_be_clickable((By.XPATH, xpath)))</span><br><span class="line">        <span class="keyword">except</span> (NoSuchElementException, TimeoutException):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_element_attribute_by_xpath</span>(<span class="params">self, xpath, attr_name, wait_in_sec=<span class="literal">None</span></span>):</span><br><span class="line">        element = self._wait_and_get_element_by_xpath(xpath, wait_in_sec)</span><br><span class="line">        <span class="keyword">return</span> element.get_attribute(attr_name)</span><br></pre></td></tr></table></figure>

<h2 id="获取邮箱OTP一次性密码"><a href="#获取邮箱OTP一次性密码" class="headerlink" title="获取邮箱OTP一次性密码"></a>获取邮箱OTP一次性密码</h2><p>自建邮件服务最方便，然后要多少账号就有多少账号，免注册邮箱。</p>
<p>用pop3协议，多次拉取确保最新邮件，用正则匹配6位数字就可以获得。</p>
<p>虽然设计3次最大重试次数，但是没触发过。</p>
<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>程序的配置项，打码平台的账号密码，永远一样的收货地址就放<code>config.ini</code>。每次都要更新的卖家和商品就放<code>pin.xlsx</code></p>
<h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><p>GUI自动化遇到异常的机会非常大，定义错误码（错误状态）往上层传递很重要。</p>
<p>用try-exception控制异常减少程序提前结束是非常必要的。</p>
<h2 id="打码平台"><a href="#打码平台" class="headerlink" title="打码平台"></a>打码平台</h2><p>验证码自己识别太难了，接入打码平台也不贵。500条1元试用，小包月也是几十块，够打了。</p>
<p>如果使用requests等库处理图片的保存，一定要<strong>设置超时</strong>，因为amazon有些云计算服务（图片）的链接一直打不开，程序表现就是卡死。</p>
<h2 id="浏览器优化"><a href="#浏览器优化" class="headerlink" title="浏览器优化"></a>浏览器优化</h2><p>主要流程打通后，不再需要观察页面元素而是通过日志来观察程序的流程时，可以尽情打开加速的配置了。</p>
<p>关闭图片加载，开启无头模式等，都能大大地加快程序运行时间，我觉得个puppeteer应该差不远了。</p>
<p>无头模式一定要设置窗口大小，不然默认的大小会让元素在窗口范围内不可见，所有等待条件都失败，具体表现为程序卡住一动不动，其实是在等待元素出现在窗口范围。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">open_chrome_driver</span>(<span class="params">buyer: Buyer</span>):</span><br><span class="line">    chrome_options = Options()</span><br><span class="line">    <span class="keyword">if</span> ConfigUtil.get_config_value_by_section_key_as_str(<span class="string">&quot;selenium&quot;</span>, <span class="string">&quot;headless&quot;</span>).strip().upper() == <span class="string">&quot;TRUE&quot;</span>:</span><br><span class="line">        chrome_options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">        chrome_options.add_argument(<span class="string">&#x27;--window-size=1080,3000&#x27;</span>)</span><br><span class="line">    <span class="comment"># 不加载图片</span></span><br><span class="line">    <span class="keyword">if</span> ConfigUtil.get_config_value_by_section_key_as_str(<span class="string">&quot;selenium&quot;</span>, <span class="string">&quot;disable_pic&quot;</span>).strip().upper() == <span class="string">&quot;TRUE&quot;</span>:</span><br><span class="line">        prefs = &#123;</span><br><span class="line">            <span class="string">&#x27;profile.default_content_setting_values&#x27;</span>: &#123;</span><br><span class="line">                <span class="string">&#x27;images&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        chrome_options.add_experimental_option(<span class="string">&#x27;prefs&#x27;</span>, prefs)</span><br><span class="line">        chrome_options.add_argument(<span class="string">&#x27;blink-settings=imagesEnabled=false&#x27;</span>)</span><br><span class="line">    chrome_options.add_argument(<span class="string">&#x27;--no-sandbox&#x27;</span>)</span><br><span class="line">    chrome_options.add_argument(<span class="string">&#x27;--disable-dev-shm-usage&#x27;</span>)</span><br><span class="line">    chrome_options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)  <span class="comment"># 谷歌文档提到需要加上这个属性来规避bug</span></span><br><span class="line">    <span class="keyword">with</span> chrome_driver_lock:  <span class="comment"># 同时打开chrome会报错，尽管user-data-dir不一样</span></span><br><span class="line">        driver = webdriver.Chrome(options=chrome_options)</span><br><span class="line">    <span class="keyword">return</span> driver</span><br></pre></td></tr></table></figure>



<h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><p>因为要求支持并发，以达到更快的买光库存，需要考虑的东西就多了</p>
<h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><p>使用多线程模型，没有用异步。</p>
<p>因为我是先完成了单线程版本，后续想修改少一些，用装饰器做同步控制</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">synchronized_self</span>(<span class="params">func</span>):</span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">        <span class="keyword">with</span> BuyerManager.lock:</span><br><span class="line">            <span class="keyword">return</span> func(*args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BuyerManager</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    lock = threading.Lock()</span><br><span class="line"> 	</span><br><span class="line"><span class="meta">    @synchronized_self</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_candidate_buyers</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> config_util.ConfigUtil.buyer_account_use_only_once():</span><br><span class="line">            valid_buyers = [x <span class="keyword">for</span> x <span class="keyword">in</span> self.buyers <span class="keyword">if</span> <span class="keyword">not</span> x.banned <span class="keyword">and</span> <span class="keyword">not</span> x.registered]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_buyers = [x <span class="keyword">for</span> x <span class="keyword">in</span> self.buyers <span class="keyword">if</span> <span class="keyword">not</span> x.banned]</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(valid_buyers) &gt; <span class="number">0</span>, <span class="string">&#x27;已无买家，程序结束&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> valid_buyers</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在打开的浏览器的时候，如果同时打开会造成会话错乱。明明已经做了数据目录的区分，同时看了源代码，每个会话也是独立的，但是不知道为什么后面还是串操作，input到了同个浏览器的会话。所以打开浏览器的时候，做了锁控制同步</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> chrome_driver_lock:  <span class="comment"># 同时打开chrome会报错，尽管user-data-dir不一样</span></span><br><span class="line">    driver = webdriver.Chrome(options=chrome_options</span><br><span class="line">                              <span class="comment"># , desired_capabilities=capabilities</span></span><br><span class="line">                              )</span><br></pre></td></tr></table></figure>

<h2 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h2><p>多线程不难，难的是要将每个线程划分清楚。什么时候可以终止</p>
<p>入参做好同步控制，不要重复。当某一个卖家已经没有库存了，此时线程池内其他线程都应该关掉收工了。但是线程开始了，比较难关闭，除非pthread等方式包装一层。此处只是把线程池中未开始的等待线程取消了。</p>
<p>假如线程池可以同时4个线程（abcd），当b率先完成任务，此时线程池内是aecd，后续的fghijk…都会被取消掉，可惜aecd这四个还是要继续执行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">buy_all</span>(<span class="params">xlsx_file</span>):</span><br><span class="line">    logger = get_logger(<span class="string">&quot;buy_all&quot;</span>)</span><br><span class="line">    bm = BuyerManager(xlsx_file)</span><br><span class="line">    sm = SellerManager(xlsx_file)</span><br><span class="line">    sellers = sm.get_sellers()</span><br><span class="line">    <span class="keyword">for</span> cur_seller <span class="keyword">in</span> sellers:</span><br><span class="line">        logger.info(<span class="string">&quot;正在处理卖家&#123;&#125;@&#123;&#125;&quot;</span>.<span class="built_in">format</span>(cur_seller.sku, cur_seller.name))</span><br><span class="line">        <span class="keyword">with</span> ThreadPoolExecutor(ConfigUtil.thread_num(), thread_name_prefix=<span class="string">&#x27;pool&#x27;</span>) <span class="keyword">as</span> pool:</span><br><span class="line">            result_list = [pool.submit(buy_one, cur_seller, x, bm) <span class="keyword">for</span> x <span class="keyword">in</span> bm.get_candidate_buyers()]</span><br><span class="line">            logger.info(<span class="string">&quot;买家&#123;&#125;个--&gt;卖家&#123;&#125;@&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(result_list), cur_seller.sku, cur_seller.name))</span><br><span class="line">            <span class="keyword">for</span> future <span class="keyword">in</span> as_completed(result_list):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> future.cancelled():</span><br><span class="line">                    result = future.result()</span><br><span class="line">                    logger.info(<span class="string">&quot;某一购买流程结束：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(result))</span><br><span class="line">                    <span class="keyword">if</span> result <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> result == PurchaseFlow.NO_STOCK:</span><br><span class="line">                        logger.info(<span class="string">&quot;卖家&#123;&#125;@&#123;&#125;已无库存，取消未执行的购买流程，已经开始的购买流程无法提前结束&quot;</span></span><br><span class="line">                                    .<span class="built_in">format</span>(cur_seller.sku, cur_seller.name))</span><br><span class="line">                        sm.set_seller_sold_out(cur_seller)</span><br><span class="line">                        [x.cancel() <span class="keyword">for</span> x <span class="keyword">in</span> result_list]</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">            logger.info(<span class="string">&quot;线程池结束shutdown&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="网速"><a href="#网速" class="headerlink" title="网速"></a>网速</h2><p>现在pc性能已经很好，但是出过带宽还是太小，以至于虽然想更快，开更多线程，但是开多了，页面元素加载就更加慢了，最终导致失败的机会更加大。</p>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>多线程或者或多进程后，日志打印会非常混乱，一般来说都按照线程来将日志打印到文件中。但是有部分公共服务的日志怎么知道是哪个线程的呢？</p>
<p>当前版本是每个方法中获取日志对象，根据线程的关键数据（买家名字）来起名。其实用传递日志对象应该更加合适</p>
]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Selenium</tag>
      </tags>
  </entry>
  <entry>
    <title>CDH平台数据同步方案</title>
    <url>/2022/02/18/projects/CDH%E5%B9%B3%E5%8F%B0%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<span id="more"></span>

<h1 id="功能描述"><a href="#功能描述" class="headerlink" title="功能描述"></a>功能描述</h1><p>CDH平台需要集成多个采集端的采样数据，采集端可能来自学校或公司，可能存在非校园网，网络不通情况。<br>采集端数据分目录存放，文件是csv格式。<br>平台侧需接收文件和文件夹，同时解析入库（MySQL）和HDFS（Hadoop分布式文件系统）。<br>集成采取定时任务形式，初步设定为每小时一次。</p>
<h1 id="概要设计"><a href="#概要设计" class="headerlink" title="概要设计"></a>概要设计</h1><h2 id="同步记录"><a href="#同步记录" class="headerlink" title="同步记录"></a>同步记录</h2><p>数据集成采取增量集成模式，需在平台侧记录哪些数据已经同步完成，哪些数据尚未同步，采集端程序每次仅传输未集成的新数据。</p>
<p>平台端增加表记录哪个目录已经集成，提供接口告诉采集端，哪些已经采集完成。</p>
<h2 id="采集端程序"><a href="#采集端程序" class="headerlink" title="采集端程序"></a>采集端程序</h2><p>采集端采用定时任务形式，任务开始会扫描数据目录下的文件夹，对比服务器上查询的同步记录，过滤未同步的文件夹。先对新目录进行zip压缩后通过Http接口上传到平台。采集端需要图形界面配置。 </p>
<h3 id="图形界面"><a href="#图形界面" class="headerlink" title="图形界面"></a>图形界面</h3><ol>
<li>定时任务间隔，单位分钟，整数输入框1个</li>
<li>配置数据目录，文件夹选择器1个</li>
<li>手动触发上传，按钮1个</li>
</ol>
<h1 id="报价"><a href="#报价" class="headerlink" title="报价"></a>报价</h1><ul>
<li>平台侧改造，增加表、增加接口、解析入口改造：100</li>
<li>采集端界面，pyqt界面工作量：200</li>
<li>采集端定时，定时任务和界面结合，兼容手动按钮：100</li>
<li>采集端上传，调用查询同步情况接口，开始上传：100</li>
<li>整体功能联调：100</li>
</ul>
<h1 id="跨网络传输方案"><a href="#跨网络传输方案" class="headerlink" title="跨网络传输方案"></a>跨网络传输方案</h1><h2 id="跨局域网点对点"><a href="#跨局域网点对点" class="headerlink" title="跨局域网点对点"></a>跨局域网点对点</h2><p>自己搭建zerotier或vpn，模拟局域网。————理论方案，尚未实践，需要公网ip服务器</p>
<p>公网ip服务器搭建中转点，采集端先上传到服务器，再下载到平台侧。————方案较复杂，实践过。</p>
<h2 id="跨网方案费用预计"><a href="#跨网方案费用预计" class="headerlink" title="跨网方案费用预计"></a>跨网方案费用预计</h2><p>服务器，腾讯云最小规格500多一年，一般熟人或新客有打折。</p>
<p>按中转的上传下载方案，程序和服务器配置方面要增加500元。</p>
]]></content>
  </entry>
  <entry>
    <title>远程控制内网设备</title>
    <url>/2021/01/29/projects/Remote-Controll-in-NAT/</url>
    <content><![CDATA[<p>家庭的路由器是刷的是openwrt，电视盒子刷的armbian，有时候想知道断网了没，内网的网络状态怎么样。这时候需要内网穿透，frp和zerotier都是使用目标，写个小东西做frpc的更新，上报一下在线状态。因为同时管理父母家里、老丈人家里、家乡等多个网络。因为之前做过一个命令推送的小项目，复用一下，用Golang先实现客户端，服务器端用Java的Netty框架，用protobuf协议。</p>
<span id="more"></span>

<h1 id="功能描述"><a href="#功能描述" class="headerlink" title="功能描述"></a>功能描述</h1><ol>
<li>启动时获取静态配置</li>
<li>上报存活状态</li>
<li>接收命令执行</li>
<li>动态升级</li>
</ol>
<h1 id="概要设计"><a href="#概要设计" class="headerlink" title="概要设计"></a>概要设计</h1><h2 id="配置获取"><a href="#配置获取" class="headerlink" title="配置获取"></a>配置获取</h2><p>时间：每分钟更新一次<br>配置格式：json<br>数据站点：<a href="https://gitee.com/Tony36051/nat-controll/raw/master/conf.json">https://gitee.com/Tony36051/nat-controll/raw/master/conf.json</a><br>动态reload到内存</p>
<h2 id="上报存活状态"><a href="#上报存活状态" class="headerlink" title="上报存活状态"></a>上报存活状态</h2><p>时间：一分钟上报一次<br>上报内容：</p>
<ol>
<li>主机名，hostname</li>
<li>内网ip，intranetIp</li>
<li>公网ip，publicIp</li>
<li>自定义名称，nickname</li>
<li>上报时间，reportTime</li>
<li>执行用户，runUser。判断命令可执行范围</li>
<li>二进制版本，version<br>服务器端回复：</li>
<li>机器id：nickname_hostname</li>
</ol>
<h2 id="命令推送"><a href="#命令推送" class="headerlink" title="命令推送"></a>命令推送</h2><p>时机：服务端推送<br>客户端收到后，返回ack。<br>下发内容：</p>
<ol>
<li>命令id，Long型</li>
<li>命令内容</li>
<li>机器id</li>
</ol>
<h2 id="命令执行"><a href="#命令执行" class="headerlink" title="命令执行"></a>命令执行</h2><p>时机：客户端收到命令后，立刻执行<br>客户端将命令原样进行系统调用，同步获取输出流和错误流，上报给服务器。<br>超时：无超时机制，如果一直在执行，则无返回。<br>阻塞：不阻塞，来一个命令开一个routine执行。必要时候接受reboot命令</p>
<h2 id="命令回执"><a href="#命令回执" class="headerlink" title="命令回执"></a>命令回执</h2><p>时机：命令执行完成后<br>上报内容：</p>
<ol>
<li>命令id</li>
<li>机器id</li>
<li>输出流</li>
<li>错误流</li>
</ol>
<h2 id="OTA"><a href="#OTA" class="headerlink" title="OTA"></a>OTA</h2><p>时机：命令推送或静态配置文件发现版本可更新<br>升级：启动升级程序，下载新版程序，停止&amp;删掉老程序，覆盖老程序，启动<br>上报：升级结果、自检结果</p>
<h1 id="接口设计"><a href="#接口设计" class="headerlink" title="接口设计"></a>接口设计</h1><h2 id="上报接口"><a href="#上报接口" class="headerlink" title="上报接口"></a>上报接口</h2><p>POST /mc/online<br>{<br>    “hostname”: “armbian”,<br>    “intranetIp”: “192.168.1.254”,<br>    “publicIp”: “100.100.123.123”,<br>    “nickname”: “hometown”,<br>    “reportTime”: “2021-01-30 16:35:02”,<br>    “runUser”: “root”,<br>    “version”: “v20210130.1”<br>}<br>{<br>    “machineId”: “hometown_armbian”<br>}</p>
<h2 id="命令下发"><a href="#命令下发" class="headerlink" title="命令下发"></a>命令下发</h2><p>POST /mc/cmd<br>{<br>    “cmd”: “date”,<br>    “machineId”: “hometown_armbian”<br>}<br>{<br>    “recvTime”: “2021-01-30 16:35:02”,<br>    “machineId”: “hometown_armbian”,<br>    “cmdId”: 123456789<br>}</p>
<h2 id="命令结果收集"><a href="#命令结果收集" class="headerlink" title="命令结果收集"></a>命令结果收集</h2><p>PUT /mc/cmd<br>{<br>    “cmdId”: 123456789,<br>    “output”: “xxxxxxxxxxxxxxxxxx”,<br>    “error”: “yyyyyyyyyyyyyyyyy”,<br>    “durationInSec”: “10”<br>}</p>
]]></content>
  </entry>
  <entry>
    <title>返现业务逻辑</title>
    <url>/2021/02/26/projects/cashback/</url>
    <content><![CDATA[<p>返现逻辑。</p>
<span id="more"></span>

<h1 id="大致流程"><a href="#大致流程" class="headerlink" title="大致流程"></a>大致流程</h1><h2 id="管理员"><a href="#管理员" class="headerlink" title="管理员"></a>管理员</h2><p>流程： 管理页面入口-配置商品的返现规则-用密码保存</p>
<ol>
<li>从给定的URL进入，url部分包括账号和密码，正确才能进入</li>
<li>展示已有的返现规则，表格形式，可以新增、删除、编辑</li>
<li>保存按钮需要重新输入密码</li>
</ol>
<h2 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h2><p>流程：用户页面入口-输入订单-确定-返回成功返现或错误信息</p>
<ol>
<li>用户入口进入后，只有一个订单输入框，一个确定按钮</li>
<li>确定后返回成功，或失败的原因。</li>
</ol>
<h1 id="业务规则"><a href="#业务规则" class="headerlink" title="业务规则"></a>业务规则</h1><ol>
<li>一个商品只能有一个规则</li>
<li>无规则不返现</li>
<li>订单不匹配不返现</li>
<li>订单只能返现一次</li>
<li>规则种类：固定、比例</li>
<li><code>固定</code>的参数：安卓固定金额(aFix)、苹果固定金额(iFix)</li>
<li><code>比例</code>的参数：安卓比例(aRate)、苹果比例(iRate)</li>
<li>固定金额(fixCashback)=安卓或苹果的固定金额</li>
<li>比例金额(rateCashback)=aRate*订单金额 或 iRate*订单金额</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>RobotFramework 前端内存泄漏测试</title>
    <url>/2019/04/25/Automation/Robotframework/RobotFramework%20%E5%89%8D%E7%AB%AF%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<h1 id="前端内存泄漏-威力加强版"><a href="#前端内存泄漏-威力加强版" class="headerlink" title="前端内存泄漏 - 威力加强版"></a>前端内存泄漏 - 威力加强版</h1><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>前端应用越来越复杂，反复操作可能导致dom或js对象没有被正确回收，导致内存占用持续高位。</p>
<h2 id="测试原理"><a href="#测试原理" class="headerlink" title="测试原理"></a>测试原理</h2><ul>
<li>Selenium 控制浏览器反复操作</li>
<li>psutil 获取操作系统层面的内存占用</li>
<li>window.performance.memory 获取浏览器V8引擎级别js堆内存使用情况（chrome only）</li>
<li>openpyxl 记录到excel</li>
<li>robotframework 包装降低学习成本</li>
</ul>
<pre class="mermaid">graph LR
    A[Robot framework/Selenium] --pid--> B[pstutil]
    A --获取pid--> C[chromedriver]
    A --执行js获取内存占用-->C
    B --获取所有子进程chrome的pid--> A
    B --chrome进程的内存占用--> A</pre>


<pre class="mermaid">graph TD
    A[Selenium: 获取chromedriver进程号] --> B[psutil: 获取多个子进程chrome的进程号]
    B --> C[psutil: 获取子进程的内存占用]
    C --> D[chrome: 执行js获取js使用情况]</pre>

<h2 id="工程目录介绍"><a href="#工程目录介绍" class="headerlink" title="工程目录介绍"></a>工程目录介绍</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├─1-TestCase</span><br><span class="line">│      切换.txt</span><br><span class="line">│</span><br><span class="line">├─2-DOMElement</span><br><span class="line">│      commonVariable.txt</span><br><span class="line">│      HomePage.txt</span><br><span class="line">│</span><br><span class="line">├─3-Keywords</span><br><span class="line">│      CanvasAW.txt</span><br><span class="line">│      Common.txt</span><br><span class="line">│      CommonAction.txt</span><br><span class="line">│      CommonAssert.txt</span><br><span class="line">│      CommonDriver.txt</span><br><span class="line">│      CommonResolve.txt</span><br><span class="line">│      CommonWait.txt</span><br><span class="line">│      HomePage.txt</span><br><span class="line">│      MemLeak.txt</span><br><span class="line">│      UplSolo.txt</span><br><span class="line">│</span><br><span class="line">├─5-Extendlibrary</span><br><span class="line">│  │</span><br><span class="line">│  └─MemoryLeak</span><br><span class="line">│          MemoryUtils.py</span><br><span class="line">│          MemUsageExcel.py</span><br></pre></td></tr></table></figure>

<pre class="mermaid">graph LR
    切换.txt --> MemLeak.txt
    切换.txt --> UplSolo.txt
    MemLeak.txt --> MemUsageExcel.py
    MemUsageExcel.py --> MemoryUtils.py</pre>



<ul>
<li>UplSolo.txt：封装页面上的业务操作</li>
<li>MemLeak.txt：封装跟内存泄漏有关的动作，MemUsageExcel.py 所有的方法在此划分</li>
<li>MemUsageExcel.py：记录excel，调用MemoryUtils.py</li>
</ul>
<h2 id="曲折经历"><a href="#曲折经历" class="headerlink" title="曲折经历"></a>曲折经历</h2><h3 id="进程号变化导致写excel数据不对齐"><a href="#进程号变化导致写excel数据不对齐" class="headerlink" title="进程号变化导致写excel数据不对齐"></a>进程号变化导致写excel数据不对齐</h3><p>记录一开始的chrome进程，后续新增的进程不管，死掉的进程默认为0</p>
<h3 id="精确内存需要在打开chrome时候新增参数"><a href="#精确内存需要在打开chrome时候新增参数" class="headerlink" title="精确内存需要在打开chrome时候新增参数"></a>精确内存需要在打开chrome时候新增参数</h3><h2 id="探讨"><a href="#探讨" class="headerlink" title="探讨"></a>探讨</h2><p>该方法是否真的能识别出内存泄漏？</p>
<ol>
<li>系统进程级别比js占用多很多</li>
<li>系统进程级别的内存可能随应用当前页面展示的内容不同而（自动地）有所回落</li>
<li>更进一步的分析就需要对数据进行分析了，后话了</li>
</ol>
<h2 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h2><p><a href="https://github.com/Tony36051/js-mem-leak-test/">https://github.com/Tony36051/js-mem-leak-test/</a></p>
]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>RobotFramework</tag>
      </tags>
  </entry>
  <entry>
    <title>RobotFramework入门级概览</title>
    <url>/2018/09/22/Automation/Robotframework/RobotFramework%E5%85%A5%E9%97%A8%E7%BA%A7%E6%A6%82%E8%A7%88/</url>
    <content><![CDATA[<p>基于RobotFramework官方的Quick Start简化而成, 包括了安装, 编写, 执行, 查看等基本流程.</p>
<span id="more"></span>

<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><blockquote>
<p>pip install robotframework</p>
<p>pip install docutils  # 可选</p>
</blockquote>
<h1 id="编写"><a href="#编写" class="headerlink" title="编写"></a>编写</h1><p>测试目标是一个登陆模块, 涵盖了注册/登陆/修改密码的命令行工具, 编写一个测试脚本对其功能进行验证.</p>
<p>测试脚本的官方术语叫测试数据(Test Data), 测试数据分为四个部分, Settings/Test Cases/Keywords/Variables. 每个部分以*号开始, 可以加任意空行提高可读性.</p>
<p>关键字和参数直接用两个或以上的空格分隔, 建议使用4个, 是否需要上下行对齐看个人洁癖情况.</p>
<p>Settings部分主要是引入库/资源文件/变量文件; 测试套的元数据如Setup/Teardown/timeout等; </p>
<p>Testcase就是用例, 用例内每行一个步骤, 每个步骤以关键字为核心, 关键字右侧是关键字的参数, 左侧是关键字的返回.</p>
<p>Keywords是用户自定义的由其他关键字组成的更高抽象层次的关键字, 可以设定参数和返回值.</p>
<p>Variables是该常量定义区, 里面也可以使用系统内建的变量.</p>
<p>以下用例针登录模块的部分测试用例的实现, 本文并不会详细展开实现细节, 将在后续文章逐渐涉及.</p>
<p><code>overview.robot</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*** Settings ***</span><br><span class="line">Library    OperatingSystem</span><br><span class="line">Suite Setup    Clear database</span><br><span class="line"></span><br><span class="line">*** Test Cases ***</span><br><span class="line">Login with nobody</span><br><span class="line">    $&#123;resp&#125;    Login    nobody    P4ssw0rd</span><br><span class="line">    should be equal as strings    $&#123;resp&#125;    Access Denied</span><br><span class="line"></span><br><span class="line">Create and log in</span><br><span class="line">    $&#123;resp&#125;    Create user  Tony    P4ssw0rd</span><br><span class="line">    should be equal  $&#123;resp&#125;    SUCCESS</span><br><span class="line">    $&#123;resp&#125;    Login          Tony  P4ssw0rd</span><br><span class="line">    should be equal as strings  $&#123;resp&#125;     Logged In</span><br><span class="line"></span><br><span class="line">*** Keywords ***</span><br><span class="line">Clear database</span><br><span class="line">    remove file     $&#123;database_path&#125;</span><br><span class="line"></span><br><span class="line">Run target</span><br><span class="line">    [Arguments]     $&#123;option&#125;   $&#123;username&#125;     $&#123;password&#125;     $&#123;new_password&#125;=$&#123;None&#125;</span><br><span class="line">    $&#123;full_path&#125;    set variable     $&#123;targets_dir&#125;$&#123;/&#125;login.py</span><br><span class="line">    $&#123;resp&#125;   run  python $&#123;full_path&#125; $&#123;option&#125; $&#123;username&#125; $&#123;password&#125;</span><br><span class="line">    [Return]  $&#123;resp&#125;</span><br><span class="line"></span><br><span class="line">Create user</span><br><span class="line">    [Arguments]  $&#123;username&#125;    $&#123;password&#125;</span><br><span class="line">    $&#123;resp&#125;  Run target  create  $&#123;username&#125;    $&#123;password&#125;</span><br><span class="line">    [Return]  $&#123;resp&#125;</span><br><span class="line"></span><br><span class="line">Login</span><br><span class="line">    [Arguments]  $&#123;username&#125;    $&#123;password&#125;</span><br><span class="line">    $&#123;resp&#125;  Run target  login    $&#123;username&#125;     $&#123;password&#125;</span><br><span class="line">    [Return]  $&#123;resp&#125;</span><br><span class="line"></span><br><span class="line">*** Variables ***</span><br><span class="line">$&#123;targets_dir&#125;      $&#123;CURDIR&#125;$&#123;/&#125;..$&#123;/&#125;targets</span><br><span class="line">$&#123;database_path&#125;    $&#123;temp_dir&#125;$&#123;/&#125;robotframework-quickstart-db.txt</span><br></pre></td></tr></table></figure>

<h1 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h1><p>RobotFramework3使用robot作为主要命令, 旧版2.9及以前使用pybot作为主要执行命令, 功能一致. 最基本的命令行格式robot &lt;脚本路径&gt;</p>
<p>假设使用本文提供的样例脚本, git clone <strong>XXXX</strong></p>
<p><img src="%E6%89%A7%E8%A1%8C.png" alt="执行截图"></p>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>测试用例执行后, 首先生成的是xUnit兼容的xml文件, 里面记录了测试执行的输出, 然后从output.xml文件中解析生成用于调试查看的<code>log.html</code>和查看整体结果的<code>report.html</code>报告文件.</p>
<h1 id="被测对象-login-py"><a href="#被测对象-login-py" class="headerlink" title="被测对象 login.py"></a>被测对象 login.py</h1><p>程序来源: <a href="https://github.com/robotframework/QuickStartGuide">https://github.com/robotframework/QuickStartGuide</a></p>
<p>该程序是RobotFramework官方Quick Start教程的被测程序, 以下简单说明其功能.</p>
<p>该程序是一个简单的用户登录例子, 这是个命令行实现的验证程序, 允许调用者进行以下三个操作:</p>
<ul>
<li>用合规的密码创建用户</li>
<li>用有效的账号和密码登录</li>
<li>修改现有账号的密码</li>
</ul>
<p>以下是一些调用的实例:</p>
<p>不存在的用户使用合规的密码登录, 将得到一样的错误提示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; python sut/login.py login nobody P4ssw0rd</span><br><span class="line">Access Denied</span><br></pre></td></tr></table></figure>

<p>创建用户之后, 可以成功登录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; python sut/login.py create fred P4ssw0rd</span><br><span class="line">SUCCESS</span><br><span class="line"></span><br><span class="line">&gt; python sut/login.py login fred P4ssw0rd</span><br><span class="line">Logged In</span><br></pre></td></tr></table></figure>

<p>密码合规的验证规则: 7-12位, 必须包含大小写字母和数字, 但不允许包含特殊字符.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; python sut/login.py create fred short</span><br><span class="line">Creating user failed: Password must be 7-12 characters long</span><br><span class="line"></span><br><span class="line">&gt; python sut/login.py create fred invalid</span><br><span class="line">Creating user failed: Password must be a combination of lowercase and</span><br><span class="line">uppercase letters and numbers</span><br></pre></td></tr></table></figure>

<p>修改密码的用例:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; python sut/login.py change-password fred wrong NewP4ss</span><br><span class="line">Changing password failed: Access Denied</span><br><span class="line"></span><br><span class="line">&gt; python sut/login.py change-password fred P4ssw0rd short</span><br><span class="line">Changing password failed: Password must be 7-12 characters long</span><br><span class="line"></span><br><span class="line">&gt; python sut/login.py change-password fred P4ssw0rd NewP4ss</span><br><span class="line">SUCCESS</span><br></pre></td></tr></table></figure>

<p>该应用程序使用简单的”数据库”去保存用户的信息, 其实是保存在操作系统的临时文件所在的目录, 文件名默认为<code>robotframework-quickstart-db.txt</code></p>
]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>RobotFramework</tag>
      </tags>
  </entry>
  <entry>
    <title>RobotFramework变量</title>
    <url>/2018/09/26/Automation/Robotframework/RobotFramework%E5%8F%98%E9%87%8F/</url>
    <content><![CDATA[<p>自动化用例跟其他编程语言的源文件基本类似, 关键字类比方法或函数, 关键字的参数就是函数的参数, 关键字的返回也就是函数的返回. 类似编程学习, 第一步是学习定义和使用各种变量.</p>
<span id="more"></span>

<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>变量可以应用于脚本的绝大多数地方, 不过应用最多的还是在关键字的入参. 跟大多数编程语言一样, 变量不允许跟关键字重名.</p>
<p>常见用途:</p>
<ul>
<li>减少修改遗漏: 如果在大片用例都是硬编码的<code>user001</code>, 建议抽成变量${username}, 好处是修改时只需要改一处, 而不用担心漏改/改错.</li>
<li>定义系统无关的变量, 如将<code>127.0.0.1</code>修改为${HOST}, 然后通过命令行传入, 即可令测试脚本能无修改地跨系统执行, 免除因执行环境的变化而无谓的手工修改.</li>
<li>当脚本复杂到入参是一个对象, 而不是字符串时, 必须使用变量. 因为写在脚本中的参数, 都被认为是字符串(参考字符串连接).</li>
<li>参数传递, 上一个关键字的返回值作为下一个关键字的入参, 此时你需要变量</li>
<li>超长的值, 当某个参数是一个很大的json, 写起来非常长, 使用变量来代表是一个好方法.</li>
</ul>
<h1 id="变量类型"><a href="#变量类型" class="headerlink" title="变量类型"></a>变量类型</h1><p>变量跟关键字一样, 是<code>大小写无关</code>的, 同时忽略空格和下划线(${CURDIR}除外), 前者被认为不存在. 建议使用全大写代表全局变量(如: ${PATH}), 小写的驼峰或者蛇形作为局部变量(如: ${my_name}, ${contractNo}).</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">变量名忽略大小写/下划线/空格</span><br><span class="line">    $&#123;a_boy&#125;    set variable  tony</span><br><span class="line">    should be equal as strings  tony  $&#123;a_boy&#125;</span><br><span class="line">    should be equal as strings  tony  $&#123;A_boy&#125;</span><br><span class="line">    should be equal as strings  tony  $&#123;aboy&#125;</span><br><span class="line">    should be equal as strings  tony  $&#123;ABOY&#125;</span><br><span class="line">    LOG     $&#123;CURDIR&#125;  # 特殊例子</span><br></pre></td></tr></table></figure>



<p>一个变量由<code>类型标识符</code>($/@/&amp;/&amp;), 花括号({, }), 变量名组成, 变量名通常建议使用英文字母和数字下划线和空格组成. </p>
<h2 id="scalar标量"><a href="#scalar标量" class="headerlink" title="scalar标量"></a>scalar标量</h2><p>标量的类型标识符是$, 是最常用的一种, 经常代表一个字符串, 但其可以表示任一一个对象, 包括链表, 字典等. 以下为常量和变量的一个用法, 两个用例的Log结果是一致的.  <code>set variable</code>关键字可以认为跟python语言的<code>赋值=</code>一样作用, 这是创建变量的一个常用方法, 创建的是局部变量.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Scalar标量</span><br><span class="line">    $&#123;GREET&#125;    set variable  Hello</span><br><span class="line">    $&#123;NAME&#125;     set variable  world</span><br><span class="line">    Log    Hello, world!!           # 常量</span><br><span class="line">    Log    $&#123;GREET&#125;, $&#123;NAME&#125;!!      # 变量</span><br></pre></td></tr></table></figure>

<p>值得注意的一点是, 如果一个测试数据单元格内, 只有变量本身, 他可以代表一个对象. 一旦单元格内还有别的变量或常量, 则只会进行字符串拼接成一个字符串. 隐式地调用python对象的<code>__unicode__</code>或java对象的<code>toString()</code>方法将对象转为字符串, 然后跟单元格内其余部分拼接. 如果python的<code>__unicode__</code>方法失败, 将调用<code>__str__</code>方法.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*** Settings ***</span><br><span class="line">Library  ../ExtLibrarys/VarLibrary.py</span><br><span class="line"></span><br><span class="line">*** Test Cases ***</span><br><span class="line">字符串连接</span><br><span class="line">    [Documentation]  传参给关键字和函数需要注意, 连接后入参为字符串</span><br><span class="line">    $&#123;STR&#125;      set variable  Hello world!!</span><br><span class="line">    $&#123;str_type&#125;  get type    $&#123;STR&#125;                 # str类型</span><br><span class="line">    $&#123;list_type&#125;  get type    $&#123;LIST&#125;               # list类型, 使用@会展开为n个参数</span><br><span class="line">    $&#123;user1_type&#125;  get type  $&#123;user1&#125;                # dict类型,使用&amp;会展开为命名参数</span><br><span class="line">    $&#123;concat_str_type&#125;  get type  str: $&#123;STR&#125;       # str类型</span><br><span class="line">    $&#123;concat_list_type&#125;  get type  list: @&#123;LIST&#125;    # str类型</span><br><span class="line">    $&#123;concat_dict_type&#125;  get type  dict: &amp;&#123;user1&#125;   # str类型</span><br><span class="line">    should contain  $&#123;str_type&#125;  str</span><br><span class="line">    should contain  $&#123;list_type&#125;  list</span><br><span class="line">    should contain  $&#123;user1_type&#125;  dict</span><br><span class="line">    should contain  $&#123;concat_str_type&#125;  str</span><br><span class="line">    should contain  $&#123;concat_list_type&#125;  str</span><br><span class="line">    should contain  $&#123;concat_dict_type&#125;  str</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ../ExtLibrarys/VarLibrary.py</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_type</span>(<span class="params">obj</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(<span class="built_in">type</span>(obj))</span><br></pre></td></tr></table></figure>



<h2 id="List列表"><a href="#List列表" class="headerlink" title="List列表"></a>List列表</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">List列表变量</span><br><span class="line">    @&#123;user&#125;    create list  robot  secret</span><br><span class="line">    Login    robot    secret</span><br><span class="line">    Login   @&#123;user&#125;  # 等同上一个</span><br><span class="line"></span><br><span class="line">List变量关键字传参, 列表可扩展性</span><br><span class="line">    Show list    @&#123;LIST&#125;    more    args</span><br><span class="line">    Show list    $&#123;SCALAR&#125;    @&#123;LIST&#125;    constant</span><br><span class="line">    Show list    @&#123;LIST&#125;    @&#123;ANOTHER&#125;    @&#123;ONE MORE&#125;</span><br><span class="line"></span><br><span class="line">List变量访问, 变量索引</span><br><span class="line">    $&#123;index&#125;    set variable  1</span><br><span class="line">    Show list  @&#123;LIST&#125;[0]  @&#123;LIST&#125;[1]  @&#123;LIST&#125;[-1]</span><br><span class="line">    should be equal as strings  @&#123;LIST&#125;[$&#123;INDEX&#125;]  $&#123;LIST[$&#123;INDEX&#125;]&#125;  # 两种不同写法</span><br><span class="line">    </span><br><span class="line">*** Keywords ***</span><br><span class="line">Login</span><br><span class="line">    [Arguments]    $&#123;name&#125;  $&#123;password&#125;</span><br><span class="line">    should be equal as strings  $&#123;name&#125;  robot</span><br><span class="line">    should be equal as strings  $&#123;password&#125;  secret</span><br><span class="line"></span><br><span class="line">Show list</span><br><span class="line">    [Arguments]  @&#123;obj&#125;</span><br><span class="line">    Log  list: @&#123;obj&#125;</span><br><span class="line">    </span><br><span class="line">*** Variables ***</span><br><span class="line">$&#123;SCALAR&#125;    3.1415926</span><br><span class="line">@&#123;LIST&#125;     1st  2nd  3rd</span><br><span class="line">@&#123;ANOTHER&#125;  4th  5th</span><br><span class="line">@&#123;ONE MORE&#125;  6th</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>从例子可以看出, 可以将不定个数的参数封装为一个列表, 用于for循环或传参给关键字. </p>
<p>List变量的访问跟python语言中并无二致. 值得注意的是索引访问时, 如果认为LIST是标量, 则应该在索引写着花括号内; 如果认为LIST是列表, 则应该将索引卸载花括号外.</p>
<p>列表变量的创建可以从<code>create list</code>关键字, 变量定义部分, 方法返回, 甚至是环境变量, 命令行参数中获得.</p>
<h2 id="dict字典变量"><a href="#dict字典变量" class="headerlink" title="dict字典变量"></a>dict字典变量</h2><p>字典变量与列表变量非常类似, 甚至也是能迭代遍历.  在关键字参数传递时候, 如python函数传递一样, 参数按照顺序: <code>位置参数-列表参数-命名参数</code></p>
<p>字典的访问方式较为多样:</p>
<ul>
<li>&amp;{user1}[password]: 键值为常量</li>
<li>&amp;{user1}[${key}]: 键值为变量</li>
<li>${user1.key}: 属性访问</li>
<li>${user1[‘name’]}: robotframework2.9以前也可以用此方法, json也可以按此法</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Dict字典变量</span><br><span class="line">    $&#123;key&#125;  set variable  name</span><br><span class="line">    Login   password=secret  name=robot  # 命名参数, 顺序无关</span><br><span class="line">    Login   &amp;&#123;user1&#125;</span><br><span class="line">    Login   &amp;&#123;user1&#125;[$&#123;key&#125;]  &amp;&#123;user1&#125;[password]  # 还可以$&#123;user1.key&#125;</span><br><span class="line"></span><br><span class="line">Dict变量关键字传参, 可扩展性</span><br><span class="line">    Login  robot  &amp;&#123;password_part&#125;  # 如python, 位置参数-列表参数-命名参数</span><br><span class="line">    Login  &amp;&#123;name_part&#125;  password=secret   #合并</span><br><span class="line">    Login  &amp;&#123;name_part&#125;  &amp;&#123;password_part&#125;  #合并</span><br><span class="line"></span><br><span class="line">*** Variables ***</span><br><span class="line">&amp;&#123;user1&#125;     name=robot  password=secret</span><br><span class="line">&amp;&#123;name_part&#125;     name=robot</span><br><span class="line">&amp;&#123;password_part&#125;     password=secret</span><br></pre></td></tr></table></figure>

<p>如果是用pycharm/IDEA的插件IntelliBot, 目前版本还不能识别&amp;{}定义的变量被${}引用, 所以请忽略pycharm的错误提示.</p>
<h1 id="内建变量"><a href="#内建变量" class="headerlink" title="内建变量"></a>内建变量</h1><h2 id="系统变量"><a href="#系统变量" class="headerlink" title="系统变量"></a>系统变量</h2><table>
<thead>
<tr>
<th>Variable</th>
<th>解释</th>
<th>Explanation</th>
</tr>
</thead>
<tbody><tr>
<td>${CURDIR}</td>
<td>当前文件所在的目录的绝对路径</td>
<td>An absolute path to the directory where the test data file is located. This variable is case-sensitive.</td>
</tr>
<tr>
<td>${TEMPDIR}</td>
<td>系统临时文件的路径</td>
<td>An absolute path to the system temporary directory. In UNIX-like systems this is typically /tmp, and in Windows c:\Documents and Settings&lt;user&gt;\Local Settings\Temp.</td>
</tr>
<tr>
<td>${EXECDIR}</td>
<td>robot/pybot调用时所在目录</td>
<td>An absolute path to the directory where test execution was started from.</td>
</tr>
<tr>
<td>${/}</td>
<td>通用目录分割符</td>
<td>The system directory path separator. <code>/</code> in UNIX-like systems and \ in Windows.</td>
</tr>
<tr>
<td>${:}</td>
<td>通用环境路径分隔符</td>
<td>The system path element separator. <code>:</code> in UNIX-like systems and <code>;</code> in Windows.</td>
</tr>
<tr>
<td>${\n}</td>
<td>通用的换行符</td>
<td>The system line separator. \n in UNIX-like systems and \r\n in Windows. New in version 2.7.5.</td>
</tr>
</tbody></table>
<h2 id="布尔Boolean"><a href="#布尔Boolean" class="headerlink" title="布尔Boolean"></a>布尔Boolean</h2><p>默认情况下, 测试数据的每个格子都是字符串, 有些时候需传递布尔变量, 使用${true}和${false}, <code>大小写无关</code></p>
<h2 id="None和null"><a href="#None和null" class="headerlink" title="None和null"></a>None和null</h2><p>默认情况下, 测试数据的每个格子都是字符串, 有些时候需传递空值, 使用${None}和${null}, <code>大小写无关</code>, 互为别名, 可以交换使用. 因为使用python或Jython时会自动转换为正确的形式.</p>
<h2 id="空格和空字符串"><a href="#空格和空字符串" class="headerlink" title="空格和空字符串"></a>空格和空字符串</h2><p>Robotframework在解析测试数据时, 以两个或以上的空格为分隔符, 所以在真正的测试数据中使用多于一个空格需要转义. 而多次转义使得测试代码的可读性进一步下降, 所以可以使用${space * 4}表示4个空格.</p>
<p>如果需要表示空字符串, 需使用${EMPTY}.  这是错误的: <code>should be equal  $&#123;empty&#125;  &#39;&#39;</code></p>
<p>${SPACE}和${EMPTY}都是 <code>大小写无关</code>.</p>
<h2 id="数字变量"><a href="#数字变量" class="headerlink" title="数字变量"></a>数字变量</h2><p>默认情况下, 测试数据的每个格子都是字符串, 有些时候需传递数字变量, 使用${数字}等形式</p>
<ul>
<li><p>${80}</p>
</li>
<li><p>${3.14}</p>
</li>
<li><p>${-1e-4}: 也即 -0.0001</p>
</li>
<li><p>各种进制</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Example</span><br><span class="line">    Should Be Equal    $&#123;0b1011&#125;    $&#123;11&#125;   # 二进制</span><br><span class="line">    Should Be Equal    $&#123;0o10&#125;      $&#123;8&#125;    # 八进制</span><br><span class="line">    Should Be Equal    $&#123;0xff&#125;      $&#123;255&#125;  # 16进制</span><br><span class="line">    Should Be Equal    $&#123;0B1010&#125;    $&#123;0XA&#125;  # 二进制和16进制可以直接比较</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="元数据变量"><a href="#元数据变量" class="headerlink" title="元数据变量"></a>元数据变量</h2><p>如果需要获取一些跟测试数据或执行时变量, 可以考虑使用以下变量, 此处仅挑选较为常用的:</p>
<ul>
<li>${TEST NAME}</li>
<li>${SUITE NAME}</li>
<li>@{TEST TAGS}</li>
<li>${OUTPUT DIR}</li>
</ul>
<h1 id="优先级和作用域"><a href="#优先级和作用域" class="headerlink" title="优先级和作用域"></a>优先级和作用域</h1><h2 id="优先级"><a href="#优先级" class="headerlink" title="优先级"></a>优先级</h2><p>内建 &gt; 执行中赋值的 &gt;命令行 &gt; 测试用例文件 &gt; resource和variable文件</p>
<p>内建变量不允许覆盖, 但每次执行都会被重置, 类似Java的final变量, 一次定义不能修改. ${CURDIR}变量在执行过程中会不断变化, 其值为当前执行动作所在文件的目录的绝对路径.</p>
<p>资源文件如果引用别的资源文件, 多个文件中有同名变量, 本文件中的变量优先级较高.</p>
<p>命令行如果声明多个同名变量, 最后一个优先级高; <code>相反地</code>变量文件中, 最先声明/导入的变量拥有最高的优先级.</p>
<h2 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h2><ul>
<li>Global: 全局变量, 通常由命令行赋值, 建议首字母大写, 可以通过Set Global Variable修改.</li>
<li>Suite: 测试套级, 不可递归, 建议首字母大写, 可以通过Set Suite Variable修改</li>
<li>Test: 用例级, 建议首字母大写, 用例内所有步骤(keywords)可见, 可以通过Set Test Variable修改</li>
<li>Local: 本地变量, 建议全小写, 用于keyword的参数和返回值, 关键字外不可见,</li>
</ul>
<p>用例文件设置的变量文件可以在本文件内任何位置使用, 包括settings.</p>
<p>因为变量表(Variables)先被处理, 解析Settings/Variables路径时还没导入别的变量, 所以导入的变量不能在Settings/Variables中应用.</p>
<h1 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h1><h2 id="扩展语法"><a href="#扩展语法" class="headerlink" title="扩展语法"></a>扩展语法</h2><p>变量名的花括号内可以访问对象的属性和方法, 但不建议过度访问对象的方法. 如果访问的方法还需要入参, 更加不建议, 这会增加测试数据的复杂性, 减低可读性, 增加维护成本. 如果非要这样做, 建议挪到自定义keyword或自定义库中.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*** Settings ***</span><br><span class="line">Variables  ../Variables/vars.py  # 变量文件名不要跟类名一样</span><br><span class="line"></span><br><span class="line">*** Test Cases ***</span><br><span class="line">扩展语法:MyObject</span><br><span class="line">    Log    $&#123;OBJECT.name&#125;</span><br><span class="line">    Log    $&#123;OBJECT.eat(&#x27;Cucumber&#x27;)&#125;</span><br><span class="line">    Log    $&#123;DICTIONARY[2]&#125;</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ../Variables/vars.py  # 变量文件名不要跟类名一样</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyObject</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">eat</span>(<span class="params">self, what</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;%s eats %s&#x27;</span> % (self.name, what)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.name</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">OBJECT = MyObject(<span class="string">&#x27;Robot&#x27;</span>)</span><br><span class="line">DICTIONARY = &#123;<span class="number">1</span>: <span class="string">&#x27;one&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;two&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;three&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>与此类似的还可以对标准的python对象进行操作, 要想知道对应python对象可以有哪些方法和成员, <code>dir(obj)</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">扩展语法:String</span><br><span class="line">    $&#123;string&#125; =    Set Variable    abc</span><br><span class="line">    Log    $&#123;string.upper()&#125;      # Logs &#x27;ABC&#x27;</span><br><span class="line">    Log    $&#123;string * 2&#125;          # Logs &#x27;abcabc&#x27;</span><br><span class="line"></span><br><span class="line">扩展语法:Number</span><br><span class="line">    $&#123;number&#125; =    Set Variable    $&#123;-2&#125;</span><br><span class="line">    Log    $&#123;number * 10&#125;         # Logs -20</span><br><span class="line">    Log    $&#123;number.__abs__()&#125;    # Logs 2  # 会报错: $&#123;abs(number)&#125;, 变量名需紧跟&#123;</span><br></pre></td></tr></table></figure>

<h2 id="赋值"><a href="#赋值" class="headerlink" title="赋值"></a>赋值</h2><p>除了可以用<code>.</code>访问对象的属性和方法, 还可以给对象内的属性赋值.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">扩展语法:赋值</span><br><span class="line">    $&#123;OBJECT.name&#125; =    Set Variable    New name</span><br><span class="line">    $&#123;OBJECT.new_attr&#125; =    Set Variable    New attribute</span><br><span class="line">    should be equal as strings  $&#123;OBJECT&#125;  New name</span><br><span class="line">    should be equal as strings  $&#123;OBJECT.new_attr&#125;  New attribute</span><br></pre></td></tr></table></figure>

<h2 id="变量嵌套"><a href="#变量嵌套" class="headerlink" title="变量嵌套"></a>变量嵌套</h2><p>变量嵌套会从最内层开始替换为真实的值</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">扩展语法:嵌套</span><br><span class="line">    $&#123;OBJECT.name&#125; =    Set Variable    T-800</span><br><span class="line">    $&#123;key&#125; =    Set Variable    name</span><br><span class="line">    $&#123;T-800 HOME&#125;  set variable  /home/T-800</span><br><span class="line">    should be equal as strings  $&#123;OBJECT.$&#123;key&#125;&#125;  T-800</span><br><span class="line">    should be equal as strings  $&#123;$&#123;OBJECT.name&#125; HOME&#125;  /home/T-800</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>RobotFramework</tag>
      </tags>
  </entry>
  <entry>
    <title>RobotFramework实现Page Object设计模式的应用——GUI测试进阶</title>
    <url>/2018/04/17/Automation/Robotframework/RobotFramework%E5%AE%9E%E7%8E%B0Page%20Object%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%BA%94%E7%94%A8%E2%80%94%E2%80%94GUI%E6%B5%8B%E8%AF%95%E8%BF%9B%E9%98%B6/</url>
    <content><![CDATA[<p>第一次用RobotFramework-SeleniumLibrary写网页的GUI测试，封装关键字，按功能模块划分关键字。后来一次系统层面的UI重构，所有用例要重新写，成本很大，遂找到2013年提出，2015成熟的Page Object设计模式。基于页面或重用组件封装，仅将人类能交互的操作封装为方法。抽象后，可读性、可维护性大增。</p>
<span id="more"></span>
<h1 id="选型"><a href="#选型" class="headerlink" title="选型"></a>选型</h1><p>一开始选择的<a href="https://github.com/ncbi/robotframework-pageobjects">NCBI</a>的，文档详尽，功能较多，缺点是实现较复杂，坑是要指定对应的Selenium2Library的版本，对新的版本要改import，觉得不方便，什么还有别的问题。<br>后来选择使用较新的<a href="https://github.com/boakley/robotframework-pageobjectlibrary">boakley的实现</a>，实现上比较简单，功能与PageObject的意思都到了。缺点是没有完全按照PageObject的设计理念，方法返回值不一定是某页面或具体值，如果学院派地看，甚至可以说没有实现PageObject也是成立的。</p>
<h1 id="实战后总结"><a href="#实战后总结" class="headerlink" title="实战后总结"></a>实战后总结</h1><p><strong>2020-01-14 Updated</strong>：<br>PageObject定义页面和元素xpath关系即可，页面动作如果非必要，不用为某个页面定义动作。因为大部分的操作还是点击和输入，这个在更底层应该封装好。无论在RobotFramework还是纯代码实现上，都可遵从此原则</p>
<h1 id="实际项目举例"><a href="#实际项目举例" class="headerlink" title="实际项目举例"></a>实际项目举例</h1><h2 id="草稿"><a href="#草稿" class="headerlink" title="草稿"></a>草稿</h2><h3 id="commodityIndex-商品首页"><a href="#commodityIndex-商品首页" class="headerlink" title="commodityIndex 商品首页"></a>commodityIndex 商品首页</h3><ol>
<li>click_n_frame_contract(index) 点击第n个框架</li>
<li>search(key) 搜索</li>
<li>clear_search() 清除搜索</li>
<li>switch_row_display() 切换紧凑行显示</li>
<li>switch_col_display() 切换宽松列显示</li>
<li>click_n_pic(commodity_type) 该方法点击某类的第n个商品图片</li>
<li>test66 意大利TIM 配置按钮（按名字定位）</li>
<li>click_commodity_by_name(name) 点击商品名</li>
<li>click_n_more(commodity_type) 点击某个类型下的more、收起动作<h3 id="commodityIndexAll-商品首页（无左边栏）空的页面"><a href="#commodityIndexAll-商品首页（无左边栏）空的页面" class="headerlink" title="commodityIndexAll 商品首页（无左边栏）空的页面"></a>commodityIndexAll 商品首页（无左边栏）空的页面</h3></li>
</ol>
<h3 id="commodityDetails-商品详情页"><a href="#commodityDetails-商品详情页" class="headerlink" title="commodityDetails 商品详情页"></a>commodityDetails 商品详情页</h3><ol>
<li>get_product_id() 获取商品id</li>
<li>click_configuration_tab() 点击配置页</li>
<li>click_product_specification_tab() 点击规格页</li>
<li>add_n(n) 添加n个商品到购物车【输入框 限制】</li>
<li>click_customize() 点击客制化按钮</li>
<li>维保选择</li>
<li>test66能源店：多选基础服务，其他数量、描述超过4行<h3 id="commodityCustomize-商品定制化页"><a href="#commodityCustomize-商品定制化页" class="headerlink" title="commodityCustomize 商品定制化页"></a>commodityCustomize 商品定制化页</h3>该页定制化情况太多，不太好封装</li>
<li>input_name(name) </li>
<li>click_text(text) 根据文本内容点击配件，要搭配滚屏</li>
<li>input_num(text, n) 根据文本定位对应的输入框，输入数字</li>
<li>select_num(text, choice) 根据文本定位对应的输入框，下拉选择</li>
<li>view_result() 切换到定制结果</li>
<li>view_config()切回来</li>
<li>get_product_price() 获取定制结果的产品价格</li>
<li>get_Service_price() 获取定制结果的服务价格</li>
<li>add_n(n) 添加n个商品到购物车</li>
<li>参数正确性-协议</li>
<li>展开收缩<h3 id="commodityQuery"><a href="#commodityQuery" class="headerlink" title="commodityQuery"></a>commodityQuery</h3>暂不处理</li>
</ol>
<h2 id="common"><a href="#common" class="headerlink" title="common"></a>common</h2><p>可以按text来点击<br>太长或太宽，要先滚动<br>自定义商品参数正确性，建议使用协议</p>
<p>命名规范：<br>input_xxx<br>click_xxx<br>select_xxx<br>组合动作按实际业务命名<br>click_n_xxx：xxx取列头的名字，或类型</p>
]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>RobotFramework</tag>
        <tag>PageObject</tag>
      </tags>
  </entry>
  <entry>
    <title>RobotFramework执行镜像</title>
    <url>/2018/04/25/Automation/Robotframework/RobotFramework%E6%89%A7%E8%A1%8C%E9%95%9C%E5%83%8F/</url>
    <content><![CDATA[<p>团队使用RobotFramework作为主要自动化工具，将执行环境容器化，方便部署和扩展，以下为构建的Dockerfile</p>
<span id="more"></span>
<p>准备修改基础镜像，使其尺寸更小。同时考虑修改为python3<br>以下为疑似问题<br>1、尺寸大<br>2、python2字符问题<br>3、sqlite3有unicode问题<br>4、Jenkins（in docker）执行docker命令时，如果传参中文会报错,docker run rfwjs python <path contain chinese>/jobsubmit.py para1 para2</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</span><br><span class="line"># This container is made to execute RobotFramework test.</span><br><span class="line"># !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</span><br><span class="line"></span><br><span class="line">FROM devilrancy/robot-cx-python:2.7-slim</span><br><span class="line"></span><br><span class="line">MAINTAINER Wu Jiansong &lt;360517703@163.com&gt;</span><br><span class="line"></span><br><span class="line">ENV http_proxy=http://username:password@proxy.example.com:8080 \</span><br><span class="line">    https_proxy=http://username:password@proxy.example.com:8080 \</span><br><span class="line">    REMOTE_URL=http://100.100.154.250:4444/wd/hub</span><br><span class="line"></span><br><span class="line">RUN pip install -U pip \</span><br><span class="line">    requests \</span><br><span class="line">    selenium \</span><br><span class="line">    xlrd \</span><br><span class="line">    cx-Oracle \</span><br><span class="line">    pyhive \</span><br><span class="line">    pymysql \</span><br><span class="line">    robotframework \</span><br><span class="line">    dbbot \</span><br><span class="line">    robotframework-selenium2library \</span><br><span class="line">    robotframework-databaselibrary \</span><br><span class="line">    robotframework-requests \</span><br><span class="line">    robotframework-sshlibrary \</span><br><span class="line">    robotframework-excelLibrary &amp;&amp; \</span><br><span class="line">    sed -i &quot;s#formatting_info=True,##g&quot; /usr/local/lib/python2.7/site-packages/ExcelLibrary/ExcelLibrary.py &amp;&amp; \</span><br><span class="line">    sed -i &quot;s#remote_url=False#remote_url=&#x27;$REMOTE_URL&#x27;#g&quot; /usr/local/lib/python2.7/site-packages/SeleniumLibrary/keywords/browsermanagement.py &amp;&amp; \</span><br><span class="line">    echo &quot;\</span><br><span class="line">    def switch_base_url(self, alias, url):\n\</span><br><span class="line">        &#x27;&#x27;&#x27;\n\</span><br><span class="line">        change base_url of current session. add by w00406273\n\</span><br><span class="line">        &#x27;&#x27;&#x27;\n\</span><br><span class="line">        session = self._cache.switch(alias)\n\</span><br><span class="line">        session.url = url\n&quot;\</span><br><span class="line">    &gt;&gt; /usr/local/lib/python2.7/site-packages/RequestsLibrary/RequestsKeywords.py &amp;&amp; \</span><br><span class="line">    echo Asia/Shanghai &gt; /etc/timezone &amp;&amp; \</span><br><span class="line">    mv /etc/localtime /etc/localtime.bak &amp;&amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line"></span><br><span class="line">ENV http_proxy= \</span><br><span class="line">    https_proxy=</span><br></pre></td></tr></table></figure>

<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</span></span><br><span class="line"><span class="comment"># This container is made to execute RobotFramework test.</span></span><br><span class="line"><span class="comment"># !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> python:<span class="number">2.7</span>-slim</span><br><span class="line"></span><br><span class="line"><span class="keyword">MAINTAINER</span> Wu Jiansong &lt;<span class="number">360517703</span>@<span class="number">163</span>.com&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> REMOTE_URL=http://localhost:<span class="number">4444</span>/wd/hub</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install Ubuntu packages</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; apt-get install -y --no-install-recommends \</span></span><br><span class="line"><span class="language-bash">                alien \</span></span><br><span class="line"><span class="language-bash">                dpkg-dev \</span></span><br><span class="line"><span class="language-bash">                debhelper \</span></span><br><span class="line"><span class="language-bash">                build-essential \</span></span><br><span class="line"><span class="language-bash">                libaio1 \</span></span><br><span class="line"><span class="language-bash">                wget \</span></span><br><span class="line"><span class="language-bash">            &amp;&amp; <span class="built_in">rm</span> -rf /var/lib/apt/lists/* </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install oracle</span></span><br><span class="line"><span class="comment"># Reference: https://help.ubuntu.com/community/Oracle%20Instant%20Client</span></span><br><span class="line"><span class="comment"># Download RPM files from http://www.oracle.com/technetwork/topics/linuxx86-64soft-092277.html</span></span><br><span class="line"><span class="comment"># Get Oracle Client (this isn&#x27;t the offical download location, but at least it works without logging in!)</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> wget --no-check-certificate https://raw.githubusercontent.com/bumpx/oracle-instantclient/master/oracle-instantclient12.2-basiclite-12.2.0.1.0-1.x86_64.rpm \</span></span><br><span class="line"><span class="language-bash"></span></span><br><span class="line"><span class="comment"># Alien RPM package installer</span></span><br><span class="line"> &amp;&amp; alien -i *.rpm \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Cleaning up the packages downloaded</span></span><br><span class="line"> &amp;&amp; rm *.rpm \</span><br><span class="line"> &amp;&amp; apt-get purge -y --auto-remove wget alien</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">echo</span> <span class="string">&quot;/usr/lib/oracle/12.2/client64/lib/&quot;</span> &gt;&gt; /etc/ld.so.conf.d/oracle.conf \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; <span class="built_in">echo</span> <span class="string">&#x27;#!/bin/bash\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">export ORACLE_HOME=/usr/lib/oracle/12.2/client64\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">export PATH=$PATH:$ORACLE_HOME/bin&#x27;</span> &gt;&gt; /etc/profile.d/oracle.sh \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; <span class="built_in">chmod</span> +x /etc/profile.d/oracle.sh \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; /etc/profile.d/oracle.sh \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; ldconfig</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install -U pip \</span></span><br><span class="line"><span class="language-bash">    requests \</span></span><br><span class="line"><span class="language-bash">    selenium \</span></span><br><span class="line"><span class="language-bash">    xlrd \</span></span><br><span class="line"><span class="language-bash">    cx-Oracle \</span></span><br><span class="line"><span class="language-bash">    pyhive \</span></span><br><span class="line"><span class="language-bash">    pymysql \</span></span><br><span class="line"><span class="language-bash">    robotframework \</span></span><br><span class="line"><span class="language-bash">    dbbot \</span></span><br><span class="line"><span class="language-bash">    robotframework-selenium2library \</span></span><br><span class="line"><span class="language-bash">    robotframework-databaselibrary \</span></span><br><span class="line"><span class="language-bash">    robotframework-requests \</span></span><br><span class="line"><span class="language-bash">    robotframework-sshlibrary \</span></span><br><span class="line"><span class="language-bash">    robotframework-excelLibrary &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    sed -i <span class="string">&quot;s#formatting_info=True,##g&quot;</span> /usr/local/lib/python2.7/site-packages/ExcelLibrary/ExcelLibrary.py &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    sed -i <span class="string">&quot;s#remote_url=False#remote_url=&#x27;<span class="variable">$REMOTE_URL</span>&#x27;#g&quot;</span> /usr/local/lib/python2.7/site-packages/SeleniumLibrary/keywords/browsermanagement.py &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="built_in">echo</span> <span class="string">&quot;\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">    def switch_base_url(self, alias, url):\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">        &#x27;&#x27;&#x27;\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">        change base_url of current session. add by w00406273\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">        &#x27;&#x27;&#x27;\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">        session = self._cache.switch(alias)\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">        session.url = url\n&quot;</span>\</span></span><br><span class="line"><span class="language-bash">    &gt;&gt; /usr/local/lib/python2.7/site-packages/RequestsLibrary/RequestsKeywords.py &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="built_in">echo</span> Asia/Shanghai &gt; /etc/timezone &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="built_in">mv</span> /etc/localtime /etc/localtime.bak &amp;&amp; <span class="built_in">cp</span> /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>RobotFramework问题集锦</title>
    <url>/2019/04/24/Automation/Robotframework/RobotFramework%E9%97%AE%E9%A2%98%E9%9B%86%E9%94%A6/</url>
    <content><![CDATA[<h3 id="关键字默认参数是变量，也需要定义"><a href="#关键字默认参数是变量，也需要定义" class="headerlink" title="关键字默认参数是变量，也需要定义"></a>关键字默认参数是变量，也需要定义</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">登录</span><br><span class="line">    [Arguments]    $&#123;url&#125;=$&#123;Url_A3&#125;    $&#123;userName&#125;=$&#123;User_A3&#125;    $&#123;passWord&#125;=$&#123;Password_A3&#125;</span><br></pre></td></tr></table></figure>
<p>如果这里的<code>$&#123;Url_A3&#125;</code>没有定义，会报错<code>Non-existing variable &#39;$&#123;Url_A3&#125;&#39;.</code></p>
<h3 id="打开chromedriver时候，增加（命令行）参数"><a href="#打开chromedriver时候，增加（命令行）参数" class="headerlink" title="打开chromedriver时候，增加（命令行）参数"></a>打开chromedriver时候，增加（命令行）参数</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$&#123;args_list&#125;	Create List	user-data-dir=$&#123;OUTPUT DIR&#125;$&#123;/&#125;chrome_data	enable-precise-memory-info</span><br><span class="line">$&#123;chromeOptions&#125;	Create Dictionary	args	$&#123;args_list&#125;</span><br><span class="line">$&#123;cap_dict&#125;	Create Dictionary	chromeOptions	$&#123;chromeOptions&#125;</span><br><span class="line">Open Browser	$&#123;url&#125;	chrome	desired_capabilities=$&#123;cap_dict&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>RobotFramework</tag>
      </tags>
  </entry>
  <entry>
    <title>Aansible 启动 Tomcat，解决环境变量、执行后退出问题</title>
    <url>/2018/05/07/ops/Ansible/Aansible%20%E5%90%AF%E5%8A%A8%20Tomcat%EF%BC%8C%E8%A7%A3%E5%86%B3%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E3%80%81%E6%89%A7%E8%A1%8C%E5%90%8E%E9%80%80%E5%87%BA%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>作为团队QA角色，在环境搭建上使用ansible作为部署运维的自动化工具，在启动tomcat、presto、kylin时，遇到环境变量不对，无法启动；启动没报错但发现没有启动，发现进程启动了又退出了。本文简要记述相关原因与解决方案。</p>
<span id="more"></span>
<h1 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h1><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><blockquote>
<p>ansible调用playbook远程mvn执行打包时发现执行出错，找不到<code>JAVA_HOME</code></p>
</blockquote>
<blockquote>
<p>Please make sure the user has the privilege to run hbase shell</p>
</blockquote>
<h2 id="排查"><a href="#排查" class="headerlink" title="排查"></a>排查</h2><p>登录远程服务器执行env与ansible执行env命令，看到环境变量不一样</p>
<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>login shell 和 non-login shell的区别造成的，该情况还可能出现在ssh登录后执行命令。<br>具体分析请看：<a href="https://blog.csdn.net/u010871982/article/details/78525367">关于ansible远程执行的环境变量问题（login shell &amp; nonlogin shelll）</a><br>敲黑板，记笔记！</p>
<ul>
<li>login shell：取得bash时需要完整的登入流程的，就称为login shell。举例来说，你要由tty1~tty6登入，需要输入用户的账号和密码，此时取得的bash就称为『login shell』啰；  </li>
<li><strong>login shell加载环境变量的顺序</strong>：① /etc/profile ② ~/.bash_profile ③ ~/.bashrc ④ /etc/bashrc  </li>
</ul>
<hr>
<ul>
<li>non-login shell：取得bash接口的方法不需要重复登入的举动，举例来说，(1)你以Xwindow登入Linux后，再以X的图形化接口启动终端机，此时那个终端接口并没有需要再次的输入账号和密码，那个bash的环境就称为non-login shell了。(2)你在原本的bash环境下再次下达bash这个命令，同样的也没有输入账号密码，那第二个bash (子程序)也是non-login shell 。</li>
<li><strong>non-login shell加载环境变量的顺序</strong>： ① ~/.bashrc ② /etc/bashrc<h2 id="解决方案和建议"><a href="#解决方案和建议" class="headerlink" title="解决方案和建议"></a>解决方案和建议</h2></li>
</ul>
<ol>
<li>将环境变量写到<code>~/.bashrc</code>【推荐，一步解决】</li>
<li>在ssh中先source后再执行命令；在ansible中用shell模块source后再执行。说明：shell后的第一个<code>.</code>默认指/bin/sh。<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">source</span> <span class="string">~/.bash_profile</span> <span class="string">and</span> <span class="string">run</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">.</span> <span class="string">/home/username/.bashrc</span> <span class="string">&amp;&amp;</span> [<span class="string">the</span> <span class="string">actual</span> <span class="string">command</span> <span class="string">you</span> <span class="string">want</span> <span class="string">run</span>]</span><br></pre></td></tr></table></figure></li>
<li>用sudo -i 模拟<code>login shell</code>，ansible_user_id可以为user_id或user_name<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">source</span> <span class="string">bashrc</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sudo</span> <span class="string">-iu</span> &#123;&#123;<span class="string">ansible_user_id</span>&#125;&#125; [<span class="string">the</span> <span class="string">actual</span> <span class="string">command</span> <span class="string">you</span> <span class="string">want</span> <span class="string">run</span>]</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h1 id="启动后没有进程"><a href="#启动后没有进程" class="headerlink" title="启动后没有进程"></a>启动后没有进程</h1><h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>ansible-playbook执行没有报错，但应用却没有启动。</p>
<h2 id="排查-1"><a href="#排查-1" class="headerlink" title="排查"></a>排查</h2><p>在启动的过程中，开另外的窗口，<code>ps -ef | grep kylin</code>观察到有启动的进程，但后来又消失了。</p>
<h2 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h2><p>ansible应该是fork进程来执行脚本，执行后ansible退出父进程，子进程也同时被关闭掉</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>nohup一下即可</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">nohup</span> /home/hadoop/soft/kylin/bin/kylin.sh start &amp;</span><br></pre></td></tr></table></figure>
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyMjY1NjE5MTNdfQ==
-->]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Aansible</tag>
        <tag>SSH</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible 注释或取消注释配置文件行</title>
    <url>/2018/03/07/ops/Ansible/Ansible%20%E6%B3%A8%E9%87%8A%E6%88%96%E5%8F%96%E6%B6%88%E6%B3%A8%E9%87%8A%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A1%8C/</url>
    <content><![CDATA[<h1 id="Ansible-注释或取消注释配置文件行"><a href="#Ansible-注释或取消注释配置文件行" class="headerlink" title="Ansible 注释或取消注释配置文件行"></a>Ansible 注释或取消注释配置文件行</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>使用replace或lineinfile文件处理多行或单行配置文件，进行注释或解除注释</p>
<h3 id="原始文件"><a href="#原始文件" class="headerlink" title="原始文件"></a>原始文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> /etc/zabbix/zabbix_agentd.conf</span><br><span class="line"><span class="comment">### Option: EnableRemoteCommands</span></span><br><span class="line"><span class="comment">#       Whether remote commands from Zabbix server are allowed.</span></span><br><span class="line"><span class="comment">#       0 - not allowed</span></span><br><span class="line"><span class="comment">#       1 - allowed</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Mandatory: no</span></span><br><span class="line"><span class="comment"># Default:</span></span><br><span class="line"><span class="comment"># EnableRemoteCommands=0</span></span><br></pre></td></tr></table></figure>

<h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> config.yml</span><br><span class="line">  - name: EnableRemoteCommands </span><br><span class="line">    lineinfile: </span><br><span class="line">      path: /etc/zabbix/zabbix_agentd.conf</span><br><span class="line">      regexp: <span class="string">&#x27;(.*EnableRemoteCommands.*)&#x27;</span></span><br><span class="line">      line: <span class="string">&#x27;#\1&#x27;</span></span><br><span class="line">    become: <span class="built_in">yes</span></span><br></pre></td></tr></table></figure>

<h3 id="取消注释"><a href="#取消注释" class="headerlink" title="取消注释"></a>取消注释</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> config.yml</span><br><span class="line">  - name: EnableRemoteCommands </span><br><span class="line">    lineinfile: </span><br><span class="line">      path: /etc/zabbix/zabbix_agentd.conf</span><br><span class="line">      regexp: <span class="string">&#x27;^#(.*EnableRemoteCommands.*)&#x27;</span></span><br><span class="line">      line: <span class="string">&#x27;\1&#x27;</span></span><br><span class="line">    become: <span class="built_in">yes</span></span><br></pre></td></tr></table></figure>

<!--stackedit_data:
eyJoaXN0b3J5IjpbODExNDU2NDI2XX0=
-->]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Aansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 替代命令笔记podman、nerdctl、crictl</title>
    <url>/2021/07/10/ops/Docker/Docker%20%E6%9B%BF%E4%BB%A3%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0podman%E3%80%81nerdctl%E3%80%81crictl/</url>
    <content><![CDATA[<p>容器镜像相关操作命令，案例以k3s为切入点</p>
<span id="more"></span>

<h1 id="安装-amp-配置"><a href="#安装-amp-配置" class="headerlink" title="安装&amp;配置"></a>安装&amp;配置</h1><h2 id="准备镜像文件"><a href="#准备镜像文件" class="headerlink" title="准备镜像文件"></a>准备镜像文件</h2><p>下载k3s-airgap-images-amd64.tar.gz，k3s, install.sh(<a href="http://get.k3s.io/">http://get.k3s.io</a>)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">mkdir</span> -p /var/lib/rancher/k3s/agent/images/</span><br><span class="line">gzip -<span class="built_in">cd</span> k3s-airgap-images-amd64.tar.gz &gt; k3s-airgap-images-amd64.tar</span><br><span class="line">sudo <span class="built_in">cp</span> ./k3s-airgap-images-amd64.tar /var/lib/rancher/k3s/agent/images/</span><br><span class="line"><span class="built_in">cp</span> ./k3s /usr/local/bin/k3s</span><br><span class="line"><span class="built_in">chmod</span> +x ./install.sh</span><br><span class="line"><span class="built_in">chmod</span> +x /usr/local/bin/k3s</span><br></pre></td></tr></table></figure>

<h2 id="单节点安装"><a href="#单节点安装" class="headerlink" title="单节点安装"></a>单节点安装</h2><h3 id="server节点"><a href="#server节点" class="headerlink" title="server节点"></a>server节点</h3><blockquote>
<p>INSTALL_K3S_SKIP_DOWNLOAD=true ./install.sh</p>
</blockquote>
<h3 id="agent节点"><a href="#agent节点" class="headerlink" title="agent节点"></a>agent节点</h3><p>请在每个 agent 节点上执行以下操作。注意将 myserver 替换为 server 的 IP 或有效的 DNS，并将 mynodetoken 替换 server 节点的 token，通常在/var/lib/rancher/k3s/server/node-token</p>
<blockquote>
<p>INSTALL_K3S_SKIP_DOWNLOAD=true K3S_URL=<a href="https://myserver:6443/">https://myserver:6443</a> K3S_TOKEN=mynodetoken ./install.sh</p>
</blockquote>
<h3 id="检查安装"><a href="#检查安装" class="headerlink" title="检查安装"></a>检查安装</h3><blockquote>
<p>crictl images</p>
</blockquote>
<h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>因为<br>root:/etc/rancher/k3s# ll /usr/local/bin/crictl<br>lrwxrwxrwx 1 root root 3 Jun  7 10:42 /usr/local/bin/crictl -&gt; k3s*</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#sudo vim /etc/systemd/system/k3s.service.env</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/systemd/system/k3s.service.env &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">HTTP_PROXY=&quot;http://100.100.154.250:3128&quot;</span></span><br><span class="line"><span class="string">HTTPS_PROXY=&quot;http://100.100.154.250:3128&quot;</span></span><br><span class="line"><span class="string">NO_PROXY=&quot;localhost,127.0.0.0/8,0.0.0.0,10.0.0.0/8,192.168.0.0/16,172.16.0.0/12,internal.example.com&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart k3s</span><br></pre></td></tr></table></figure>

<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><p>待补充</p>
<h1 id="常用命令对比"><a href="#常用命令对比" class="headerlink" title="常用命令对比"></a>常用命令对比</h1><table>
<thead>
<tr>
<th align="left">命令</th>
<th align="left">Docker</th>
<th align="left">Containerd crictl（推荐）</th>
</tr>
</thead>
<tbody><tr>
<td align="left">查看容器列表</td>
<td align="left"><code>docker ps</code></td>
<td align="left"><code>crictl ps</code></td>
</tr>
<tr>
<td align="left">查看容器详情</td>
<td align="left"><code>docker inspect</code></td>
<td align="left"><code>crictl inspect</code></td>
</tr>
<tr>
<td align="left">查看容器日志</td>
<td align="left"><code>docker logs</code></td>
<td align="left"><code>crictl logs</code></td>
</tr>
<tr>
<td align="left">容器内执行命令</td>
<td align="left"><code>docker exec</code></td>
<td align="left"><code>crictl exec</code></td>
</tr>
<tr>
<td align="left">挂载容器</td>
<td align="left"><code>docker attach</code></td>
<td align="left"><code>crictl attach</code></td>
</tr>
<tr>
<td align="left">显示容器资源使用情况</td>
<td align="left"><code>docker stats</code></td>
<td align="left"><code>crictl stats</code></td>
</tr>
<tr>
<td align="left">创建容器</td>
<td align="left"><code>docker create</code></td>
<td align="left"><code>crictl create</code></td>
</tr>
<tr>
<td align="left">启动容器</td>
<td align="left"><code>docker start</code></td>
<td align="left"><code>crictl start</code></td>
</tr>
<tr>
<td align="left">停止容器</td>
<td align="left"><code>docker stop</code></td>
<td align="left"><code>crictl stop</code></td>
</tr>
<tr>
<td align="left">删除容器</td>
<td align="left"><code>docker rm</code></td>
<td align="left"><code>crictl rm</code></td>
</tr>
<tr>
<td align="left">查看镜像列表</td>
<td align="left"><code>docker images</code></td>
<td align="left"><code>crictl images</code></td>
</tr>
<tr>
<td align="left">查看镜像详情</td>
<td align="left"><code>docker inspect</code></td>
<td align="left"><code>crictl inspecti</code></td>
</tr>
<tr>
<td align="left">拉取镜像</td>
<td align="left"><code>docker pull</code></td>
<td align="left"><code>crictl pull</code></td>
</tr>
<tr>
<td align="left">推送镜像</td>
<td align="left"><code>docker push</code></td>
<td align="left">无</td>
</tr>
<tr>
<td align="left">删除镜像</td>
<td align="left"><code>docker rmi</code></td>
<td align="left"><code>crictl rmi</code></td>
</tr>
<tr>
<td align="left">查看Pod列表</td>
<td align="left">无</td>
<td align="left"><code>crictl pods</code></td>
</tr>
<tr>
<td align="left">查看Pod详情</td>
<td align="left">无</td>
<td align="left"><code>crictl inspectp</code></td>
</tr>
<tr>
<td align="left">启动Pod</td>
<td align="left">无</td>
<td align="left"><code>crictl runp</code></td>
</tr>
<tr>
<td align="left">停止Pod</td>
<td align="left">无</td>
<td align="left"><code>crictl stopp</code></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 运行 Jenkins 无法显示报告</title>
    <url>/2018/04/08/ops/Docker/Docker%20%E8%BF%90%E8%A1%8C%20Jenkins%20%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA%E6%8A%A5%E5%91%8A/</url>
    <content><![CDATA[<p>Docker运行Jenkins有诸多不便，尽量不要使用。<br>较新版本Jenkins限制了js和css的运行，然而RobotFramework的日志log.html和报告report.html都严重依赖js和css。docker平台上最简单解决方法就是用JAVA_OPTS-Dhudson.model.DirectoryBrowserSupport.CSP=，放松Jenkins的安全策略。缺失字体库会造成显示成方块的问题</p>
<span id="more"></span>
<h1 id="Docker-运行-Jenkins-无法显示报告、字体乱码问题"><a href="#Docker-运行-Jenkins-无法显示报告、字体乱码问题" class="headerlink" title="Docker 运行 Jenkins 无法显示报告、字体乱码问题"></a>Docker 运行 Jenkins 无法显示报告、字体乱码问题</h1><h2 id="运行命令"><a href="#运行命令" class="headerlink" title="运行命令"></a>运行命令</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -u root --name jenkins --restart always -d \</span><br><span class="line">-p 8083:8080 -p 50000:50000 \</span><br><span class="line">--<span class="built_in">link</span> hwcntlm:hwcntlm \</span><br><span class="line">-v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime \</span><br><span class="line">-v /home/tony/jenkins-blueocean-data:/var/jenkins_home \</span><br><span class="line">-v /var/run/docker.sock:/var/run/docker.sock \</span><br><span class="line">-e http_proxy=hwcntlm:3128 \</span><br><span class="line">-e https_proxy=hwcntlm:3128 \</span><br><span class="line">-e JAVA_OPTS=<span class="string">&quot;-DproxyHost=hwcntlm -DproxyPort=3128 -Dhudson.model.DirectoryBrowserSupport.CSP= -Duser.timezone=Asia/Shanghai&quot;</span> \</span><br><span class="line">jenkinsci/blueocean</span><br></pre></td></tr></table></figure>
<ol>
<li>多个JAVA_OPTS：如果处在多个JAVA_OPTS，需要空格隔开，双引号包住。等号后面不加内容为空。</li>
<li>时区问题：通过JAVA_OPTS和映射时区文件都可以解决，按理说只取其一即可</li>
<li>代理：公司环境很可能需要代理才能访问，按理说也是环境变量<code>http_proxy</code>和JAVA_OPTS=-DproxyHost=hwcntlm -DproxyPort=3128任一即可</li>
</ol>
]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>RobotFramework</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop2.x 工作台构建(Hadoop圈应用独立部署)</title>
    <url>/2018/05/02/ops/Hadoop/Hadoop2.x%20%E5%B7%A5%E4%BD%9C%E5%8F%B0%E6%9E%84%E5%BB%BA(Hadoop%E5%9C%88%E5%BA%94%E7%94%A8%E7%8B%AC%E7%AB%8B%E9%83%A8%E7%BD%B2)/</url>
    <content><![CDATA[<p>之前hadoop圈的应用（如hive、sqoop、azkaban等）都在master节点部署，一次性多个应用同时启动，耗尽内存后Linux随机删掉进程，影响集群和应用的稳定性。</p>
<span id="more"></span>

<h1 id="整体说明"><a href="#整体说明" class="headerlink" title="整体说明"></a>整体说明</h1><p>解决思路是在联通的网络环境下，取一台单独的服务器，不作为集群一部分，仅部署各种应用，应用使用jvm控制内存，更进一步使用独立用户搭配cgroup控制资源的使用，维持整体稳定。这台单独的服务器下称为“工作台”。</p>
<h1 id="试验环境"><a href="#试验环境" class="headerlink" title="试验环境"></a>试验环境</h1><p>workshop原版: 10.41.236.56</p>
<h2 id="快速拷贝"><a href="#快速拷贝" class="headerlink" title="快速拷贝"></a>快速拷贝</h2><h3 id="shell脚本"><a href="#shell脚本" class="headerlink" title="shell脚本"></a>shell脚本</h3><p>这是从A3的209拷贝任务脚本到”母体”(10.41.236.56), 在母体上执行命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> SRC_HOST=10.41.236.209</span><br><span class="line">scp -r hadoop@<span class="variable">$SRC_HOST</span>:/home/hadoop/soft/file /home/hadoop/soft</span><br></pre></td></tr></table></figure>
<h3 id="自定义jar包"><a href="#自定义jar包" class="headerlink" title="自定义jar包"></a>自定义jar包</h3><p>这是从A3的209拷贝任务脚本到”母体”(10.41.236.56), 在母体上执行命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> SRC_HOST=10.41.236.209</span><br><span class="line">scp hadoop@<span class="variable">$SRC_HOST</span>:/home/hadoop/soft/*.jar /home/hadoop/soft/</span><br></pre></td></tr></table></figure>
<h3 id="环境变量与软件"><a href="#环境变量与软件" class="headerlink" title="环境变量与软件"></a>环境变量与软件</h3><p>这命令是从”母体”(10.41.236.56)拷贝到”执行者”executor上, 在执行者的机器上执行命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> SRC_HOST=10.41.236.56</span><br><span class="line">sudo scp hadoop@<span class="variable">$SRC_HOST</span>:/etc/profile.d/xcube.sh /etc/profile.d/xcube.sh</span><br><span class="line"><span class="built_in">source</span> /etc/profile.d/xcube.sh</span><br><span class="line">scp -r hadoop@<span class="variable">$SRC_HOST</span>:/home/hadoop/soft /home/hadoop/soft</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="整体规划"><a href="#整体规划" class="headerlink" title="整体规划"></a>整体规划</h1><h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/profile.d/xcube.sh  <span class="comment"># 添加以下内容</span></span><br><span class="line"><span class="comment"># JAVA</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/home/hadoop/soft/jdk </span><br><span class="line"><span class="built_in">export</span> JRE_HOME=<span class="variable">$JAVA_HOME</span>/jre </span><br><span class="line"><span class="built_in">export</span> CLASSPATH=<span class="variable">$JAVA_HOME</span>/lib:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar:<span class="variable">$JRE_HOME</span>/lib:<span class="variable">$CLASSPATH</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$JRE_HOME</span>/bin </span><br><span class="line"><span class="comment"># Hadoop</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hadoop/soft/hadoop </span><br><span class="line"><span class="built_in">export</span> HADOOP_DEV_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPARED_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>  </span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>  </span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>  </span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>  </span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$&#123;HADOOP_HOME&#125;</span>/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> YARN_CONF_DIR=<span class="variable">$&#123;HADOOP_HOME&#125;</span>/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"><span class="comment"># Hive</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/home/hadoop/soft/hive</span><br><span class="line"><span class="built_in">alias</span> bee=<span class="string">&#x27;beeline -n hadoop -u jdbc:hive2://10.41.236.209:10000&#x27;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br><span class="line"><span class="comment">#Sqoop</span></span><br><span class="line"><span class="built_in">export</span> SQOOP_HOME=/home/hadoop/soft/sqoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SQOOP_HOME</span>/bin</span><br><span class="line"><span class="comment">#Hbase</span></span><br><span class="line"><span class="comment">#export HBASE_HOME=/home/hadoop/soft/hbase</span></span><br><span class="line"><span class="comment">#Scala</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/home/hadoop/soft/scala</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SCALA_HOME</span>/bin</span><br><span class="line"><span class="comment">#Spark</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/home/hadoop/soft/spark</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 账号密码jdbc</span></span><br><span class="line"><span class="built_in">export</span> azkaban_username=azkaban</span><br><span class="line"><span class="built_in">export</span> azkaban_password=azkaban%941</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> kylin_username=ADMIN</span><br><span class="line"><span class="built_in">export</span> kylin_password=KYLIN%258</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> tr_url=jdbc:oracle:thin:@//10.41.37.47:1521/dgpffin.huawei.com</span><br><span class="line"><span class="built_in">export</span> tr_username=uniccs</span><br><span class="line"><span class="built_in">export</span> tr_password=uniccs123</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> xcube_url=jdbc:oracle:thin:@//a3xcubeoracle01.beta.hic.cloud:1521/a3xcube_srv</span><br><span class="line"><span class="built_in">export</span> xcube_username=xcube</span><br><span class="line"><span class="built_in">export</span> xcube_password=huawei123</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> xcube_url_kaifa=jdbc:oracle:thin:@//szftdscan02.huawei.com:1521/xcubedt_srv</span><br><span class="line"><span class="built_in">export</span> xcube_username_kaifa=xcube</span><br><span class="line"><span class="built_in">export</span> xcube_password_kaifa=huawei123</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> cpi_url=jdbc:oracle:thin:@//10.98.65.205:1521/nkuatr.huawei.com</span><br><span class="line"><span class="built_in">export</span> cpi_username=uniconfigbase_query</span><br><span class="line"><span class="built_in">export</span> cpi_password=huawei123</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> ccs_url=jdbc:oracle:thin:@//nkdb370371-cls.huawei.com:1521/nka3fin.huawei.com</span><br><span class="line"><span class="built_in">export</span> ccs_username=uniccs</span><br><span class="line"><span class="built_in">export</span> ccs_password=xhrg<span class="comment">#3ddcr</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> rcm_url=jdbc:oracle:thin:@//nkgtsp16566-cls.huawei.com:1521/cepd</span><br><span class="line"><span class="built_in">export</span> rcm_username=fcquery</span><br><span class="line"><span class="built_in">export</span> rcm_password=huawei123</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> ccm_url=jdbc:oracle:thin:@//nkgtsp16566-cls.huawei.com:1521/cepd</span><br><span class="line"><span class="built_in">export</span> ccm_username=ccm</span><br><span class="line"><span class="built_in">export</span> ccm_password=d12aafcddac156c</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> tr_url=jdbc:oracle:thin:@//nkdb370371-cls.huawei.com:1521/nka3fin.huawei.com</span><br><span class="line"><span class="built_in">export</span> tr_username=starplate</span><br><span class="line"><span class="built_in">export</span> tr_password=<span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h2 id="JDK1-8"><a href="#JDK1-8" class="headerlink" title="JDK1.8"></a>JDK1.8</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop/soft</span><br><span class="line"><span class="built_in">cd</span> /home/hadoop/soft</span><br><span class="line"><span class="comment"># mv jdk.tar.gz</span></span><br><span class="line">tar -zvxf jdk-8u151-linux-x64.tar.gz</span><br><span class="line"><span class="built_in">mv</span> jdk1.8.0_151 jdk</span><br><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/home/hadoop/soft/jdk</span><br><span class="line"><span class="built_in">export</span> JRE_HOME=<span class="variable">$JAVA_HOME</span>/jre</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$JRE_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> CLASSPATH=<span class="variable">$JAVA_HOME</span>/lib:<span class="variable">$CLASSPATH</span></span><br><span class="line"><span class="built_in">export</span> PATH</span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>
<h2 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h2><p>hadoop圈的应用大都需要引用hdfs、yarn、mapreduce相关jar包才能启动，所以首先要在工作台上配置hadoop，使其能够访问集群的hdfs文件系统，能提交mapreduce任务。</p>
<h3 id="解压、环境变量"><a href="#解压、环境变量" class="headerlink" title="解压、环境变量"></a>解压、环境变量</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf hadoop-2.7.2.tar.gz</span><br><span class="line"><span class="built_in">mv</span> hadoop-2.7.2 hadoop</span><br><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment">#Hadoop&amp;YARN</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_DEV_HOME=/home/hadoop/soft/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_DEV_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_DEV_HOME</span>/sbin</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hadoop/soft/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPARED_HOME=<span class="variable">$&#123;HADOOP_DEV_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$&#123;HADOOP_DEV_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$&#123;HADOOP_DEV_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$&#123;HADOOP_DEV_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$&#123;HADOOP_DEV_HOME&#125;</span>/etc/hadoop</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>
<h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /data01/huawei/BigData/jntmp/journal</span><br><span class="line"><span class="built_in">mkdir</span> -p /data01/huawei/BigData/hadoop/name</span><br><span class="line"><span class="built_in">mkdir</span> -p /data01/huawei/BigData/hadoop/data</span><br><span class="line">sudo <span class="built_in">chown</span> -R hadoop:root /data01</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/soft/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><p>dfs.client.failover.proxy.provider.ns1这一项一定要配置，ns1要跟core-site.xml和dfs.nameservices对应</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.41.236.209:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.41.236.115:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.41.236.209<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.41.236.115<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.41.236.209:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.staging-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><blockquote>
<p>hadoop   jar ~/soft/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar pi 10 100000000</p>
</blockquote>
<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><h3 id="解压、环境变量-1"><a href="#解压、环境变量-1" class="headerlink" title="解压、环境变量"></a>解压、环境变量</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zvxf apache-hive-2.3.2-bin.tar.gz</span><br><span class="line"><span class="built_in">mv</span> apache-hive-2.3.2-bin hive</span><br><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment">#HIVE</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/home/hadoop/soft/hive</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>
<h3 id="目录-1"><a href="#目录-1" class="headerlink" title="目录"></a>目录</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /data01/huawei/BigData/hive/tmp</span><br><span class="line">sudo <span class="built_in">chown</span> -R hadoop:root /data01</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="hive-site-xml"><a href="#hive-site-xml" class="headerlink" title="hive-site.xml"></a>hive-site.xml</h3><p>最小化修改.</p>
<ol>
<li>长sql有中文名, 导致job name过长, 在此限制一下, 避免在结束时<code>Job status not available</code>的问题</li>
<li>开发sql有时候不是非常严格规范, 需要放宽:hive.strict.checks检查<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/soft/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.jobname.length<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>max jobname length<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.strict.checks.cartesian.product<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      Enabling strict Cartesian join checks disallows the following:</span><br><span class="line">        Cartesian product (cross join).</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="beeline"><a href="#beeline" class="headerlink" title="beeline"></a>beeline</h3>命令行工具测试是否可用<blockquote>
<p>beeline -n hadoop -u jdbc:hive2://10.41.236.209:10000</p>
</blockquote>
</li>
</ol>
<h2 id="sqoop"><a href="#sqoop" class="headerlink" title="sqoop"></a>sqoop</h2><ol>
<li>解压二进制包到/home/hadoop/sqoop, 同时确认为SQOOP_HOME</li>
<li>拷贝jdbc依赖的ojdbc6.jar到$SQOOP_HOME/lib/下</li>
<li>修改metastore的地址, 预防在~/.sqoop下占用太多空间, 在xml文件<configuration>节内添加(或解注释)以下内容<blockquote>
<p>vim $SQOOP_HOME/conf/sqoop-site.xml</p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>sqoop.metastore.server.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data01/soft/sqoop-metastore/shared.db<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Path to the shared metastore database files. If this is not set, it will be placed in ~/.sqoop/.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>sqoop.metastore.server.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>16000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Port that this metastore should listen on.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>因为没有配置<code>$HBASE_HOME/$HCAT_HOME/$ACCUMULO_HOME/$ZOOKEEPER_HOME</code>这些路径, 所以会<code>Warining</code>提示不能导入Hcatalog/Accumulo的任务. 忽略之, 直到需要了再配置</li>
</ol>
<h2 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h2><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p><code>spark-env.sh</code>如果环境变量已经有, 改配置文件基本不需要改</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim ~/soft/spark/conf/spark-env.sh</span><br><span class="line"><span class="comment"># 当系统的环境变量配置好后,不需要下方的配置, SPARK_DRIVER_MEMORY属于优化配置, 可省略</span></span><br><span class="line"><span class="comment">#export SPARK_MASTER_WEBUI_PORT=8081 # default:8080</span></span><br><span class="line">SPARK_DRIVER_MEMORY=4G</span><br></pre></td></tr></table></figure>
<p><code>spark-defaults.conf</code>以下配置按照NodeManager是12C12G计算</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim ~/soft/spark/conf/spark-defaults.conf</span><br><span class="line">spark.master                        yarn</span><br><span class="line">spark.submit.deployMode				cluster</span><br><span class="line">spark.home                          /home/hadoop/soft/spark</span><br><span class="line">spark.eventLog.enabled              <span class="literal">true</span></span><br><span class="line">spark.eventLog.<span class="built_in">dir</span>                  hdfs://ns1/spark/spark-log</span><br><span class="line">spark.serializer                    org.apache.spark.serializer.KryoSerializer</span><br><span class="line"><span class="comment"># hive on spark 建议5/6/7</span></span><br><span class="line">spark.executor.cores                6</span><br><span class="line"><span class="comment"># 按6*12G/12vcores计算</span></span><br><span class="line">spark.executor.memory               5222m</span><br><span class="line"><span class="comment"># 28个计算节点*每个节点2个executor</span></span><br><span class="line">spark.executor.instances            56</span><br><span class="line"><span class="comment"># 所有core的两三倍：56*6*3=1008</span></span><br><span class="line">spark.default.parallelism           1000</span><br><span class="line"><span class="comment"># 15% * spark.executor.memory</span></span><br><span class="line">spark.yarn.executor.memoryOverhead  921m</span><br><span class="line">spark.driver.memory                 4g</span><br><span class="line">spark.yarn.driver.memoryOverhead    400m</span><br><span class="line">spark.yarn.jars                     hdfs://ns1/spark/jars/*.jar</span><br></pre></td></tr></table></figure>
<h3 id="验证-1"><a href="#验证-1" class="headerlink" title="验证"></a>验证</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./bin/spark-submit --class org.apache.spark.examples.SparkPi ./examples/jars/spark-examples_2.11-2.2.0.jar 10</span><br></pre></td></tr></table></figure>

<h2 id="Azkaban-3-50-2"><a href="#Azkaban-3-50-2" class="headerlink" title="Azkaban-3.50.2"></a>Azkaban-3.50.2</h2><p>github编译的3.50.2的二进制包:<br><code>https://szxsvn02-ex:3690/svn/CP_CCM_SVN/UniSTAR Common/10.Project Team/15.xCube/14 Hadoop环境搭建/package&amp;config/package/azkaban-3.50.2</code></p>
<h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>web工程是UI界面, 用于查看任务等; exec-server工程是执行者的工程, 用于执行任务. Azkaban从3.0.0开始, 支持多个执行器, 本次采用<strong>multiple executor mode</strong>多执行器的部署形式.<br>也即Azkaban-web工程只需要部署一个, Azkaban-executor工程可能需要部署多台.</p>
<h3 id="备份数据库"><a href="#备份数据库" class="headerlink" title="备份数据库"></a>备份数据库</h3><p>有备无患的步骤, 其中参数<code>hex-blob</code>不可省略</p>
<blockquote>
<p>mysqldump -h10.41.236.209 -uhive -phuawei123 azkaban –hex-blob &gt; a3.sql</p>
</blockquote>
<h3 id="升级数据库"><a href="#升级数据库" class="headerlink" title="升级数据库"></a>升级数据库</h3><p>生产和测试环境使用的2.5.0版本, 需要执行<code>azkaban-sql-3.0.0.zip</code>中的的4个脚本, 升级到3.0时代, 然后再执行<code>azkaban-db-3.50.2.zip</code>中的2个upgrade脚本.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create.executors.sql</span><br><span class="line">update.active_executing_flows.3.0.sql</span><br><span class="line">update.execution_flows.3.0.sql</span><br><span class="line">create.executor_events.sql</span><br></pre></td></tr></table></figure>
<p>偷懒可以粘贴这一段</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> executors (</span><br><span class="line">  id <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT,</span><br><span class="line">  host <span class="type">VARCHAR</span>(<span class="number">64</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  port <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  active <span class="type">BOOLEAN</span> <span class="keyword">DEFAULT</span> <span class="literal">true</span>,</span><br><span class="line">  <span class="keyword">UNIQUE</span> (host, port),</span><br><span class="line">  <span class="keyword">UNIQUE</span> INDEX executor_id (id)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">CREATE</span> INDEX executor_connection <span class="keyword">ON</span> executors(host, port);</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> active_executing_flows <span class="keyword">DROP</span> <span class="keyword">COLUMN</span> host;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> active_executing_flows <span class="keyword">DROP</span> <span class="keyword">COLUMN</span> port;</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> execution_flows <span class="keyword">ADD</span> <span class="keyword">COLUMN</span> executor_id <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>;</span><br><span class="line"><span class="keyword">CREATE</span> INDEX executor_id <span class="keyword">ON</span> execution_flows(executor_id);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> executor_events (</span><br><span class="line">  executor_id <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  event_type TINYINT <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  event_time DATETIME <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  username <span class="type">VARCHAR</span>(<span class="number">64</span>),</span><br><span class="line">  message <span class="type">VARCHAR</span>(<span class="number">512</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">CREATE</span> INDEX executor_log <span class="keyword">ON</span> executor_events(executor_id, event_time);</span><br><span class="line"><span class="comment">---3.20.0--&gt;3.22.0</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> project_versions <span class="keyword">ADD</span> resource_id <span class="type">VARCHAR</span>(<span class="number">512</span>);</span><br><span class="line"><span class="keyword">ALTER</span> DATABASE azkaban <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> projects MODIFY name <span class="type">VARCHAR</span>(<span class="number">64</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</span><br></pre></td></tr></table></figure>
<p>如果出错, 请看: <a href="https://azkaban.github.io/azkaban/docs/latest/#upgrade-27">参考文档</a></p>
<h3 id="Azkaban-web-server工程"><a href="#Azkaban-web-server工程" class="headerlink" title="Azkaban-web-server工程"></a>Azkaban-web-server工程</h3><h4 id="下载解压"><a href="#下载解压" class="headerlink" title="下载解压"></a>下载解压</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop/soft/azkaban</span><br><span class="line"><span class="built_in">cd</span> /home/hadoop/soft/azkaban</span><br><span class="line">unzip azkaban-web-server.zip</span><br><span class="line"><span class="built_in">rm</span> -f azkaban-web-server.zip</span><br></pre></td></tr></table></figure>
<h4 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h4><p>10.41.236.56上已经改好适配A3环境, 如果是改环境, <strong>mysql</strong>/邮箱地址/keystore这三部分</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 改conf配置, 主要是mysql/邮箱地址/keystore</span></span><br><span class="line">vim azkaban-web-server/conf/azkaban.properties</span><br></pre></td></tr></table></figure>
<h4 id="keystore"><a href="#keystore" class="headerlink" title="keystore"></a>keystore</h4><p>只有一开始keystore password需要输入两次<code>azkaban</code>, 后面一路回车, 注意到correct?确认的时候, 需要输入一个<code>y</code>, 后面也是回车, 直到最后的warning.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/hadoop/soft/azkaban/azkaban-web-server</span><br><span class="line">keytool -keystore keystore -<span class="built_in">alias</span> jetty -genkey -keyalg RSA</span><br><span class="line">Enter keystore password:azkaban</span><br><span class="line">Re-enter new password:azkaban</span><br><span class="line">What is your first and last name?</span><br><span class="line">  [Unknown]:</span><br><span class="line">What is the name of your organizational unit?</span><br><span class="line">  [Unknown]:</span><br><span class="line">What is the name of your organization?</span><br><span class="line">  [Unknown]:</span><br><span class="line">What is the name of your City or Locality?</span><br><span class="line">  [Unknown]:</span><br><span class="line">What is the name of your State or Province?</span><br><span class="line">  [Unknown]:</span><br><span class="line">What is the two-letter country code <span class="keyword">for</span> this unit?</span><br><span class="line">  [Unknown]:</span><br><span class="line">Is CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=Unknown correct?</span><br><span class="line">  [no]:  y</span><br><span class="line"></span><br><span class="line">Enter key password <span class="keyword">for</span> &lt;jetty&gt;</span><br><span class="line">        (RETURN <span class="keyword">if</span> same as keystore password):</span><br><span class="line"></span><br><span class="line">Warning:</span><br><span class="line">The JKS keystore uses a proprietary format. It is recommended to migrate to PKCS12 <span class="built_in">which</span> is an industry standard format using <span class="string">&quot;keytool -importkeystore -srckeystore keystore -destkeystore keystore -deststoretype pkcs12&quot;</span>.</span><br></pre></td></tr></table></figure>
<h4 id="启动与访问验证"><a href="#启动与访问验证" class="headerlink" title="启动与访问验证"></a>启动与访问验证</h4><p>启动</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/hadoop/soft/azkaban/azkaban-web-server</span><br><span class="line"><span class="comment">#sh bin/azkaban-web-start.sh</span></span><br><span class="line">sh bin/start-web.sh</span><br></pre></td></tr></table></figure>
<p>访问</p>
<blockquote>
<p><a href="https://10.41.236.56:8443/">https://10.41.236.56:8443</a></p>
</blockquote>
<p>停止</p>
<blockquote>
<p>sh /home/hadoop/soft/azkaban/azkaban-web-server/bin/azkaban-web-shutdown.sh</p>
</blockquote>
<h3 id="Azkaban-exec-server工程"><a href="#Azkaban-exec-server工程" class="headerlink" title="Azkaban-exec-server工程"></a>Azkaban-exec-server工程</h3><p>由于使用的是多个执行器的部署形式, <strong>每个</strong>执行器也应该部署hadoop等软件, 进行配置步骤. executors之间可以考虑拷贝环境变量文件, 拷贝软件目录. </p>
<h4 id="下载解压-1"><a href="#下载解压-1" class="headerlink" title="下载解压"></a>下载解压</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/hadoop/soft/azkaban</span><br><span class="line"><span class="built_in">cd</span> /home/hadoop/soft/azkaban</span><br><span class="line">unzip azkaban-exec-server.zip</span><br><span class="line"><span class="built_in">rm</span> -f azkaban-exec-server.zip</span><br></pre></td></tr></table></figure>
<h4 id="修改配置-1"><a href="#修改配置-1" class="headerlink" title="修改配置"></a>修改配置</h4><p>10.41.236.56和10.41.236.44已经改好适配A3环境, 如果是改环境, <strong>mysql</strong>/邮箱地址/keystore这三部分</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 改conf配置, 主要是mysql/邮箱地址/keystore</span></span><br><span class="line">vim azkaban-exec-server/conf/azkaban.properties</span><br></pre></td></tr></table></figure>

<h4 id="启动与停止"><a href="#启动与停止" class="headerlink" title="启动与停止"></a>启动与停止</h4><p>启动</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/hadoop/soft/azkaban/azkaban-exec-server</span><br><span class="line"><span class="comment">#sh bin/azkaban-executor-start.sh</span></span><br><span class="line">sh bin/start-exec.sh</span><br></pre></td></tr></table></figure>
<p>停止</p>
<blockquote>
<p>/home/hadoop/soft/azkaban/azkaban-exec-server/bin/azkaban-executor-shutdown.sh</p>
</blockquote>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop2.x 相关的配置文件路径</title>
    <url>/2018/05/27/ops/Hadoop/Hadoop2.x%20%E7%9B%B8%E5%85%B3%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84/</url>
    <content><![CDATA[<p>Hadoop圈有多个应用（如hive、sqoop、azkaban等），每个应用有一个或多个配置文件，简单记录一下应用、配置，路径的关系。</p>
<span id="more"></span>

<h1 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h1><blockquote>
<p>/home/hadoop/.bash_profile</p>
</blockquote>
<p>建议改为</p>
<blockquote>
<p>/home/hadoop/.bashrc</p>
</blockquote>
<h1 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h1><p>配置文件：/home/hadoop/soft/zookeeper/conf/zoo.cfg<br>每个实例都有自己独特的id：/home/hadoop/soft/zookeeper/data/myid</p>
<h1 id="hdfs"><a href="#hdfs" class="headerlink" title="hdfs"></a>hdfs</h1><p>配置路径：<code>/home/hadoop/soft/hadoop/etc/hadoop</code></p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>core-site.xml</td>
<td>zk、文件系统根目录、临时文件</td>
</tr>
<tr>
<td><code>hadoop-env.sh</code></td>
<td>JAVA_HOME</td>
</tr>
<tr>
<td>hdfs-site.xml</td>
<td>核心配置，HA，端口，journal，nn、dn、jn目录等</td>
</tr>
<tr>
<td>slaves</td>
<td>所有从节点的ip/hostname, 只写DataNode和NodeManager</td>
</tr>
<tr>
<td><code>httpfs-env.sh</code></td>
<td>cdh的httpfs(未启用)</td>
</tr>
<tr>
<td>httpfs-site.xml</td>
<td>cdh的httpfs(未启用)</td>
</tr>
</tbody></table>
<h1 id="yarn-mapreduce"><a href="#yarn-mapreduce" class="headerlink" title="yarn(mapreduce)"></a>yarn(mapreduce)</h1><p>配置路径：<code>/home/hadoop/soft/hadoop/etc/hadoop</code></p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>slaves</td>
<td>所有从节点的ip(hostname),一般只写DataNode和NodeManager</td>
</tr>
<tr>
<td>yarn-site.xml</td>
<td>核心配置，HA，zk，cpu、mem资源，日志聚集，端口</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce的默认配置</td>
</tr>
<tr>
<td><code>mapred-env.sh</code></td>
<td>未配置</td>
</tr>
<tr>
<td><code>yarn-env.sh</code></td>
<td>未配置</td>
</tr>
</tbody></table>
<h1 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h1><p>配置文件路径：/home/hadoop/soft/hbase/conf</p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><code>hbase-env.sh</code></td>
<td>JAVA_HOME,HADOOP_HOME</td>
</tr>
<tr>
<td>hbase-site</td>
<td>文件系统根目录，zk，临时文件，端口</td>
</tr>
<tr>
<td>regionservers</td>
<td>从节点的ip/hostname</td>
</tr>
<tr>
<td>hdfs-site.xml</td>
<td>不需要的文件，如果配置了HADOOP_HOME</td>
</tr>
</tbody></table>
<h1 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h1><p>配置目录：/home/hadoop/soft/hive/conf/，正常来说该目录下不需要<code>hdfs-site.xml</code>和<code>spark-defaults.conf</code>文件。hive会通过<code>HADOOP_HOME</code>和<code>SPARK_HOME</code>找到配置文件。<br>如果实在没有生效，建立软连接到hive的配置目录。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/home/hadoop/soft/hive/conf/hive-env.sh</span><br><span class="line">/home/hadoop/soft/hive/conf/hive-site.xml</span><br></pre></td></tr></table></figure>

<h1 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h1><p>配置文件路径：/home/hadoop/soft/spark/conf</p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>slaves</td>
<td>计算从节点的ip/hostname</td>
</tr>
<tr>
<td><code>spark-env.sh</code></td>
<td>环境变量，JAVA_HOME、SCALA_HOME，HADOOP_HOME，ip，端口，目录，内存</td>
</tr>
<tr>
<td>spark-defaults.conf</td>
<td>运行方式，jars，executor，并行度等配置</td>
</tr>
</tbody></table>
<h1 id="presto"><a href="#presto" class="headerlink" title="presto"></a>presto</h1><p>配置文件目录：/home/hadoop/soft/presto/etc</p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>config.properties</td>
<td>是否为coordinator，端口，内存使用，uri</td>
</tr>
<tr>
<td>jvm.config</td>
<td>jvm参数</td>
</tr>
<tr>
<td>node.properties</td>
<td>数据目录</td>
</tr>
</tbody></table>
<h1 id="azkaban"><a href="#azkaban" class="headerlink" title="azkaban"></a>azkaban</h1><h2 id="azkaban-executor"><a href="#azkaban-executor" class="headerlink" title="azkaban-executor"></a>azkaban-executor</h2><blockquote>
<p>/home/hadoop/soft/azkaban-executor-2.5.0/conf/azkaban.properties</p>
</blockquote>
<h2 id="azkaban-web"><a href="#azkaban-web" class="headerlink" title="azkaban-web"></a>azkaban-web</h2><blockquote>
<p>/home/hadoop/soft/azkaban-web-2.5.0/conf/azkaban.properties</p>
</blockquote>
<h1 id="kylin"><a href="#kylin" class="headerlink" title="kylin"></a>kylin</h1><p>配置目录：/home/hadoop/soft/kylin/conf</p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>kylin_hive_conf.xml</td>
<td>操作hive时的参数，是否压缩等（使用默认）</td>
</tr>
<tr>
<td>kylin_job_conf_inmem.xml</td>
<td>job使用内存的分配，mapreduce使用多少内存</td>
</tr>
<tr>
<td>kylin_job_conf.xml</td>
<td>使用默认</td>
</tr>
<tr>
<td>kylin.properties</td>
<td>uri，hdfs，hive，hbase</td>
</tr>
</tbody></table>
<h1 id="hue"><a href="#hue" class="headerlink" title="hue"></a>hue</h1><blockquote>
<p>/home/hadoop/soft/hue/desktop/conf/hue.ini</p>
</blockquote>
<h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><blockquote>
<p>/home/hadoop/soft/mysql/my.cnf</p>
</blockquote>
<h1 id="sqoop"><a href="#sqoop" class="headerlink" title="sqoop"></a>sqoop</h1><blockquote>
<p>/home/hadoop/soft/sqoop/conf/sqoop-site.xml</p>
</blockquote>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop2.x 组件运维命令</title>
    <url>/2018/04/05/ops/Hadoop/Hadoop2.x%20%E7%BB%84%E4%BB%B6%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h1 id="Hadoop组件运维命令"><a href="#Hadoop组件运维命令" class="headerlink" title="Hadoop组件运维命令"></a>Hadoop组件运维命令</h1><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>Agent在supervise的方式下启动，如果进程死掉会被系统立即重启，以提供服务。</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>项目中初次使用原生的Hadoop集群，各组件不稳定，常需要各种重启命令。</p>
<h2 id="Hadoop-2-7"><a href="#Hadoop-2-7" class="headerlink" title="Hadoop 2.7"></a>Hadoop 2.7</h2><p>应该按照下文的顺序启动集群，更详细的说明请参考# HA 模式下的 <a href="http://blog.csdn.net/u011414200/article/details/50437356">Hadoop+ZooKeeper+HBase 启动顺序</a></p>
<ol>
<li>ZooKeeper<br><small>节点规划中，zookeeper跟journalnode放在一起，共5个节点</small><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">zkServer.sh start  <span class="comment"># QuorumPeerMain</span></span><br><span class="line">hadoop-daemon.sh start journalnode <span class="comment"># JournalNode</span></span><br></pre></td></tr></table></figure></li>
<li>启动NameNode<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure></li>
<li>启动DataNode<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop-daemon.sh start datanode  <span class="comment"># 单个</span></span><br><span class="line">hadoop-daemons.sh start datanode <span class="comment"># 整个集群</span></span><br></pre></td></tr></table></figure></li>
<li>启动ResourceManager<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure></li>
<li>启动NodeManager<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yarn-daemon.sh start nodemanager  <span class="comment"># 单个</span></span><br><span class="line">yarn-daemons.sh start nodemanager <span class="comment"># 整个集群</span></span><br></pre></td></tr></table></figure></li>
<li>启动zkfc(DFSZKFailoverController) - HA两台master都要<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop-daemon.sh start zkfc</span><br></pre></td></tr></table></figure></li>
<li>启动JobHistoryServer<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure></li>
<li>切换Active的NameNode<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hdfs haadmin -failover nn2 nn1</span><br></pre></td></tr></table></figure></li>
<li>查看hdfs状态<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hdfs haadmin -getServiceState nn1</span><br></pre></td></tr></table></figure></li>
<li>切换Active的ResourceManager</li>
</ol>
<p>由于yarn rmadmin不支持-failover命令，只能kill掉active的ResourceManager进程，待切换后再查看 </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yarn rmadmin -getServiceState rm1 <span class="comment">#查看状态 </span></span><br><span class="line">yarn rmadmin -getServiceState rm2 <span class="comment">#查看状态</span></span><br></pre></td></tr></table></figure>
<p>nn1是namenode1，nn2是namenode2. 对应的配置文件是<strong>hdfs-site.xml</strong></p>
<ol start="12">
<li>平衡</li>
</ol>
<p>参考文章:<br><a href="https://community.hortonworks.com/articles/43615/hdfs-balancer-1-100x-performance-improvement.html#">原因</a><br><a href="https://community.hortonworks.com/articles/43849/hdfs-balancer-2-configurations-cli-options.html">参数</a><br><a href="https://community.hortonworks.com/articles/44148/hdfs-balancer-3-cluster-balancing-algorithm.html">算法</a><br>任意节点执行: dfsadmin -setBalancerBandwidth 10485760 (=10MB/s)<br>该命令会在两个NameNode节点生效. 后续执行 hdfs balancer 会快很多.<br>默认是每个DataNode节点是1MB/s  </p>
<p>生产环境点对点大约是60MB/s, 这样配置大约会占用六分之一的带宽.<br>不要再设置更大了, 因为多对机器传输累积到网关的速度就很大了.</p>
<p>hdfs balancer命令原本设计是常驻后台进程, 所以默认参数平衡时很慢的. 适用于长期运行, 不影响业务操作. 无限期后台<code>hdfs balancer -idleiterations -1</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dfsadmin -setBalancerBandwidth 10485760</span><br><span class="line">hdfs balancer </span><br></pre></td></tr></table></figure>

<h2 id="Hbase"><a href="#Hbase" class="headerlink" title="Hbase"></a>Hbase</h2><ol>
<li>启动HMaster<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hbase-daemon.sh start master</span><br></pre></td></tr></table></figure></li>
<li>启动HRegionServer<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hbase-daemon.sh start regionserver  <span class="comment"># 单个</span></span><br><span class="line">hbase-daemons.sh start regionserver <span class="comment"># 整个集群</span></span><br></pre></td></tr></table></figure>
<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2></li>
<li>启动Metastore<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hive --service metastore  # 关键部分  </span></span><br><span class="line"><span class="built_in">nohup</span> hive --service metastore &gt; /home/hadoop/soft/hive/logs/metastore.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>启动HiveServer2<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hive --service hiveserver2  # 关键部分  </span></span><br><span class="line"><span class="built_in">nohup</span> hive --service hiveserver2 &gt; /home/hadoop/soft/hive/logs/hiveserver2.<span class="built_in">log</span> 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="presto"><a href="#presto" class="headerlink" title="presto"></a>presto</h2>coordinator和worker都是一样的启动命令<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/home/hadoop/soft/presto/bin/launcher start</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="Azkaban"><a href="#Azkaban" class="headerlink" title="Azkaban"></a>Azkaban</h2><p>Azkaban工作流项目使用的是2.5.0版本，有Web和Executor两个组件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/hadoop/soft/azkaban-web-2.5.0/</span><br><span class="line"><span class="built_in">nohup</span> bin/azkaban-web-start.sh &gt; /home/hadoop/soft/azkaban-web-2.5.0/webServer.<span class="built_in">log</span> 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span>  /home/hadoop/soft/azkaban-executor-2.5.0/</span><br><span class="line"><span class="built_in">nohup</span> bin/azkaban-executor-start.sh &gt; /home/hadoop/soft/azkaban-executor-2.5.0/executorServer.<span class="built_in">log</span> 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Kylin"><a href="#Kylin" class="headerlink" title="Kylin"></a>Kylin</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/hadoop/soft/kylin/bin</span><br><span class="line">sh kylin.sh start</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Hue"><a href="#Hue" class="headerlink" title="Hue"></a>Hue</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span>  /home/hadoop/soft/hue</span><br><span class="line"><span class="built_in">nohup</span> build/env/bin/supervisor &amp;</span><br></pre></td></tr></table></figure>
<h2 id="杀掉yarn上的任务"><a href="#杀掉yarn上的任务" class="headerlink" title="杀掉yarn上的任务"></a>杀掉yarn上的任务</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/yarn application -kill &lt;applicationId&gt;</span><br></pre></td></tr></table></figure>

<h2 id="统计hive数据仓库表占用空间"><a href="#统计hive数据仓库表占用空间" class="headerlink" title="统计hive数据仓库表占用空间"></a>统计hive数据仓库表占用空间</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python  </span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-  </span></span><br><span class="line"><span class="keyword">import</span> re  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line">  </span><br><span class="line">cmd = <span class="string">&quot;hdfs dfs -du -s /user/hive/warehouse/dwdb.db/* &gt; /tmp/hive_dwdb_space.txt&quot;</span>  </span><br><span class="line">os.system(cmd)  </span><br><span class="line">  </span><br><span class="line">path = <span class="string">r&quot;/tmp/hive_dwdb_space.txt&quot;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">sum</span> = <span class="number">0</span>  </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():  </span><br><span class="line">        ss = re.split(<span class="string">&quot;\s*&quot;</span>, line)  </span><br><span class="line">        s0 = <span class="built_in">int</span>(ss[<span class="number">0</span>])  </span><br><span class="line">        s1 = ss[<span class="number">1</span>]  </span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;prj_&quot;</span> <span class="keyword">in</span> s1:  </span><br><span class="line">            <span class="built_in">sum</span> += s0  </span><br><span class="line">            <span class="built_in">print</span>(s1)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sum: %0.2f GB&quot;</span> % (<span class="built_in">sum</span> * <span class="number">1.0</span> / <span class="number">1024</span> / <span class="number">1024</span> / <span class="number">1024</span>))</span><br></pre></td></tr></table></figure>
<h2 id="hadoop-mapreduce-Job-Name指定任务名"><a href="#hadoop-mapreduce-Job-Name指定任务名" class="headerlink" title="hadoop mapreduce Job Name指定任务名"></a>hadoop mapreduce Job Name指定任务名</h2><h3 id="sqoop参数"><a href="#sqoop参数" class="headerlink" title="sqoop参数"></a>sqoop参数</h3><blockquote>
<p>sqoop export/import -Dmapreduce.job.name=”&lt;你指定的任务名&gt;”</p>
</blockquote>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="http://xstarcd.github.io/wiki/Cloud/manual_start_hadoop_hbase.html">Hadoop、Hbase原生脚本说明</a></li>
<li><a href="http://blog.csdn.net/u011414200/article/details/50437356">Hadoop+ZooKeeper+HBase 启动顺序</a></li>
<li><a href="http://zjushch.iteye.com/blog/1736065">HBASE启动脚本/Shell解析</a></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop2.x 运维调优笔记</title>
    <url>/2018/05/02/ops/Hadoop/Hadoop2.x%20%E8%BF%90%E7%BB%B4%E8%B0%83%E4%BC%98%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="Hadoop运维调优笔记"><a href="#Hadoop运维调优笔记" class="headerlink" title="Hadoop运维调优笔记"></a>Hadoop运维调优笔记</h1><h2 id="yarn调配"><a href="#yarn调配" class="headerlink" title="yarn调配"></a>yarn调配</h2><h3 id="datanode-nodemanager系统配置"><a href="#datanode-nodemanager系统配置" class="headerlink" title="datanode/nodemanager系统配置"></a>datanode/nodemanager系统配置</h3><table>
<thead>
<tr>
<th>item</th>
<th>value</th>
</tr>
</thead>
<tbody><tr>
<td>sys</td>
<td>Centos7</td>
</tr>
<tr>
<td>cpu</td>
<td>16C（无超线程）</td>
</tr>
<tr>
<td>mem</td>
<td>16G</td>
</tr>
<tr>
<td>hdd</td>
<td>1000G</td>
</tr>
</tbody></table>
<h3 id="yarn和mapreduce"><a href="#yarn和mapreduce" class="headerlink" title="yarn和mapreduce"></a>yarn和mapreduce</h3><p>系统和datanode、nodemanager进程预留4C4G，yarn使用12C12G。目前测试集群30台，2台HA模式的master，28个工作节点，共计336核和336G内存<br>| item | value |<br>|–|–|<br>| yarn.nodemanager.resource.cpu-vcores | 12 |<br>| yarn.nodemanager.resource.memory-mb | 12288 |<br>| yarn.scheduler.minimum-allocation-vcores | 1 |<br>| yarn-scheduler.maximum-allocation-vcores | 8 |<br>| yarn.scheduler.increment-allocation-vcores | 1 |<br>| yarn.scheduler.minimum-allocation-mb | 1024 |<br>| yarn.scheduler.maximum-allocation-mb | 8192 |<br>| yarn.scheduler.increment-allocation-mb | 512 |<br>| yarn.app.mapreduce.am.resource.cpu-vcores | 1 |<br>| yarn.app.mapreduce.am.resource.mb | 1024 |<br>| mapreduce.map.cpu.vcores | 1 |<br>| mapreduce.map.memory.mb | 1024 |<br>| mapreduce.map.java.opts | -Xmx1024m |<br>| mapreduce.reduce.cpu.vcores | 1 |<br>| mapreduce.reduce.memory.mb | 1024 |<br>| mapreduce.reduce.java.opts | -Xmx1024m |<br>| mapreduce.task.io.sort.mb | 256 |<br>|  |  |</p>
<h3 id="新旧参数"><a href="#新旧参数" class="headerlink" title="新旧参数"></a>新旧参数</h3><p>更多可以参考：<a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/DeprecatedProperties.html">https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/DeprecatedProperties.html</a><br>| hadoop 0.x 1.x | Hadoop 2.x |<br>|–|–|<br>| mapred.child.java.opts |  |<br>| mapred.map.child.java.opts | mapreduce.map.java.opts |<br>| mapred.reduce.child.java.opts  | mapreduce.reduce.java.opts |<br>| mapred.job.map.memory.mb | mapreduce.map.memory.mb |<br>| mapred.job.reduce.memory.mb | mapreduce.reduce.memory.mb |<br>|  | yarn.app.mapreduce.am.command-opts |<br>|  | yarn.app.mapreduce.am.resource.mb |<br><code>*.java.opts</code>（java堆内存）的值应该为<code>-Xmx1024m</code>的格式，<code>memory.mb</code>的值应该为<code>1024</code>的格式。<br>推荐堆内存设置为容器内存的20%~25%。</p>
<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><h3 id="HiveServer高可用"><a href="#HiveServer高可用" class="headerlink" title="HiveServer高可用"></a>HiveServer高可用</h3><p>Ref: <a href="http://hainiubl.com/topics/19#HiveServer%E9%AB%98%E5%8F%AF%E7%94%A8">http://hainiubl.com/topics/19#HiveServer%E9%AB%98%E5%8F%AF%E7%94%A8</a></p>
<h3 id="hive开启本地模式"><a href="#hive开启本地模式" class="headerlink" title="hive开启本地模式"></a>hive开启本地模式</h3><p>Ref: <a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a></p>
<blockquote>
<p>SET mapreduce.framework.name=local;</p>
</blockquote>
<h3 id="datanode并行处理任务数"><a href="#datanode并行处理任务数" class="headerlink" title="datanode并行处理任务数"></a>datanode并行处理任务数</h3><blockquote>
<p>dfs.datanode.handler.count<br>一般原则是将其设置为集群大小的自然对数乘以20，即20logN，N为集群大小</p>
</blockquote>
<h2 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h2><ol>
<li>修改配置文件后要分发所有主机吗？<strong>要</strong></li>
<li>分发新的配置文件后，要重启集群吗？<br>A：如果是作业参数（mapreduce等），无需重启；如果是系统参数，如端口号等，需要重启。</li>
</ol>
<h2 id="草稿"><a href="#草稿" class="headerlink" title="草稿"></a>草稿</h2><ol>
<li>mapred.child.java.opts<br>如果您看到正在使用swap，请减少分配给每个任务的RAM数量<code>mapred.child.java.opts</code></li>
<li>使用LZO压缩<br>mapred.compress.map.output</li>
<li></li>
</ol>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ol>
<li>启用yarn日志聚集功能，tracking UI</li>
<li></li>
</ol>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li>默认参数：<a href="https://hadoop.apache.org/docs/r2.7.3/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">https://hadoop.apache.org/docs/r2.7.3/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml</a></li>
<li><a href="https://github.com/mattshma/bigdata/blob/master/hadoop/hdfs/tune.md">Hadoop参数调整</a></li>
<li><a href="https://my.oschina.net/dailidong/blog/675633">内存：Yarn-Mapreduce参数调整</a></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop2.x 配置文件研读</title>
    <url>/2018/04/25/ops/Hadoop/Hadoop2.x%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%A0%94%E8%AF%BB/</url>
    <content><![CDATA[<p>团队下来一个任务，要求我研究hadoop的三个基本配置文件core-site.xml,hdfs-site.xml,mapred-site.xml。以下为研读笔记</p>
<span id="more"></span>
<h1 id="默认配置"><a href="#默认配置" class="headerlink" title="默认配置"></a>默认配置</h1><p>浏览apache官网，依葫芦画瓢可以找到其他版本，举例如下:<br><a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/core-default.xml">https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/core-default.xml</a><br><a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</a><br><a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">https://hadoop.apache.org/docs/r2.7.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml</a></p>
<h2 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h2><p>hadoop.tmp.dir，临时目录，存放临时编译的jar包的解压后的class文件，临时文件。容量不足时，将导致无法传递jar包而至任务失败<br>hadoop.native.lib，本地库，压缩和解压时候用到<br>io.native.lib.available=true,本地库可以加快基本操作，例如IO，压缩等。<br>hadoop.http.filter.initializers，  <code>hadoop.security.*</code>安全类配置，不启用<br><code>hadoop.logfile.*</code>日志文件大小和数量，默认即可<br><strong>dfs.ha.fencing.methods</strong>，HDFS的HA功能的防脑裂方法。可以是内建的方法(例如shell和sshfence)或者用户定义的方法。<em>建议使用sshfence(hadoop:9922)，括号内的是用户名和端口，注意，这需要NN的2台机器之间能够免密码登陆</em><br><strong>fs.defaultFS</strong>，HA方式，这里设置服务名，例如：hdfs://ns1，hdfs的客户端访问hdfs需要此参数<br><strong>io.file.buffer.size</strong>，在读写文件时使用的缓存大小。这个大小应该是内存Page的倍数，比如1m，默认值4m<br>io.compression.codecs，压缩和解压缩方式，对于冷数据可以考虑压缩存储减少空间，压缩和解压都是全自动的，在挑选方式时会有可否划分等差异<br>fs.trash.interval，回收周期内，文件先移动到垃圾桶，不会真实删除，建议开启，建议4320（3天）<br>fs.file.impl，选择使用的文件系统。本地、hdfs、s3、hftp等等<code>fs.*.impl</code><br><code>fs.checkpoint.*</code>namenode的快照的时间间隔和目录等，默认即可<br>io.serializations，序列化，默认WritableSerialization即可<br><code>io.seqfile.*</code>和<code>io.mapfile.*</code>对于小文件的优化形式，小文件慢的话要开启优化这个<br>io.seqfile.compress.blocksize=1000000，SequenceFiles以块压缩方式压缩时，块大小大于此值时才启动压缩。<br><code>ipc.*</code>进程间通信，超时和队列的配置在此<br><code>hadoop.rpc.socket.*</code>rpc的socket配置，默认即可<br><strong>webinterface.private.actions</strong>，web交互行为，可以设置这个参数实际上就是为了方便测试用。允许在web 页面上对任务设置优先级以及kill 任务。需要注意的是，kill 任务是个缓慢的过程，它需要杀掉所有的任务task 然后才是任务结束。如果task数量多，可能有点慢，需要一些耐心等待。<br><code>topology.*</code>机架相关，我们全云化机器，没法配机架<br>fs.AbstractFileSystem.viewfs.impl=org.apache.hadoop.fs.viewfs.ViewFs，<br>在实现federation联邦特性时，客户端可以部署此系统，方便同时访问多个nameservice</p>
<h2 id="hdfs-default-html"><a href="#hdfs-default-html" class="headerlink" title="hdfs-default.html"></a>hdfs-default.html</h2><table>
<thead>
<tr>
<th>配置项</th>
<th>端口</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>dfs.http.address</td>
<td>50070</td>
<td>namenode情况</td>
</tr>
<tr>
<td>dfs.secondary.http.address</td>
<td>50090</td>
<td>secondaryNameNode情况，<em>使用了HA后，就不再使用SNN了</em></td>
</tr>
<tr>
<td>dfs.datanode.address</td>
<td>50010</td>
<td>TCP管理服务</td>
</tr>
<tr>
<td>dfs.datanode.http.address</td>
<td>50075</td>
<td>HTTP访问</td>
</tr>
<tr>
<td>dfs.datanode.ipc.address</td>
<td>50020</td>
<td>IPC服务</td>
</tr>
<tr>
<td>dfs.datanode.https.address</td>
<td>50475</td>
<td>https访问</td>
</tr>
<tr>
<td>dfs.https.address</td>
<td>50470</td>
<td>https访问</td>
</tr>
<tr>
<td>dfs.journalnode.rpc-address</td>
<td>8485</td>
<td>JournalNode RPC服务地址和端口</td>
</tr>
<tr>
<td>dfs.journalnode.http-address</td>
<td>8480</td>
<td>JournalNode的HTTP地址和端口。端口设置为0表示随机选择</td>
</tr>
<tr>
<td>dfs.namenode.backup.address</td>
<td>50100</td>
<td>NN的BK节点地址和端口，<em>使用HA，就不需要关注此选项了。建议不使用BK节点</em></td>
</tr>
<tr>
<td>dfs.namenode.backup.http-address</td>
<td>50105</td>
<td><em>使用HA，就不需要关注此选项了。建议不使用BK节点</em></td>
</tr>
<tr>
<td>mapreduce.jobhistory.address</td>
<td>10020</td>
<td>MapReduce JobHistory Server地址</td>
</tr>
<tr>
<td>mapreduce.jobhistory.webapp.address</td>
<td>19888</td>
<td>MapReduce JobHistory Server Web UI地址</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>dfs.datanode.handler.count，datanode服务连接数，集群配置强悍则需要调高<br>dfs.namenode.handler.count=10，nn服务连接数，集群强悍可提高<br>dfs.https.enable，https，不开启。<code>dfs.https.*</code>相关配置<br><code>dfs.datanode.dns.*</code>datanode向namenode注册时候，可以用dns，我们不用<br>dfs.namenode.safemode.threshold-pct=0.999f，副本不足将导致安全模式<br><strong>dfs.datanode.balance.bandwidthPerSec</strong>数据平衡时，最大使用带宽，默认1M，建议改大到10M<br><large><strong>dfs.namenode.support.allow.format=true</strong>，NN是否允许被格式化，生产环境务必要改为FALSE！！！<large><br>dfs.nameservices，federation,NN联邦时候需要配置多个，否则一个即可<br>dfs.namenode.audit.loggers，审查日志的实现类列表，能够接收audit事件。默认已开启，但<strong>未知怎么使用</strong><br>dfs.namenode.logging.level=info，DFS的NN的日志等级。值可以是：info，dir(跟踪命名空间变动)，”block” (跟踪块的创建删除，replication变动)，或者”all”.<br>dfs.namenode.replication.considerLoad=true，设定在选择存放目标时是否考虑负载。需要，保持默认即可<br>dfs.namenode.fs-limits.max-component-length=0，路径中每个部分的最大字节长度（目录名，文件名的长度）。0表示不检查长度。<em>长文件名影响性能</em><br>dfs.namenode.fs-limits.max-directory-items=0，目录下文件数上限<br>dfs.namenode.fs-limits.min-block-size=1048576，最小block，字节，严重影响性能<br>dfs.namenode.fs-limits.max-blocks-per-file=1048576，防止超大文件<br><code>dfs.image.transfer.*</code>HA模式使用不到，不关注<br>dfs.datanode.drop.cache.behind.reads/writes=FALSE，大且不可重复数据，如Hbase随机读写数据，扔掉缓存可提高性能，前提需要配置本地库<br>dfs.namenode.avoid.read.stale.datanode=FALSE，避免从脏dn上读取数据，脏dn指已经没有心跳信息的dn<br><strong>dfs.webhdfs.enabled=FALSE</strong>，在nn和dn上开启restAPI访问功能，HortonWorks开发捐给Apache，HttpFS由Clouera也捐给了Apache，HUE配置需要httpfs。如果HA模式下，hue必须使用HttpFS（只能用自家的，呵呵）<br>dfs.hosts，接受或排除的host文件</p>
<h2 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h2><p><strong>mapreduce.job.name</strong>，job名称，<br>hadoop.job.history.(user.)location，制定历史文件存放目录<br><code>io.sort.*</code> 排序相关参数，内存用量，占比多少开始写硬盘。大量排序时可优化<br>mapreduce.map.memory.mb，map使用内存，<code>RAM-per-container</code><br>mapreduce.reduce.memory.mb，reduce使用内存，<code>2 * RAM-per-container</code><br>mapreduce.map.java.opts，<code>0.8 * RAM-per-container</code><br>mapreduce.reduce.java.opts, <code>0.8 * 2 * RAM-per-container</code><br>mapred.child.java.opts，每个任务最大jvm heap大小为1000M， -Xmx1000M -Dfile.encoding=UTF8 -XX:-UseGCOverheadLimit<br>mapred.map/reduce.tasks，不知道yarn管理之后还有没有，默认值2/1应该偏小<br><code>mapred.output.compress.*</code>启用压缩相关<br>cdh推荐配置<br>|配置项 | 推荐参数 | 注释|<br>|–|–|–|<br>|yarn.app.mapreduce.am.resource.cpu-vcores | 1 | AM container vcore reservation |<br>|yarn.app.mapreduce.am.resource.mb | 1024 | AM container memory reservation |<br>|ApplicationMaster Java Maximum Heap Size (available in CM) | 1024 | AM Java heap size |<br>|mapreduce.map.cpu.vcores | 1 | Map task vcore reservation |<br>|mapreduce.map.memory.mb | 1024 | Map task memory reservation |<br>|mapreduce.map.java.opts.max.heap | 1024 | Map task Java heap size |<br>|mapreduce.reduce.cpu.vcores | 1 | Reduce task vcore reservation |<br>|mapreduce.reduce.memory.mb | 1024 | Reduce task memory reservation |<br>|mapreduce.reduce.java.opts | 1024 | Reduce Task Java heap size |<br>|mapreduce.task.io.sort.mb | 256 | Spill/Sort memory reservation |</p>
<h2 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h2><h3 id="日志聚合功能"><a href="#日志聚合功能" class="headerlink" title="日志聚合功能"></a>日志聚合功能</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/var/log/hadoop-yarn/apps<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>[需要修改目录]Where to aggregate logs to.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>86400<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>yarn.nodemanager.resource.memory-mb，直接设为nn的物理内存<br>yarn.scheduler.minimum/maximum-allocation-mb，最小1G，最大8G</p>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop3.3.2 on Windows10</title>
    <url>/2022/03/20/ops/Hadoop/Hadoop3.3.2%20on%20Windows10/</url>
    <content><![CDATA[<h1 id="Hadoop3-3-2-on-Windows10"><a href="#Hadoop3-3-2-on-Windows10" class="headerlink" title="Hadoop3.3.2 on Windows10"></a>Hadoop3.3.2 on Windows10</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在windows系统上进行hadoop相关开发，不需要高可用，仅用作开发调试还是很方便的。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>hadoop: <a href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz">3.3.2</a><br>jdk: 1.8<br>winutils 3.3.x 和 hadoop.dll: <a href="https://github.com/kontext-tech/winutils/tree/master/hadoop-3.3.1/bin">https://github.com/kontext-tech/winutils/tree/master/hadoop-3.3.1/bin</a></p>
<p>实测3.3.1的winutils可以适配3.3.2的hadoop版本。本机3.2.2hadoop在启动datanode时会失败。</p>
<h2 id="安装和配置步骤"><a href="#安装和配置步骤" class="headerlink" title="安装和配置步骤"></a>安装和配置步骤</h2><p>下载解压hadoop，假设解压到<code>D:\PortableSoftware\hadoop-3.3.2</code><br>下载对应版本的<code>winutils.exe</code>和<code>hadoop.dll</code>复制到<code>D:\PortableSoftware\hadoop-3.3.2\bin</code></p>
<ol>
<li>JAVA_HOME,如果你的java安装路径是含有”Program Files”, 使用<code>Progra~1</code>代替”Program Files”，或使用<code>Progra~2</code> 代替 “Program Files(x86)”</li>
<li>HADOOP_HOME</li>
<li>PATH变量加入<code>%JAVA_HOME%\bin;%HADOOP_HOME%\bin;%HADOOP_HOME%\sbin</code></li>
<li>检查： 新开cmd窗口，输入<code>hadoop -version</code></li>
<li>配置<code>%HADOOP_HOME%\etc\hadoop\hdfs-site.xml</code></li>
<li>配置<code>%HADOOP_HOME%\etc\hadoop\core-site.xml</code></li>
<li>配置<code>%HADOOP_HOME%\etc\hadoop\mapred-site.xml</code></li>
<li>配置<code>%HADOOP_HOME%\etc\hadoop\yarn-site.xml</code><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- hdfs-site.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///D:/PortableSoftware/hadoop-3.3.2/data/dfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///D:/PortableSoftware/hadoop-3.3.2/data/dfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- core-site.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- mapred-site.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>MapReduce framework name<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- yarn-site.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Yarn Node Manager Aux Service<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>试验：</p>
<blockquote>
<p>hadoop version</p>
</blockquote>
<h2 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动HDFS</h2><p>第一次使用需要<code>hdfs namenode -format</code></p>
<p>启动:</p>
<blockquote>
<p>start-dfs.cmd</p>
</blockquote>
<p>停止:</p>
<blockquote>
<p>stop-dfs.cmd</p>
</blockquote>
<p>访问：</p>
<blockquote>
<p><a href="http://localhost:9870/">http://localhost:9870/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive on Spark 安装配置</title>
    <url>/2018/03/27/ops/Hadoop/Hive%20on%20Spark%20%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="hive-on-spark-安装配置"><a href="#hive-on-spark-安装配置" class="headerlink" title="hive on spark 安装配置"></a>hive on spark 安装配置</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>网上的教程都说spark官网预编译的二进制文件含有hive部分，不能直接使用，需源码编译，包括hive的wiki也提及需要不含hive的jars。经过实践也可以通过剔除hive相关包，使用预编译的spark包完成hive-on-spark的部署。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>hadoop: 2.7.3<br>hive: 2.3.2<br>spark: 2.2.0<br>6个节点，4个nodemanager<br>hive 的wiki说只有对应的版本能保证兼容性，不是完全兼容也可以的。只是不知道有无隐患。</p>
<h2 id="yarn配置"><a href="#yarn配置" class="headerlink" title="yarn配置"></a>yarn配置</h2><p>修改之后需要分发集群并重启</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /home/hadoop/soft/hadoop/etc/hadoop/yarn-site.xml</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h2 id="hdfs准备路径和jar包"><a href="#hdfs准备路径和jar包" class="headerlink" title="hdfs准备路径和jar包"></a>hdfs准备路径和jar包</h2><h3 id="新建spark-log目录"><a href="#新建spark-log目录" class="headerlink" title="新建spark-log目录"></a>新建spark-log目录</h3><blockquote>
<p>hdfs dfs -mkdir -p hdfs://ns1/spark/spark-log</p>
</blockquote>
<h3 id="上传jar包"><a href="#上传jar包" class="headerlink" title="上传jar包"></a>上传jar包</h3><blockquote>
<p>hdfs dfs -mkdir -p hdfs://ns1/spark/jars<br>hdfs dfs -put $SPARK_HOME/jars/*.jar hdfs://ns1/spark/jars/</p>
</blockquote>
<h2 id="spark配置"><a href="#spark配置" class="headerlink" title="spark配置"></a>spark配置</h2><p>配置<code>spark-env.sh</code>、<code>slaves</code>和<code>spark-defaults.conf</code>三个文件<br><code>spark-env.sh</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_MASTER_WEBUI_PORT=8081</span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/home/hadoop/soft/scala</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/home/hadoop/soft/jdk</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hadoop/soft/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line">SPARK_MASTER_IP=master1</span><br><span class="line">SPARK_LOCAL_DIRS=/home/hadoop/soft/spark</span><br><span class="line">SPARK_DRIVER_MEMORY=4G</span><br></pre></td></tr></table></figure>
<p><code>slaves</code> 每行一个hostname或ip</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hd2</span><br><span class="line">hd4</span><br><span class="line">hd5</span><br><span class="line">hd6</span><br><span class="line">hd7</span><br></pre></td></tr></table></figure>
<p><code>spark-defaults.conf</code><br>以下配置按照NodeManager是12C12G计算</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">spark.master                        yarn</span><br><span class="line">spark.home                          /home/hadoop/soft/spark</span><br><span class="line">spark.eventLog.enabled              <span class="literal">true</span></span><br><span class="line">spark.eventLog.<span class="built_in">dir</span>                  hdfs://ns1/spark/spark-log</span><br><span class="line">spark.serializer                    org.apache.spark.serializer.KryoSerializer</span><br><span class="line"><span class="comment"># hive on spark 建议5/6/7</span></span><br><span class="line">spark.executor.cores                6</span><br><span class="line"><span class="comment"># 按6*12G/12vcores计算</span></span><br><span class="line">spark.executor.memory               5222m</span><br><span class="line"><span class="comment"># 28个计算节点*每个节点2个executor</span></span><br><span class="line">spark.executor.instances            56</span><br><span class="line"><span class="comment"># 所有core的两三倍：56*6*3=1008</span></span><br><span class="line">spark.default.parallelism           1000</span><br><span class="line"><span class="comment"># 15% * spark.executor.memory</span></span><br><span class="line">spark.yarn.executor.memoryOverhead  921m</span><br><span class="line">spark.driver.memory                 4g</span><br><span class="line">spark.yarn.driver.memoryOverhead    400m</span><br><span class="line">spark.yarn.jars                     hdfs://ns1/spark/jars/*.jar</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>拷贝到hive的配置目录，使调用hive时能识别使用spark-defaults.conf</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s ~/soft/spark/conf/spark-defaults.conf ~/soft/hive/conf/</span><br></pre></td></tr></table></figure>
<h3 id="验证spark"><a href="#验证spark" class="headerlink" title="验证spark"></a>验证spark</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client ./examples/jars/spark-examples_2.11-2.2.0.jar 10</span><br></pre></td></tr></table></figure>
<h2 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h2><h3 id="添加必要的依赖库"><a href="#添加必要的依赖库" class="headerlink" title="添加必要的依赖库"></a>添加必要的依赖库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s /home/hadoop/soft/spark/jars/scala-library-2.11.8.jar /home/hadoop/soft/hive/lib/</span><br><span class="line"><span class="built_in">ln</span> -s /home/hadoop/soft/spark/jars/spark-network-common_2.11-2.2.0.jar /home/hadoop/soft/hive/lib/</span><br><span class="line"><span class="built_in">ln</span> -s /home/hadoop/soft/spark/jars/spark-core_2.11-2.2.0hiv.jar /home/hadoop/soft/hive/lib/</span><br></pre></td></tr></table></figure>
<h3 id="剔除spark中hive的库"><a href="#剔除spark中hive的库" class="headerlink" title="剔除spark中hive的库"></a>剔除spark中hive的库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> hive-jars</span><br><span class="line"><span class="built_in">mv</span> /home/hadoop/soft/spark/jars/hive*.jar /home/hadoop/soft/spark/hive-jars</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="启用spark引擎"><a href="#启用spark引擎" class="headerlink" title="启用spark引擎"></a>启用spark引擎</h3><p>1为临时方案，2为默认配置</p>
<ol>
<li>在命令行交互（进入hive之后）<code>set hive.execution.engine=spark;</code></li>
<li>配置hive.site.xml文件，配置<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.execution.engine<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>spark<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      Expects one of [mr, tez, spark].</span><br><span class="line">      Chooses execution engine. Options are: mr (Map reduce, default), tez, spark. While MR</span><br><span class="line">      remains the default engine for historical reasons, it is itself a historical engine</span><br><span class="line">      and is deprecated in Hive 2 line. It may be removed without further warning.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="验证hive-on-spark"><a href="#验证hive-on-spark" class="headerlink" title="验证hive on spark"></a>验证hive on spark</h3></li>
</ol>
<ul>
<li>  命令行输入 hive，进入hive CLI</li>
<li>  set hive.execution.engine=spark; (将执行引擎设为Spark，默认是mr，退出hive CLI后，回到默认设置。若想让引擎默认为Spark，需要在hive-site.xml里设置）</li>
<li>  create table test(ts BIGINT,line STRING); (创建表）</li>
<li>  select count(*) from test;</li>
<li>  若整个过程没有报错，并出现正确结果，则Hive on Spark配置成功。</li>
</ul>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>因为在yarn上执行，拷贝spark的jars到hdfs上能避免每次拷贝。<br>如果仅是在hive中使用spark，可以在hive-site.xml中配置。由于在<code>spark-defaults.conf</code>已经配置过，这里可以不配置</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>spark.yarn.jars<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ns1/spark/jars/*.jar<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>其他</strong></p>
<ol>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark:+Getting+Started#HiveonSpark:GettingStarted-Configurationpropertydetails">hive的wiki</a></li>
<li><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=2888665">Cloudera的翻译</a></li>
<li><a href="https://tech.meituan.com/spark-tuning-basic.html">spark参数配置-美团</a></li>
<li><a href="http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/">spark参数配置-cloudera博客</a></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos 离线安装通用方法(Docker为例)</title>
    <url>/2018/03/13/ops/Linux/Centos%20%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E9%80%9A%E7%94%A8%E6%96%B9%E6%B3%95(Docker%E4%B8%BA%E4%BE%8B)/</url>
    <content><![CDATA[<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>yum install有参数--downloadonly，可以只下载不安装，搭配--downloaddir=DLDIR参数可以下载依赖包，完成离线安装。<br>命令实例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># online machine: pwd --&gt; /root</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /root/download</span><br><span class="line">yum install --downloadonly --downloaddir=/root/download &lt;package-name&gt;</span><br><span class="line">tar zcf download.tar.gz download/</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># offline machine: pwd --&gt; /root</span></span><br><span class="line">tar xf download.tar.gz</span><br><span class="line">yum localinstall download/*</span><br></pre></td></tr></table></figure>
<h1 id="docker实例"><a href="#docker实例" class="headerlink" title="docker实例"></a>docker实例</h1><p>按照官网说明，使用以上命令，获得的rpm包，基于Centos7.0-1406系统<br><a href="https://github.com/Tony36051/docker-installer/tree/master/RPM-based/docker-ce-17.12-CentOS-7.0-1406">https://github.com/Tony36051/docker-installer/tree/master/RPM-based/docker-ce-17.12-CentOS-7.0-1406</a><br>root权限执行一下命令即可:</p>
<blockquote>
<p>sudo sh install.sh</p>
</blockquote>
<h2 id="可能的坑"><a href="#可能的坑" class="headerlink" title="可能的坑"></a>可能的坑</h2><p>rpm包有重复、冲突，体现为在安装xxx包时候，依赖项Requires，但是有重复或冲突，需要卸载Removing，并被yyy包更新Updated。但是这个过程不能自动化，因为yum不知道你冲突后要保留哪个。例子如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">--&gt; Processing Dependency: rpm = 4.11.3-25.el7 <span class="keyword">for</span> package: rpm-libs-4.11.3-25.el7.x86_64</span><br><span class="line">--&gt; Finished Dependency Resolution</span><br><span class="line">Error: Package: 1:net-snmp-agent-libs-5.7.2-24.el7.i686 (@Server)</span><br><span class="line">           Requires: librpm.so.3</span><br><span class="line">           Removing: rpm-libs-4.11.3-17.el7.i686 (@Server)</span><br><span class="line">               librpm.so.3</span><br><span class="line">           Updated By: rpm-libs-4.11.3-25.el7.x86_64 (/rpm-libs-4.11.3-25.el7.x86_64)</span><br><span class="line">               Not found</span><br><span class="line">Error: Package: rpm-build-libs-4.11.3-17.el7.x86_64 (@Server)</span><br><span class="line">           Requires: rpm-libs(x86-64) = 4.11.3-17.el7</span><br><span class="line">           Removing: rpm-libs-4.11.3-17.el7.x86_64 (@Server)</span><br><span class="line">               rpm-libs(x86-64) = 4.11.3-17.el7</span><br><span class="line">           Updated By: rpm-libs-4.11.3-25.el7.x86_64 (/rpm-libs-4.11.3-25.el7.x86_64)</span><br><span class="line">               rpm-libs(x86-64) = 4.11.3-25.el7</span><br><span class="line">Error: Package: 1:net-snmp-agent-libs-5.7.2-24.el7.i686 (@Server)</span><br><span class="line">           Requires: librpmio.so.3</span><br><span class="line">           Removing: rpm-libs-4.11.3-17.el7.i686 (@Server)</span><br><span class="line">               librpmio.so.3</span><br><span class="line">           Updated By: rpm-libs-4.11.3-25.el7.x86_64 (/rpm-libs-4.11.3-25.el7.x86_64)</span><br><span class="line">               Not found</span><br><span class="line">Error: Package: rpm-libs-4.11.3-25.el7.x86_64 (/rpm-libs-4.11.3-25.el7.x86_64)</span><br><span class="line">           Requires: rpm = 4.11.3-25.el7</span><br><span class="line">           Installed: rpm-4.11.3-17.el7.x86_64 (@Server)</span><br><span class="line">               rpm = 4.11.3-17.el7</span><br><span class="line"> You could try using --skip-broken to work around the problem</span><br><span class="line"> You could try running: rpm -Va --nofiles --nodigest</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><ul>
<li>查看重复包<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -vqa | grep net-snmp-agent-</span><br><span class="line">net-snmp-agent-libs-5.7.2-24.el7.x86_64</span><br><span class="line">net-snmp-agent-libs-5.7.2-24.el7.i686</span><br></pre></td></tr></table></figure></li>
<li>卸载冲突包<br>下面是卸载不符合系统的包，也有可能完把老版本全删掉，直接装新的<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum remove rpm-libs-4.11.3-17.el7.i686</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Centos</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos 6/7的防火墙配置</title>
    <url>/2017/08/22/ops/Linux/Centos-6-7-firewall-configuration/</url>
    <content><![CDATA[<p>Centos 6/7的防火墙配置略有差异，仅作小记。</p>
<span id="more"></span>
<h2 id="Centos-6-防火墙端口"><a href="#Centos-6-防火墙端口" class="headerlink" title="Centos 6 防火墙端口"></a>Centos 6 防火墙端口</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptables -I INPUT -p tcp --dport 8080 -j ACCEPT <span class="comment">#开启8080端口  </span></span><br><span class="line">iptables save <span class="comment">#保存配置  </span></span><br><span class="line">iptables restart <span class="comment">#重启服务  </span></span><br></pre></td></tr></table></figure>


<h2 id="Centos-7"><a href="#Centos-7" class="headerlink" title="Centos 7"></a>Centos 7</h2><p>开启端口</p>
<blockquote>
<p>firewall-cmd –zone=public –add-port=80/tcp –permanent</p>
</blockquote>
<p>命令含义：<br>–zone #作用域<br>–add-port=80/tcp  #添加端口，格式为：端口/通讯协议<br>–permanent  #永久生效，没有此参数重启后失效</p>
<p>重启防火墙</p>
<blockquote>
<p>firewall-cmd –reload</p>
</blockquote>
<h2 id="mermaid"><a href="#mermaid" class="headerlink" title="mermaid"></a>mermaid</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">st=&gt;start: Start</span><br><span class="line">e=&gt;end</span><br><span class="line">op=&gt;operation: My Operation</span><br><span class="line">cond=&gt;condition: Yes or No?</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line">cond(yes)-&gt;e</span><br><span class="line">cond(no)-&gt;op</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Firewall</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux swap占用过高</title>
    <url>/2019/05/17/ops/Linux/Linux%20swap%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98/</url>
    <content><![CDATA[<p>OS的监控告警，swap占用超过80%，记录解决思路</p>
<span id="more"></span>
<h2 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h2><p>监控告警Linux系统的swap占用超过80%。</p>
<h2 id="相关知识"><a href="#相关知识" class="headerlink" title="相关知识"></a>相关知识</h2><h3 id="Swap使用过高解决方法"><a href="#Swap使用过高解决方法" class="headerlink" title="Swap使用过高解决方法"></a>Swap使用过高解决方法</h3><p>首先要保证内存剩余要大于等于swap使用量，否则会宕机！根据内存机制，swap分区一旦释放，所有存放在swap分区的文件都会转存到物理内存上。通常通过重新挂载swap分区完成释放swap。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Swapoff –a 或 swapoff /dev/sda2</span><br><span class="line"><span class="comment"># 停止swap 使用free查看，成功后swap空间会归零</span></span><br><span class="line">Swapon –a 或 swapon /dev/sda2</span><br><span class="line"><span class="comment"># 启动swap 使用free查看，成功后swap回复</span></span><br></pre></td></tr></table></figure>
<h3 id="内存占用多少后启动物理内存"><a href="#内存占用多少后启动物理内存" class="headerlink" title="内存占用多少后启动物理内存"></a>内存占用多少后启动物理内存</h3><blockquote>
<p>cat /proc/sys/vm/swappiness<br>60</p>
</blockquote>
<p>上面这个60代表物理内存在使用60%的时候才会使用swap<br>swappiness=0的时候表示最大限度使用物理内存，然后才是 swap空间，<br>swappiness＝100的时候表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面。</p>
<p>通常情况下：<br>swap分区设置建议是内存的两倍 （内存小于等于4G时），如果内存大于4G，swap只要比内存大就行。另外尽量的将swappiness调低，这样系统的性能会更好。  </p>
<p>修改swappiness参数<br>临时性修改：</p>
<blockquote>
<p>sysctl vm.swappiness=10<br>vm.swappiness = 10</p>
</blockquote>
<blockquote>
<p>cat /proc/sys/vm/swappiness<br>10</p>
</blockquote>
<p>永久性修改：</p>
<blockquote>
<p>vim /etc/sysctl.conf<br>vm.swappiness = 35</p>
</blockquote>
<blockquote>
<p>sysctl -p  </p>
</blockquote>
<p>查看是否生效：<br>cat /proc/sys/vm/swappiness<br>35</p>
<h3 id="检查哪个进程使用最多swap内存"><a href="#检查哪个进程使用最多swap内存" class="headerlink" title="检查哪个进程使用最多swap内存"></a>检查哪个进程使用最多swap内存</h3><p>手动命令：</p>
<blockquote>
<p>在 top 命令中，按 f，就是 field 的意思，调出列选项，把 swap 列显示出来，然后按 O，大写的，应该是 order 的意思，选择按照 swap 列进行排序，可以看到下面的结果</p>
</blockquote>
<p>脚本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">##############################################################################</span></span><br><span class="line"><span class="comment"># 脚本功能 ： 列出正在占用swap的进程。</span></span><br><span class="line"><span class="comment">###############################################################################</span></span><br><span class="line"> </span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;PID\t\tSwap\t\tProc_Name&quot;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 拿出/proc目录下所有以数字为名的目录（进程名是数字才是进程，其他如sys,net等存放的是其他信息）</span></span><br><span class="line"><span class="keyword">for</span> pid <span class="keyword">in</span> `<span class="built_in">ls</span> -l /proc | grep ^d | awk <span class="string">&#x27;&#123; print $9 &#125;&#x27;</span>| grep -v [^0-9]`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="comment"># 让进程释放swap的方法只有一个：就是重启该进程。或者等其自动释放。放</span></span><br><span class="line">    <span class="comment"># 如果进程会自动释放，那么我们就不会写脚本来找他了，找他都是因为他没有自动释放。</span></span><br><span class="line">    <span class="comment"># 所以我们要列出占用swap并需要重启的进程，但是init这个进程是系统里所有进程的祖先进程</span></span><br><span class="line">    <span class="comment"># 重启init进程意味着重启系统，这是万万不可以的，所以就不必检测他了，以免对系统造成影响。</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="variable">$pid</span> -eq 1 ];<span class="keyword">then</span> <span class="built_in">continue</span>;<span class="keyword">fi</span></span><br><span class="line">    grep -q <span class="string">&quot;Swap&quot;</span> /proc/<span class="variable">$pid</span>/smaps 2&gt;/dev/null</span><br><span class="line">    <span class="keyword">if</span> [ $? -eq 0 ];<span class="keyword">then</span></span><br><span class="line">        swap=$(grep Swap /proc/<span class="variable">$pid</span>/smaps \</span><br><span class="line">            | gawk <span class="string">&#x27;&#123; sum+=$2;&#125; END&#123; print sum &#125;&#x27;</span>)</span><br><span class="line">        proc_name=$(ps aux | grep -w <span class="string">&quot;<span class="variable">$pid</span>&quot;</span> | grep -v grep \</span><br><span class="line">            | awk <span class="string">&#x27;&#123; for(i=11;i&lt;=NF;i++)&#123; printf(&quot;%s &quot;,$i); &#125;&#125;&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> [ <span class="variable">$swap</span> -gt 0 ];<span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> -e <span class="string">&quot;<span class="variable">$&#123;pid&#125;</span>\t<span class="variable">$&#123;swap&#125;</span>\t<span class="variable">$&#123;proc_name&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span> | <span class="built_in">sort</span> -k2 -n | awk -F<span class="string">&#x27;\t&#x27;</span> <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    pid[NR]=$1;</span></span><br><span class="line"><span class="string">    size[NR]=$2;</span></span><br><span class="line"><span class="string">    name[NR]=$3;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">END&#123;</span></span><br><span class="line"><span class="string">    for(id=1;id&lt;=length(pid);id++)</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">        if(size[id]&lt;1024)</span></span><br><span class="line"><span class="string">            printf(&quot;%-10s\t%15sKB\t%s\n&quot;,pid[id],size[id],name[id]);</span></span><br><span class="line"><span class="string">        else if(size[id]&lt;1048576)</span></span><br><span class="line"><span class="string">            printf(&quot;%-10s\t%15.2fMB\t%s\n&quot;,pid[id],size[id]/1024,name[id]);</span></span><br><span class="line"><span class="string">        else</span></span><br><span class="line"><span class="string">            printf(&quot;%-10s\t%15.2fGB\t%s\n&quot;,pid[id],size[id]/1048576,name[id]);</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><ol>
<li>打开大的文件或物理内存被占用，都可能导致swap过高。</li>
<li>内存很大的机器建议直接不要swap内存</li>
<li>最后gan<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE0MzIwMzMyNSwxOTYzMzEwODUwXX0=</li>
</ol>
<p>–&gt;</p>
]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 常用命令组合</title>
    <url>/2018/05/02/ops/Linux/Linux%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%BB%84%E5%90%88/</url>
    <content><![CDATA[<p>身为半个运维人员，日常使用Linux命令组合很多，每次都记不住，特此笔记。</p>
<span id="more"></span>
<h2 id="查看系统信息"><a href="#查看系统信息" class="headerlink" title="查看系统信息"></a>查看系统信息</h2><blockquote>
<p>lsb_release -a</p>
</blockquote>
<h2 id="硬件信息"><a href="#硬件信息" class="headerlink" title="硬件信息"></a>硬件信息</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 总核数 = 物理CPU个数 X 每颗物理CPU的核数 </span></span><br><span class="line"><span class="comment"># 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数</span></span><br><span class="line"><span class="comment"># 查看物理CPU个数 </span></span><br><span class="line"><span class="built_in">cat</span> /proc/cpuinfo| grep <span class="string">&quot;physical id&quot;</span>| <span class="built_in">sort</span>| <span class="built_in">uniq</span>| <span class="built_in">wc</span> -l</span><br><span class="line"><span class="comment"># 查看每个物理CPU中core的个数(即核数) </span></span><br><span class="line"><span class="built_in">cat</span> /proc/cpuinfo| grep <span class="string">&quot;cpu cores&quot;</span>| <span class="built_in">uniq</span> </span><br><span class="line">查看逻辑CPU的个数 </span><br><span class="line"><span class="built_in">cat</span> /proc/cpuinfo| grep <span class="string">&quot;processor&quot;</span>| <span class="built_in">wc</span> -l</span><br><span class="line"><span class="comment"># 查看CPU信息（型号）</span></span><br><span class="line"><span class="built_in">cat</span> /proc/cpuinfo | grep name | <span class="built_in">cut</span> -f2 -d: | <span class="built_in">uniq</span> -c</span><br><span class="line"><span class="comment"># 查看内存信息</span></span><br><span class="line"><span class="built_in">cat</span> /proc/meminfo</span><br></pre></td></tr></table></figure>
<h2 id="进程相关"><a href="#进程相关" class="headerlink" title="进程相关"></a>进程相关</h2><p>通过ps、grep和kill批量杀死进程</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pkill -f &lt;部分进程名&gt;</span><br><span class="line">ps aux|grep python|awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>|xargs <span class="built_in">kill</span> -9</span><br></pre></td></tr></table></figure>
<h3 id="查看某进程CPU、内存占用"><a href="#查看某进程CPU、内存占用" class="headerlink" title="查看某进程CPU、内存占用"></a>查看某进程CPU、内存占用</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">top -p 2913</span><br><span class="line"><span class="built_in">cat</span> /proc/2913/status  <span class="comment"># VmRSS对应的值就是物理内存占用</span></span><br></pre></td></tr></table></figure>
<h2 id="批量执行"><a href="#批量执行" class="headerlink" title="批量执行"></a>批量执行</h2><h3 id="pssh"><a href="#pssh" class="headerlink" title="pssh"></a>pssh</h3><h4 id="pssh使用sudo"><a href="#pssh使用sudo" class="headerlink" title="pssh使用sudo"></a>pssh使用sudo</h4><p>关键是使用ssh的参数<code>-tt</code>, 在pssh使用<code>-X</code>传递ssh参数。<br>举例如何使用：批量修改密码，前提已经有ssh互信</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> chpass.txt</span><br><span class="line">hadoop:hadoop_password</span><br><span class="line">pscp -h list_ip.txt chpass.txt /tmp/chpass.txt</span><br><span class="line">pssh -h list_ip.txt -i -X -tt <span class="string">&quot;sudo chpasswd &lt; /tmp/chpass.txt&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="centos7设置yum代理"><a href="#centos7设置yum代理" class="headerlink" title="centos7设置yum代理"></a>centos7设置yum代理</h2><p>1.在/etc/yum.conf 添加<br>proxy=<a href="http://192.168.1.10:8088/">http://192.168.1.10:8088/</a><br>2.如果代理环境中有证书，回导致源更新失败，可以继续添加<br>sslverify=false</p>
<h2 id="免密登录ssh-copy-id"><a href="#免密登录ssh-copy-id" class="headerlink" title="免密登录ssh-copy-id"></a>免密登录ssh-copy-id</h2><p><strong>ssh-keygen</strong> 产生公钥与私钥对.<br><strong>ssh-copy-id</strong>  将本机的公钥复制到远程机器的authorized_keys文件中，ssh-copy-id也能让你有到远程机器的home, ~./ssh , 和 ~/.ssh/authorized_keys的权利</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.x.xxx</span><br></pre></td></tr></table></figure>

<h2 id="windows换行转为linux版-解决-M问题"><a href="#windows换行转为linux版-解决-M问题" class="headerlink" title="windows换行转为linux版,解决^M问题"></a>windows换行转为linux版,解决^M问题</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">**单个的文件装换**  </span><br><span class="line">sed -i <span class="string">&#x27;s/\r//&#x27;</span> filename  </span><br><span class="line">  </span><br><span class="line">**批量的文件装换**  </span><br><span class="line">sed -i <span class="string">&#x27;s/\r//&#x27;</span> filename1 filename2 ...  </span><br><span class="line">或  </span><br><span class="line">find ./  -name <span class="string">&quot;*.sh&quot;</span> |xargs sed -i <span class="string">&#x27;s/\r//&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="压缩成带有时间文件名的文件"><a href="#压缩成带有时间文件名的文件" class="headerlink" title="压缩成带有时间文件名的文件"></a>压缩成带有时间文件名的文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zcvf somedir-$(<span class="built_in">date</span> +%Y%m%d-%H%M).tar.gz somedir/</span><br></pre></td></tr></table></figure>
<h2 id="自动删除n天前日志"><a href="#自动删除n天前日志" class="headerlink" title="自动删除n天前日志"></a>自动删除n天前日志</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将/opt/soft/log/目录下所有30天前带&quot;.log&quot;的文件删除</span></span><br><span class="line">find /opt/soft/log/ -mtime +30 -name <span class="string">&quot;*.log&quot;</span> -<span class="built_in">exec</span> <span class="built_in">rm</span> -rf &#123;&#125; \;</span><br></pre></td></tr></table></figure>
<h2 id="vim-粘贴带注释"><a href="#vim-粘贴带注释" class="headerlink" title="vim 粘贴带注释"></a>vim 粘贴带注释</h2><blockquote>
<p>set paste</p>
</blockquote>
<h2 id="Jenkins中命令忽略错误-返回0"><a href="#Jenkins中命令忽略错误-返回0" class="headerlink" title="Jenkins中命令忽略错误, 返回0"></a>Jenkins中命令忽略错误, 返回0</h2><blockquote>
<p>command || true  # 无论command是否成功, 都能继续执行后续动作</p>
</blockquote>
<h2 id="shell文件所在目录-当前目录"><a href="#shell文件所在目录-当前目录" class="headerlink" title="shell文件所在目录/当前目录"></a>shell文件所在目录/当前目录</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">cur_dir=`<span class="built_in">dirname</span> <span class="variable">$0</span>`</span><br><span class="line">docker stack deploy --compose-file <span class="variable">$&#123;cur_dir&#125;</span>/docker-compose.yml cco</span><br></pre></td></tr></table></figure>
<h2 id="nohup"><a href="#nohup" class="headerlink" title="nohup"></a>nohup</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">dir</span>=`<span class="built_in">dirname</span> <span class="variable">$0</span>`</span><br><span class="line"><span class="built_in">nohup</span> java -Dhudson.model.DirectoryBrowserSupport.CSP= -Duser.timezone=Asia/Shanghai -jar <span class="variable">$&#123;dir&#125;</span>/jenkins.war 2&gt;<span class="variable">$&#123;dir&#125;</span>/jenkins.log &amp;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">nohup</span> abc.sh &gt; nohup.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<p>其中2&gt;&amp;1 指将STDERR重定向到前面标准输出定向到的同名文件中，即&amp;1就是nohup.log<br>那么结果就是当执行的命令发生标准错误，那么这个错误也会输出到你指定的输出文件中<br>在jenkins中需要这样用:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pkill -f excelhelper || <span class="literal">true</span></span><br><span class="line">BUILD_ID=dontKillMe <span class="built_in">nohup</span> java -jar <span class="variable">$&#123;WORKSPACE&#125;</span>/excelhelper/target/excelhelper-1.0-SNAPSHOT.jar &gt; /tmp/excelhelper.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<h2 id="cp复制覆盖"><a href="#cp复制覆盖" class="headerlink" title="cp复制覆盖"></a>cp复制覆盖</h2><p>cp -fr src dest<br>但是因为<code>cp</code>在不少服务器被别名为<code>cp -i</code>, 所以我们可以这样:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">\<span class="built_in">cp</span> -fr src dest <span class="comment"># \取消别名</span></span><br><span class="line"><span class="built_in">yes</span> | <span class="built_in">cp</span> <span class="built_in">cp</span> -fr src dest <span class="comment"># 让管道自动输入一大堆yes</span></span><br></pre></td></tr></table></figure>
<p>如果是dos命令<code> xcopy /y src dest</code> 来实现强行复制。</p>
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTI2NTUyNjY3MSw2NDQwMDk3MzJdfQ==
-->]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>备份MySQL数据</title>
    <url>/2021/01/08/ops/Linux/MySQL_Backup/</url>
    <content><![CDATA[<p>备份MySQL数据，简单的shell笔记。</p>
<span id="more"></span>

<h1 id="备份MySQL数据"><a href="#备份MySQL数据" class="headerlink" title="备份MySQL数据"></a>备份MySQL数据</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">work_path=$(<span class="built_in">dirname</span> $(<span class="built_in">readlink</span> -f <span class="string">&quot;<span class="variable">$0</span>&quot;</span>))</span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$work_path</span></span><br><span class="line">DATE=$(<span class="built_in">date</span> +%Y%m%d)</span><br><span class="line">/usr/bin/mysqldump -h example.com -uroot -proot --databases d_common &gt; <span class="variable">$DATE</span>.sql</span><br><span class="line">tar -cjf <span class="variable">$DATE</span>.sql.tar.bz2 <span class="variable">$DATE</span>.sql</span><br><span class="line"><span class="built_in">rm</span> -f <span class="variable">$DATE</span>.sql</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Systemd使用（Nginx和Jenkins为例）</title>
    <url>/2019/06/17/ops/Linux/Systemd%E4%BD%BF%E7%94%A8%EF%BC%88Nginx%E5%92%8CJenkins%E4%B8%BA%E4%BE%8B%EF%BC%89/</url>
    <content><![CDATA[<p>作为一个测试+运维人员，经常需要使用jenkins做持续集成，将jenkins作为守护进程有很多方法，其中一个就是用systemd。</p>
<span id="more"></span>

<h1 id="Systemd使用（Nginx和Jenkins为例）"><a href="#Systemd使用（Nginx和Jenkins为例）" class="headerlink" title="Systemd使用（Nginx和Jenkins为例）"></a>Systemd使用（Nginx和Jenkins为例）</h1><h2 id="systemd是什么"><a href="#systemd是什么" class="headerlink" title="systemd是什么"></a>systemd是什么</h2><p><strong>管理系统所有进程、服务以及启动项等</strong>的软件简称「系统管理器」</p>
<h2 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h2><h3 id="2-1-查看系统所有安装的服务项"><a href="#2-1-查看系统所有安装的服务项" class="headerlink" title="2.1 查看系统所有安装的服务项"></a><strong>2.1 查看系统所有安装的服务项</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl list-unit-files --<span class="built_in">type</span>=service</span><br></pre></td></tr></table></figure>
<p>使用  <code>PageUp</code>  或  <code>PageDown</code>  翻页，查看完毕后按  <code>q</code>  退出。</p>
<h3 id="2-2-查看系统所有运行的服务项"><a href="#2-2-查看系统所有运行的服务项" class="headerlink" title="2.2 查看系统所有运行的服务项"></a><strong>2.2 查看系统所有运行的服务项</strong></h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">systemctl list-units --type=service</span><br></pre></td></tr></table></figure>

<p>如果看到某个服务项前面有一个红点，说明该服务存在问题，请进行排查。</p>
<p>使用  <code>PageUp</code>  或  <code>PageDown</code>  翻页，查看完毕后按  <code>q</code>  退出。</p>
<h3 id="2-3-查看系统所有开机自启动的服务项"><a href="#2-3-查看系统所有开机自启动的服务项" class="headerlink" title="2.3 查看系统所有开机自启动的服务项"></a><strong>2.3 查看系统所有开机自启动的服务项</strong></h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">systemctl list-unit-files --type=service | grep enabled</span><br></pre></td></tr></table></figure>

<h3 id="2-4-查看指定服务项状态"><a href="#2-4-查看指定服务项状态" class="headerlink" title="2.4 查看指定服务项状态"></a><strong>2.4 查看指定服务项状态</strong></h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">systemctl status &lt;服务项名称&gt;</span><br></pre></td></tr></table></figure>

<p>执行命令之后，系统会显示该服务项的状态、是否已激活、描述以及最后十条日志。</p>
<p>如果服务项前面有一个红点，说明该服务存在问题，请根据日志进行排查。</p>
<p><strong>例如</strong></p>
<p>查看 Nginx 服务状态</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">[root: ~]# systemctl status nginx.service</span><br></pre></td></tr></table></figure>
<h3 id="2-6-查看出错的服务"><a href="#2-6-查看出错的服务" class="headerlink" title="2.6 查看出错的服务"></a><strong>2.6 查看出错的服务</strong></h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">systemctl list-units --type=service --state=failed</span><br></pre></td></tr></table></figure>
<h2 id="管理服务"><a href="#管理服务" class="headerlink" title="管理服务"></a>管理服务</h2><h3 id="3-1-启动服务"><a href="#3-1-启动服务" class="headerlink" title="3.1 启动服务"></a><strong>3.1 启动服务</strong></h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">systemctl start &lt;服务项名称&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-停止服务"><a href="#3-2-停止服务" class="headerlink" title="3.2 停止服务"></a><strong>3.2 停止服务</strong></h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">systemctl stop &lt;服务项名称&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3-3-重启服务"><a href="#3-3-重启服务" class="headerlink" title="3.3 重启服务"></a><strong>3.3 重启服务</strong></h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">systemctl restart &lt;服务项名称&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3-4-重新读取配置文件"><a href="#3-4-重新读取配置文件" class="headerlink" title="3.4 重新读取配置文件"></a><strong>3.4 重新读取配置文件</strong></h3><p>如果该服务不能重启，但又必须使用新的配置，这条命令会很有用。</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">systemctl reload &lt;服务项名称&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3-5-使服务开机自启动"><a href="#3-5-使服务开机自启动" class="headerlink" title="3.5 使服务开机自启动"></a><strong>3.5 使服务开机自启动</strong></h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">systemctl enable &lt;服务项名称&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3-6-使服务不要开机自启动"><a href="#3-6-使服务不要开机自启动" class="headerlink" title="3.6 使服务不要开机自启动"></a><strong>3.6 使服务不要开机自启动</strong></h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">systemctl disable &lt;服务项名称&gt;</span><br></pre></td></tr></table></figure>

<h2 id="创建服务"><a href="#创建服务" class="headerlink" title="创建服务"></a>创建服务</h2><h3 id="4-1-服务文件的位置"><a href="#4-1-服务文件的位置" class="headerlink" title="4.1 服务文件的位置"></a><strong>4.1 服务文件的位置</strong></h3><p>CentOS 7的服务systemctl脚本存放在：/usr/lib/systemd/，有系统 system 和用户 user 之分。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/lib/systemd/system  </span><br><span class="line">/run/systemd/system  </span><br><span class="line">/etc/systemd/system</span><br></pre></td></tr></table></figure>
<p>在<code>/etc/systemd/system</code>下面创建<code>nginx.service.d</code>目录，在这个目录里面新建任何以.conf结尾的文件，然后写入我们自己的配置。</p>
<h3 id="4-2-服务文件的模版"><a href="#4-2-服务文件的模版" class="headerlink" title="4.2 服务文件的模版"></a><strong>4.2 服务文件的模版</strong></h3><p>每一个服务以.service结尾，一般会分为3部分：[Unit]、[Service]和[Install]，就以nginx为例吧，具体内容如下：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=nginx - high performance web server</span><br><span class="line"><span class="attr">Documentation</span>=http://nginx.org/en/docs/</span><br><span class="line"><span class="attr">After</span>=network.target remote-fs.target nss-lookup.target</span><br><span class="line"></span><br><span class="line"><span class="section">[Service]</span></span><br><span class="line"><span class="attr">Type</span>=forking</span><br><span class="line"><span class="attr">PIDFile</span>=/usr/local/nginx/logs/nginx.pid</span><br><span class="line"><span class="attr">ExecStartPre</span>=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf</span><br><span class="line"><span class="attr">ExecStart</span>=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf</span><br><span class="line"><span class="attr">ExecReload</span>=/bin/kill -s HUP <span class="variable">$MAINPID</span></span><br><span class="line"><span class="attr">ExecStop</span>=/bin/kill -s QUIT <span class="variable">$MAINPID</span></span><br><span class="line"><span class="attr">PrivateTmp</span>=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="attr">WantedBy</span>=multi-user.target</span><br></pre></td></tr></table></figure>

<h2 id="配置项说明"><a href="#配置项说明" class="headerlink" title="配置项说明"></a>配置项说明</h2><p>下面分别解释下着三部分的含义</p>
<p><em>[Unit]</em></p>
<ul>
<li>  Description : 服务的简单描述</li>
<li>  Documentation ： 服务文档</li>
<li>  After= : 依赖，仅当依赖的服务启动之后再启动自定义的服务单元</li>
</ul>
<p><em>[Service]</em></p>
<ul>
<li>Type : 启动类型simple、forking、oneshot、notify、dbus<ul>
<li>  Type=simple（默认值）：systemd认为该服务将立即启动，服务进程不会fork。如果该服务要启动其他服务，不要使用此类型启动，除非该服务是socket激活型</li>
<li>  Type=forking：systemd认为当该服务进程fork，且父进程退出后服务启动成功。对于常规的守护进程（daemon），除非你确定此启动方式无法满足需求， 使用此类型启动即可。使用此启动类型应同时指定<code>PIDFile=</code>，以便systemd能够跟踪服务的主进程。</li>
<li>  Type=oneshot：这一选项适用于只执行一项任务、随后立即退出的服务。可能需要同时设置  <code>RemainAfterExit=yes</code>  使得  <code>systemd</code>  在服务进程退出之后仍然认为服务处于激活状态。</li>
<li>  Type=notify：与  <code>Type=simple</code>  相同，但约定服务会在就绪后向  <code>systemd</code>  发送一个信号，这一通知的实现由  <code>libsystemd-daemon.so</code>  提供</li>
<li>  Type=dbus：若以此方式启动，当指定的 BusName 出现在DBus系统总线上时，systemd认为服务就绪。</li>
</ul>
</li>
<li>  PIDFile ： pid文件路径</li>
<li>  ExecStartPre ：启动前要做什么，上文中是测试配置文件 －t</li>
<li>  ExecStart：启动</li>
<li>  ExecReload：重载</li>
<li>  ExecStop：停止</li>
<li>  PrivateTmp：True表示给服务分配独立的临时空间</li>
</ul>
<p><em>[Install]</em></p>
<ul>
<li>  WantedBy：服务安装的用户模式，从字面上看，就是想要使用这个服务的有是谁？上文中使用的是：<code>multi-user.target</code>  ，就是指想要使用这个服务的目录是多用户。每一个.target实际上是链接到我们单位文件的集合,当我们执行 systemctl enable nginx.service  </li>
</ul>
<p>就会在  <code>/etc/systemd/system/multi-user.target.wants/</code>  目录下新建一个  <code>/usr/lib/systemd/system/nginx.service</code>  文件的链接。</p>
<h2 id="Jenkins实例"><a href="#Jenkins实例" class="headerlink" title="Jenkins实例"></a>Jenkins实例</h2><h3 id="创建service"><a href="#创建service" class="headerlink" title="创建service"></a>创建service</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/systemd/system/jenkins.service</span><br></pre></td></tr></table></figure>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=Tony<span class="string">&#x27;s Jenkins</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">WorkingDirectory=/root/.jenkins</span></span><br><span class="line"><span class="string">Type=simple</span></span><br><span class="line"><span class="string">ExecStart=/bin/sh -c &quot;/usr/bin/java -Dhudson.model.DirectoryBrowserSupport.CSP= -Duser.timezone=Asia/Shanghai -jar /home/jenkins/jenkins.war&quot;</span></span><br><span class="line"><span class="string">KillSignal=SIGTERM</span></span><br><span class="line"><span class="string">KillMode=mixed</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">RestartSec=5</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br></pre></td></tr></table></figure>

<h3 id="应用与生效"><a href="#应用与生效" class="headerlink" title="应用与生效"></a>应用与生效</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl <span class="built_in">enable</span> jenkins.service</span><br><span class="line">sudo systemctl start jenkins</span><br><span class="line">sudo systemctl status jenkins</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Systemd</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark伪分布式部署</title>
    <url>/2021/06/16/ops/Spark/Spark%E5%8D%95%E8%8A%82%E7%82%B9%E5%A4%A7%E6%95%B0%E6%8D%AELinux/</url>
    <content><![CDATA[<p>记录Linux上Spark伪分布式部署spark，以及做大数据分析的过程</p>
<span id="more"></span>

<h1 id="Spark伪分布式部署"><a href="#Spark伪分布式部署" class="headerlink" title="Spark伪分布式部署"></a>Spark伪分布式部署</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>版本：<br>下载地址： <a href="https://spark.apache.org/downloads.html">https://spark.apache.org/downloads.html</a><br>spark: 3.1.2<br>hadoop: 3.2 or later<br>Spark 3.0+ is pre-built with Scala 2.12.</p>
<p>master: 192.168.28.3<br>slaves: 192.168.28.3<br>driver: 192.168.28.3</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz</span><br><span class="line">tar -zxvf spark-3.1.2-bin-hadoop3.2.tgz</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install openjdk-11-jdk-headless</span><br><span class="line"><span class="built_in">cd</span> spark-3.1.2-bin-hadoop3.2</span><br><span class="line"><span class="built_in">cp</span> conf/spark-env.sh.template conf/spark-env.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export SPARK_MASTER_HOST=192.168.28.3&quot;</span> &gt;&gt; conf/spark-env.sh</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;192.168.28.3&quot;</span> &gt;&gt; conf/slaves</span><br><span class="line"></span><br><span class="line">sbin/stop-worker.sh</span><br><span class="line">sbin/stop-master.sh</span><br><span class="line">sbin/start-master.sh</span><br><span class="line">sbin/start-worker.sh spark://192.168.28.3:7077</span><br><span class="line"></span><br><span class="line">java -jar java-789005-spark-1.0-SNAPSHOT.jar --server.port=8088 --train.file=file:///home/tony/dac/train.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Gradle 转 Maven 小记(ReportPortal为例)</title>
    <url>/2018/08/20/projects/ReportPortal-Customization/Gradle-%E8%BD%AC-Maven-%E5%B0%8F%E8%AE%B0(ReportPortal%E4%B8%BA%E4%BE%8B)/</url>
    <content><![CDATA[<p>公司访问外网要代理, 证书也替换了, gradle不能忽略证书验证, 替换证书未果, 遂起了转化maven工程的念头</p>
<span id="more"></span>
<h1 id="创建pom-xml"><a href="#创建pom-xml" class="headerlink" title="创建pom.xml"></a>创建pom.xml</h1><p>在<code>build.gradle</code>文件中加入以下内容</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">apply <span class="attr">plugin:</span> <span class="string">&#x27;maven&#x27;</span></span><br><span class="line">task createPom &lt;&lt; &#123;</span><br><span class="line">    pom &#123;</span><br><span class="line">    &#125;.writeTo(<span class="string">&quot;pom.xml&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在项目根目录调用命令<code>gradle createPom</code></p>
<h1 id="新增仓库"><a href="#新增仓库" class="headerlink" title="新增仓库"></a>新增仓库</h1><p>在build.gradle中是这样定义的</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">repositories &#123;</span><br><span class="line">    mavenCentral()</span><br><span class="line">    mavenLocal()</span><br><span class="line">    maven &#123; url <span class="string">&quot;http://dl.bintray.com/epam/reportportal&quot;</span> &#125;</span><br><span class="line">    maven &#123; url <span class="string">&quot;http://jasperreports.sourceforge.net/maven2&quot;</span> &#125;</span><br><span class="line">    maven &#123; url <span class="string">&quot;http://jaspersoft.artifactoryonline.com/jaspersoft/third-party-ce-artifacts&quot;</span> &#125;</span><br><span class="line">    maven &#123; url <span class="string">&quot;https://dl.bintray.com/michaelklishin/maven/&quot;</span> &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!releaseMode) &#123;</span><br><span class="line">        maven &#123; url <span class="string">&#x27;https://jitpack.io&#x27;</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>改写pom对应应该如下写法:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>epam<span class="tag">&lt;/<span class="name">id</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://dl.bintray.com/epam/reportportal<span class="tag">&lt;/<span class="name">url</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="补全dependency"><a href="#补全dependency" class="headerlink" title="补全dependency"></a>补全dependency</h1><p>在<code>build.gradle</code>中dependencyManagement是如下写法:</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">dependencyManagement &#123;</span><br><span class="line">    imports &#123;</span><br><span class="line">        mavenBom <span class="string">&quot;org.springframework.cloud:spring-cloud-starter-parent:Edgware.SR3&quot;</span></span><br><span class="line">        mavenBom <span class="string">&quot;org.springframework.boot:spring-boot-dependencies:1.5.9.RELEASE&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>改写pom应为如下写法:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencyManagement</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-dependencies<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.9.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">type</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">scope</span>&gt;</span>import<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-dependencies<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>Dalston.SR1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">type</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">scope</span>&gt;</span>import<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencyManagement</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>应该在一些插件和其他设置中还隐含了一些依赖, 导致mvn install时还有一些依赖没有找到, 逐个手动加上. 建议google搜索<code>maven 类名</code></p>
<h1 id="springboot-no-manifest"><a href="#springboot-no-manifest" class="headerlink" title="springboot no manifest"></a>springboot no manifest</h1><p>在pom中加入:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.5.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">goal</span>&gt;</span>repackage<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Gradle</tag>
        <tag>Maven</tag>
        <tag>ReportPortal</tag>
      </tags>
  </entry>
  <entry>
    <title>ReportPortal 二次开发笔记</title>
    <url>/2018/10/24/projects/ReportPortal-Customization/ReportPortal-%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>ReportPortal二次开发中, 记录一些考量、感想</p>
<span id="more"></span>

<h1 id="ReportPortal-二次开发笔记"><a href="#ReportPortal-二次开发笔记" class="headerlink" title="ReportPortal 二次开发笔记"></a>ReportPortal 二次开发笔记</h1><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>对测试用例执行的日志进行人工标记失败的根因，借助机器学习手段，预测后来执行的失败的用例失败的原因，减少人工分析的成本。<br>在适配一些比较明显的，但类似的日志，应该能取得很好的结果。<br>最开始打算自己实现 AILog 工程，自己实现一条龙： 采集日志数据-人工标记平台-预测结果，但是工作量太大。后续就决定基于ReportPortal进行二次开发了。</p>
<h3 id="标注平台"><a href="#标注平台" class="headerlink" title="标注平台"></a>标注平台</h3><p>主要扩展标注功能，原生是单个用例进行标注根因。<br>在原本基础上，加一个页签，查询类似相近的失败用例和日志，批量标注失败根因。</p>
<p>最初是想着在自己写个Java后台，但是要同步获取MongoDB的数据。后续发现还是直接在原代码上修改，替换原工程就好了。</p>
<h2 id="关联取数据"><a href="#关联取数据" class="headerlink" title="关联取数据"></a>关联取数据</h2><p>MongoDB 查询</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">db.<span class="title function_">getCollection</span>(<span class="string">&#x27;launch&#x27;</span>).<span class="title function_">aggregate</span>([</span><br><span class="line">    &#123;<span class="comment">// 筛选launch, strID筛选新数据, 项目名, launch+test名模糊匹配 </span></span><br><span class="line">        <span class="attr">$match</span>: &#123; <span class="attr">launchId</span>: &#123;<span class="attr">$exists</span>:<span class="literal">true</span>&#125; , <span class="attr">projectRef</span>:<span class="string">&quot;cco1&quot;</span>, <span class="attr">name</span>: &#123;<span class="attr">$regex</span>: <span class="regexp">/PO/</span>&#125;&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="comment">// 去掉不用的字段 </span></span><br><span class="line">        <span class="attr">$project</span>:&#123;<span class="attr">_id</span>:<span class="number">0</span>, <span class="attr">launchId</span>:<span class="number">1</span>, <span class="attr">projectRef</span>: <span class="number">1</span>, <span class="attr">name</span>:<span class="number">1</span>&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="comment">// 关联item</span></span><br><span class="line">        <span class="attr">$lookup</span>:</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">from</span>: <span class="string">&#x27;testItem&#x27;</span>,</span><br><span class="line">            <span class="attr">localField</span>: <span class="string">&#x27;launchId&#x27;</span>,</span><br><span class="line">            <span class="attr">foreignField</span>: <span class="string">&#x27;launchRef&#x27;</span>,</span><br><span class="line">            <span class="attr">as</span>: <span class="string">&#x27;inner_item&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, </span><br><span class="line">    &#123;<span class="comment">// 展开数组</span></span><br><span class="line">        <span class="attr">$unwind</span>: <span class="string">&quot;$inner_item&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="comment">// 只取最底层步骤, 失败的步骤</span></span><br><span class="line">        <span class="attr">$match</span>: &#123;<span class="string">&#x27;inner_item.has_childs&#x27;</span>:<span class="literal">false</span>, <span class="string">&#x27;inner_item.itemId&#x27;</span>: &#123;<span class="attr">$exists</span>:<span class="literal">true</span>&#125;, <span class="string">&#x27;inner_item.status&#x27;</span>: <span class="string">&#x27;FAILED&#x27;</span>&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="comment">// 嵌套item提升到根文档</span></span><br><span class="line">        <span class="attr">$addFields</span>:&#123;<span class="attr">itemId</span>: <span class="string">&quot;$inner_item.itemId&quot;</span>, <span class="string">&quot;itemName&quot;</span>: <span class="string">&quot;$inner_item.name&quot;</span>, <span class="string">&quot;itemStatus&quot;</span>: <span class="string">&quot;$inner_item.status&quot;</span>, <span class="string">&quot;itemDesc&quot;</span>: <span class="string">&quot;$inner_item.itemDescription&quot;</span>&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="comment">// 去掉嵌套文档</span></span><br><span class="line">		<span class="attr">$project</span>: &#123;<span class="attr">inner_item</span>:<span class="number">0</span>&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="comment">// 关联log</span></span><br><span class="line">        <span class="attr">$lookup</span>:</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">from</span>: <span class="string">&#x27;log&#x27;</span>,</span><br><span class="line">            <span class="attr">localField</span>: <span class="string">&#x27;itemId&#x27;</span>,</span><br><span class="line">            <span class="attr">foreignField</span>: <span class="string">&#x27;testItemRef&#x27;</span>,</span><br><span class="line">            <span class="attr">as</span>: <span class="string">&#x27;inner_log&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="comment">// 展开log数组为n行</span></span><br><span class="line">        <span class="attr">$unwind</span>: <span class="string">&quot;$inner_log&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="comment">// 日志级别筛选</span></span><br><span class="line">        <span class="attr">$match</span>: &#123;<span class="string">&#x27;inner_log.level.log_level&#x27;</span>:&#123;<span class="attr">$gt</span>:<span class="number">30000</span>&#125;&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="comment">// 嵌套log提升到根文档</span></span><br><span class="line">        <span class="attr">$addFields</span>: &#123;<span class="attr">logMsg</span>: <span class="string">&quot;$inner_log.logMsg&quot;</span>, <span class="attr">logLevel</span>: <span class="string">&quot;$inner_log.level.log_level&quot;</span>&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="comment">// 去掉嵌套文档</span></span><br><span class="line">        <span class="attr">$project</span>: &#123;<span class="attr">inner_log</span>:<span class="number">0</span>&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">$group</span>: </span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">_id</span>: <span class="string">&quot;$logMsg&quot;</span>, <span class="attr">caselog</span>: &#123;<span class="attr">$push</span>: <span class="string">&quot;$$ROOT&quot;</span>&#125;, <span class="attr">count</span>: &#123;<span class="attr">$sum</span>:<span class="number">1</span>&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">$sort</span>: &#123;<span class="string">&quot;count&quot;</span>: -<span class="number">1</span>&#125;</span><br><span class="line">    &#125;</span><br><span class="line">])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="一条用例应该只有一个错误原因"><a href="#一条用例应该只有一个错误原因" class="headerlink" title="一条用例应该只有一个错误原因"></a>一条用例应该只有一个错误原因</h3><p>所以在关联日志的时候, 没有AI介入之前, 勉强认为第一个出现的错误即为错误原因.<br>我的用例为RobotFramework写的GUI和数据库复合用例, 在用例结束之时会尝试去关闭数据库链接和浏览器, 这里会产生失败记录. 如果一个用例可以关联多条日志, 则会影响聚类分析的准确性.</p>
<h3 id="日志做groupby的时候-如果编辑距离小于n认为是一个group-的条件"><a href="#日志做groupby的时候-如果编辑距离小于n认为是一个group-的条件" class="headerlink" title="日志做groupby的时候, 如果编辑距离小于n认为是一个group 的条件"></a>日志做groupby的时候, 如果编辑距离小于n认为是一个group 的条件</h3><p>// TODO<br>因为有些日志仅有几个字符差距, 本质上是一样的.<br>使用topic生成, 编辑距离, 还是什么ai算法可以将 <code>f(logMsg)--&gt;group cond</code>??</p>
<h2 id="前端工程有小坑"><a href="#前端工程有小坑" class="headerlink" title="前端工程有小坑"></a>前端工程有小坑</h2><p>JS编译并行化<br>两个let赋值语句build之后并行了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> curUser = <span class="variable language_">window</span>.<span class="property">localStorage</span>.<span class="title function_">getItem</span>(<span class="string">&#x27;curUser&#x27;</span>)</span><br><span class="line"><span class="keyword">let</span> projectName = <span class="variable language_">window</span>.<span class="property">localStorage</span>.<span class="title function_">getItem</span>(curUser + <span class="string">&#x27;_lastInsideHash&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> (projectName) &#123;</span><br><span class="line">  projectName = projectName.<span class="title function_">replace</span>(<span class="regexp">/\/aimark/gi</span>, <span class="string">&#x27;&#x27;</span>).<span class="title function_">replace</span>(<span class="regexp">/#/gi</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  projectName = <span class="string">&#x27;wjs-debug&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个语句在build之后, 会变成类似以下代码, 导致projectName取不到值</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> i=<span class="variable language_">window</span>.<span class="property">localStorage</span>.<span class="title function_">getItem</span>(<span class="string">&#x27;curUser&#x27;</span>), n=<span class="variable language_">window</span>.<span class="property">localStorage</span>.<span class="title function_">getItem</span>(curUser + <span class="string">&#x27;_lastInsideHash&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Agent修改"><a href="#Agent修改" class="headerlink" title="Agent修改"></a>Agent修改</h2><h3 id="官方与第三方"><a href="#官方与第三方" class="headerlink" title="官方与第三方"></a>官方与第三方</h3><p>第三方关于step的理解比原版更准确, 故使用第三方版本.<br>官方:<br><a href="https://github.com/reportportal/agent-Python-RobotFramework">https://github.com/reportportal/agent-Python-RobotFramework</a><br>第三方:<br><a href="https://github.com/ailjushkin/robotframework-reportportal-ng/">https://github.com/ailjushkin/robotframework-reportportal-ng/</a></p>
<h3 id="修改第三方-减少依赖"><a href="#修改第三方-减少依赖" class="headerlink" title="修改第三方, 减少依赖"></a>修改第三方, 减少依赖</h3><p>修改文件: <code>reportportal_listener/service.py</code><br><del>from robot.utils import PY2</del><br>import sys<br>将后文中的PY2替换为<code>sys.version_info[0] == 2</code><br><del>from urllib3.exceptions import ResponseError</del><br>将后文中的ResponseError改为<code>Exception</code></p>
<h3 id="修改初始化rp-去掉异常"><a href="#修改初始化rp-去掉异常" class="headerlink" title="修改初始化rp, 去掉异常"></a>修改初始化rp, 去掉异常</h3><p>修改文件: <code>reportportal_listener/service.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">init_service</span>(<span class="params">endpoint, project, uuid</span>):</span><br><span class="line">       <span class="string">&quot;&quot;&quot;Init service for Report Portal.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       Args:</span></span><br><span class="line"><span class="string">           endpoint: ReportPortal API endpoint.</span></span><br><span class="line"><span class="string">           project: project name in Report Portal.</span></span><br><span class="line"><span class="string">           uuid: unique id of user in Report Portal profile.</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       <span class="keyword">if</span> RobotService.rp <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">           RobotService.rp = ReportPortalService(</span><br><span class="line">               endpoint=endpoint,</span><br><span class="line">               project=project,</span><br><span class="line">               token=uuid)</span><br><span class="line">       <span class="comment"># else:</span></span><br><span class="line">       <span class="comment">#     raise Exception(&quot;RobotFrameworkService is already initialized.&quot;)</span></span><br></pre></td></tr></table></figure>

<h3 id="修改listener"><a href="#修改listener" class="headerlink" title="修改listener"></a>修改listener</h3><p>修改文件: <code>reportportal_listener/__init__.py</code><br>入参name没有使用, 修改方法最后一行. 用name比attributes[‘longname’]更短, 展示的时候更符合testdata时候的结构.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">start_suite</span>(<span class="params">self, name, attributes</span>):</span><br><span class="line">	<span class="keyword">if</span> attributes[<span class="string">&#x27;tests&#x27;</span>]:  </span><br><span class="line">    self.robot_service.start_suite(name=name, suite=suite)</span><br></pre></td></tr></table></figure>

<h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>不是平台组，干不了平台的活。我们的产品组，用例基数不大，自动化用例都不够多，效果也难以发挥。最终不了了之。可惜了</p>
<p>有轮子，当然轮子好。但是轮子本来就就是组合轮子的话，修改比较麻烦</p>
<p>比如说：Robotframework 采集日志的Agent就是他们公司外包写的，上报服务器的日志太多，执行时间延长一倍以上。</p>
<p>比如说：ES背后的ＫＮＮ算法，如果想要修改基本等于推翻重来。不具备扩展性。我没法接业务日志进来做简单生产问题分类。</p>
<h2 id="其他人的做法"><a href="#其他人的做法" class="headerlink" title="其他人的做法"></a>其他人的做法</h2><p>大约在半年后，在公司内部看到了另外一个做法。</p>
<ol>
<li>手工上传日志文件，同时提供日志摘取的条件：比如正则匹配关键字，然后取上下n行</li>
<li>平台提供n中机器学习模型训练</li>
<li>提供下载训练好的模型，打包成sdk提供本地调用</li>
<li>提供训练好的模型，打包成为RESTful API 提供在线调用。</li>
</ol>
<p>这个做法就很轻量，扩展性也不错。</p>
<h2 id="截图留念"><a href="#截图留念" class="headerlink" title="截图留念"></a>截图留念</h2><p>![](ReportPortal batch mark 1.png)</p>
<p>![](ReportPortal batch mark 2.png)</p>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>ReportPortal</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>ReportPortal 源码阅读</title>
    <url>/2018/07/22/projects/ReportPortal-Customization/ReportPortal-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<p>在智能测试日志智能洞察的实现过程中,发现已经有epam公司的ReportPortal已经以GPLv3开源了, 实现的功能非常一致. 遂需要对其进行调研, 看看二次开发成本和拿来主义的实施成本.</p>
<span id="more"></span>

<h1 id="service-api"><a href="#service-api" class="headerlink" title="service-api"></a>service-api</h1><h2 id="gradle看第三方库依赖"><a href="#gradle看第三方库依赖" class="headerlink" title="gradle看第三方库依赖"></a>gradle看第三方库依赖</h2><p>本质应该是一个springboot, 对接springcloud, 列举一些使用的到内外的包:<br>内:<br>commons-dao/commons-rules/commons-model/commons<br>外:<br>spring: retry/consul/security/aop/web/freemarker/actuator/oauth2/mongodb<br>commons-fileupload/commons-validator/javax.mail<br>slf4j/logback<br>quartz<br>poi/jasperreports<br>swagger<br>test: hamcrest/junit/mockito/jsonpath/fakemongo</p>
<h2 id="RP的相关包介绍"><a href="#RP的相关包介绍" class="headerlink" title="RP的相关包介绍"></a>RP的相关包介绍</h2><h3 id="commons-dao数据库实体层"><a href="#commons-dao数据库实体层" class="headerlink" title="commons-dao数据库实体层"></a>commons-dao数据库实体层</h3><p>com.epam.ta.reportportal.database.entity <code>实体对象</code><br>XXXRepository: 持久层<br>com.epam.ta.reportportal.database.dao <code>数据访问层</code>: 接口多继承领域接口<br>com.epam.ta.reportportal.database.search, controller条件到查询条件的转化</p>
<h3 id="commons-model模型DTO"><a href="#commons-model模型DTO" class="headerlink" title="commons-model模型DTO"></a>commons-model模型DTO</h3><p>com.epam.ta.reportportal.ws.model.* <code>DTO</code>定义和序列化<br><code>xxxRS</code>: 服务器返回Result<br><code>xxxRQ</code>: 请求服务器的Request</p>
<h3 id="service-api核心服务"><a href="#service-api核心服务" class="headerlink" title="service-api核心服务"></a>service-api核心服务</h3><p>com.epam.ta.reportportal.ws.controller(.impl) <code>controller层</code><br>com.epam.ta.reportportal.ws.converter 转化<br>com.epam.ta.reportportal.core.*(.impl) <code>service服务层</code><br><code>xxxHandler</code>: 其实就是各种服务, 相当于xxxService</p>
<h2 id="调用链"><a href="#调用链" class="headerlink" title="调用链"></a>调用链</h2><pre class="mermaid">graph LR
  client-->|json|controller
  controller-->|xxxRQ|handler(handler:查)
  handler-->|condi|repository
  repository-->|自定义Query|MongoDB</pre>
<pre class="mermaid">graph RL
  MongoDB-->|entity|handler(handler:业务规则做鉴权/存在校验,构造)
  handler-->|xxxResource|controller
  controller-->|xxxRS|client
  subgraph handler返回值流程
    entity-->BussinessRule
    BussinessRule-->entity
    entity-->xxxAssembler
    xxxAssembler-->xxxConventer(xxxConventer:流式map)
    xxxConventer-->xxxResource
  end</pre>

<h2 id="controller看对外接口"><a href="#controller看对外接口" class="headerlink" title="controller看对外接口"></a>controller看对外接口</h2><p>14个controller, 可以从<a href="http://10.75.76.163:8080/ui/#api%E7%9C%8Bswagger%E7%95%8C%E9%9D%A2">http://10.75.76.163:8080/ui/#api看swagger界面</a><br>Activity: 关联用户和项目, 有历史信息, 应该是某人在某个项目操作过的一些kv<br>Dashboard: 关联项目, 看板, 内含widget的id/size/pos<br>External System: 外部缺陷跟踪系统, 注册实例, 提单<br>File Storage: 内部文件存储, 上传图片, <strong>仅包括用户头像</strong><br>Launch: 执行任务, 新建/停止/查询by用户/-项目<br><strong>Log</strong>: 测试日志, 下挂在test item(用例)下, 时间/内容/级别<br>Plugin: 插件, 只有心跳<br><strong>Project</strong>: 项目, 配置分析/邮件/外部系统/job间隔/用户列表, 分配用户/删除项目移除es索引<br>Project Settings: 项目配置<br>Settings: 系统设置, 按profile粒度<br><strong>Test Item</strong>: 既是<code>用例</code>也是<code>用例套</code></p>
<ol>
<li>查询: 可以按父亲/缺陷类型/路径/外部系统/id/参数的kv/launch/tags/时间; </li>
<li>历史情况: 跟在Launch下, 原因/launchId/参数kv/统计</li>
<li>新建用例, 提供父亲/参数KV/tags/type(SUITE, CASE)/id</li>
</ol>
<p>User: 用户, 注册/改密/查询/登录, 登录信息存Principal<br>User Filter: (某人)项目的过滤条件, 描述/实体/名字/排序和分页/是否共享/launch<br>Widget: 内容/小工具/元数据/名字/是否共享, 可以获取预览</p>
<h1 id="agent-python-RobotFramework"><a href="#agent-python-RobotFramework" class="headerlink" title="agent-python-RobotFramework"></a>agent-python-RobotFramework</h1><h2 id="service"><a href="#service" class="headerlink" title="service"></a>service</h2><p>这个类对python-client做了简单的封装和异常处理, 用的都是静态方法. uuid作为token</p>
<h2 id="variable"><a href="#variable" class="headerlink" title="variable"></a>variable</h2><p>检查listener所需的变量是否存在, 打印提示信息. 记录变量值到类中</p>
<h2 id="model"><a href="#model" class="headerlink" title="model"></a>model</h2><p>这里的listener用的RobotFramework的listener API 2版本, model做了attributes到模型对象的封装</p>
<h2 id="listener"><a href="#listener" class="headerlink" title="listener"></a>listener</h2><blockquote>
<p>ROBOT_LISTENER_API_VERSION = 2 # 这行指定了试用api2的版本, 可以支持到keyword的信息获取, 但api v2都是不能修改的, 已经足够了</p>
</blockquote>
<ol>
<li>依旧使用list模拟stack, 完成树的遍历</li>
<li>start/end_suite中的<code>attributes[&quot;id&quot;] == &quot;s1&quot;</code> 判断是否为根的用例套<h2 id="bug坑"><a href="#bug坑" class="headerlink" title="bug坑"></a>bug坑</h2>然而官方的这个版本有问题, 虽然agent传值是对的, 但是在页面上展示的层级是错的, 用例被展示为suite, keyword/step被识别为test.<br>翻看github的issue发现有人已经针对这个bug做了魔改, 刻意把返回类型给改了<br><a href="https://github.com/ailjushkin/robotframework-reportportal-ng/">https://github.com/ailjushkin/robotframework-reportportal-ng/</a></li>
</ol>
<h1 id="client-python"><a href="#client-python" class="headerlink" title="client-python"></a>client-python</h1><h2 id="service-1"><a href="#service-1" class="headerlink" title="service"></a>service</h2><p>封装http请求, 处理launch的开闭, test item的开闭, 日志的发送.</p>
<ol>
<li>用requests处理http请求, 应该是同步的</li>
<li>launch开始, 记录launch id, agent每次使用应该都会先开launch</li>
<li>test item是树状结构, 用栈顶记录父亲id, 结束testitem时候出栈, 其实就是用栈深度遍历的思路, 刚好也是树状结构的测试步骤执行的顺序.</li>
<li>log如果没有附件, 直接post即可. 如果有(多个)附件, 将多个文件单独构造为合适的请求格式, 这里比较绕, 主要是适配requests库post文件的格式, 同时对齐service-api的接口定义.<h2 id="service-async"><a href="#service-async" class="headerlink" title="service_async"></a>service_async</h2>用队列封装service的同步动作, 使其有异步的特性.</li>
<li>队列存的是方法名和参数, 异步调用即将方法名和参数入队</li>
<li>由_monitor方法循环检查能否出队, 出队调用handle方法处理(里面用process_item调同步方法)</li>
<li>另外单独起进程管理队列的生命周期</li>
</ol>
<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><h2 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h2><ol>
<li>client用官方的</li>
<li>agent用民间魔改版<br>然而官方的这个版本有问题, 虽然agent传值是对的, 但是在页面上展示的层级是错的, 用例被展示为suite, keyword/step被识别为test.<br>翻看github的issue发现有人已经针对这个bug做了魔改, 刻意把返回类型给改了<br><a href="https://github.com/ailjushkin/robotframework-reportportal-ng/">https://github.com/ailjushkin/robotframework-reportportal-ng/</a></li>
</ol>
<h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><h3 id="agent管理launch"><a href="#agent管理launch" class="headerlink" title="agent管理launch"></a>agent管理launch</h3><blockquote>
<p>pybot -v RP_UUID:”58b1b092-6305-46fe-a15f-16c2e2081e25” -v RP_ENDPOINT:”<a href="http://100.84.93.68:8080&quot;">http://100.84.93.68:8080&quot;</a> -v RP_LAUNCH:”demo-launch” -v RP_PROJECT:”wjs-debug” -P D:\git\rf-agent\client-Python-3.2.0 -P D:\git\rf-agent\robotframework-reportportal-ng-master –listener reportportal_listener &lt;后续原命令参数&gt;</p>
</blockquote>
<h3 id="人工管理launch"><a href="#人工管理launch" class="headerlink" title="人工管理launch"></a>人工管理launch</h3><p>其中<code>5b5a7b29f7eecc0001c39c0d</code>为launchId</p>
<blockquote>
<p>pybot -v RP_UUID:”58b1b092-6305-46fe-a15f-16c2e2081e25” -v RP_ENDPOINT:”<a href="http://100.84.93.68:8080&quot;">http://100.84.93.68:8080&quot;</a> -v RP_LAUNCH:”demo-launch” -v RP_PROJECT:”wjs-debug” -P D:\git\rf-agent\client-Python-3.2.0 -P D:\git\rf-agent\robotframework-reportportal-ng-master –listener reportportal_listener:5b5a7b29f7eecc0001c39c0d &lt;后续原命令参数&gt;</p>
</blockquote>
<h2 id="并行执行多launch任务"><a href="#并行执行多launch任务" class="headerlink" title="并行执行多launch任务"></a>并行执行多launch任务</h2><p>每个pybot命令会起一个agent, 每次agent都会先开一个luanch, 最后结束掉.<br>如果需要多个pybot命令的执行结果汇总在一起, 需要共用一个launchId. 这就要求执行者手工管理launch的开启和结束</p>
<h3 id="请求的公共部分"><a href="#请求的公共部分" class="headerlink" title="请求的公共部分"></a>请求的公共部分</h3><p>uuid作为token:58b1b092-6305-46fe-a15f-16c2e2081e25<br>Headers:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Authorization:bearer 58b1b092-6305-46fe-a15f-16c2e2081e25</span><br><span class="line">Content-Type:application/json</span><br></pre></td></tr></table></figure>
<h3 id="开启"><a href="#开启" class="headerlink" title="开启"></a>开启</h3><p>url地址以:/api/v1为开始, wjs-debug为项目名<br>POST <a href="http://100.84.93.68:8080/api/v1/wjs-debug/launch">http://100.84.93.68:8080/api/v1/wjs-debug/launch</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">request<span class="punctuation">:</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;demo-launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;start_time&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2018-07-27T09:53:42+08:00&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line">response</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;number&quot;</span><span class="punctuation">:</span> <span class="number">31</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;5b5a7b29f7eecc0001c39c0d&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h3><p>url地址以:/api/v1为开始, wjs-debug为项目名, launch后的5b5a7b29f7eecc0001c39c0d为launchId<br>PUT <a href="http://100.84.93.68:8080/api/v1/wjs-debug/launch/5b5a7b29f7eecc0001c39c0d/finish">http://100.84.93.68:8080/api/v1/wjs-debug/launch/5b5a7b29f7eecc0001c39c0d/finish</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">request:</span><br><span class="line">&#123;</span><br><span class="line">  &quot;end_time&quot;: &quot;2018-07-27T09:55:42+08:00&quot;,</span><br><span class="line">  &quot;status&quot;: &quot;PASSED&quot;</span><br><span class="line">&#125;</span><br><span class="line">response:</span><br><span class="line">&#123;</span><br><span class="line">    &quot;msg&quot;: &quot;Launch with ID = &#x27;5b5a7b29f7eecc0001c39c0d&#x27; successfully finished.&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><h2 id="宿主机修改"><a href="#宿主机修改" class="headerlink" title="宿主机修改"></a>宿主机修改</h2><h3 id="修改vm-max-map-count"><a href="#修改vm-max-map-count" class="headerlink" title="修改vm.max_map_count"></a>修改vm.max_map_count</h3><p>修改此项之后, elastic才能使用</p>
<blockquote>
<p>sysctl -w vm.max_map_count=262144</p>
</blockquote>
<h3 id="目录权限"><a href="#目录权限" class="headerlink" title="目录权限"></a>目录权限</h3><p>elastic不能以root执行, 在docker-compose.yml同目录下执行以下命令:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p data/elasticsearch</span><br><span class="line"><span class="built_in">chown</span> -R 1000:1000 data/elasticsearch</span><br></pre></td></tr></table></figure>

<p>docker-compose 方式启动, 为了不影响我司代理, 暴露部分端口, 改为以下:</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">mongodb:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;mongo:3.4&#x27;</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;27017:27017&#x27;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=Asia/Shanghai</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./data/mongo:/data/db</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">registry:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;consul:1.0.6&#x27;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;.//data/consul:/consul/data&#x27;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;8500:8500&#x27;</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">agent</span> <span class="string">-server</span> <span class="string">-bootstrap-expect=1</span> <span class="string">-ui</span> <span class="string">-client</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;CONSUL_LOCAL_CONFIG=&#123;&quot;leave_on_terminate&quot;: true&#125;&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=Asia/Shanghai</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  <span class="attr">uat:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;reportportal/service-authorization:4.2.0&#x27;</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mongodb</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RP_PROFILES=docker</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RP_SESSION_LIVE=86400</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=Asia/Shanghai</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  <span class="attr">gateway:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;traefik:1.6.3&#x27;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;8080:8080&#x27;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=Asia/Shanghai</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;--consulcatalog.endpoint=registry:8500&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;--defaultEntryPoints=http&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;--entryPoints=Name:http Address::8080&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;--web&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;--web.address=:8081&#x27;</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  <span class="attr">index:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;reportportal/service-index:4.2.0&#x27;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RP_SERVER_PORT=8080</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RP_PROXY_CONSUL=true</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=Asia/Shanghai</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">registry</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">gateway</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  <span class="attr">api:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;reportportal/service-api:4.2.1&#x27;</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mongodb</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./rp-api-1.0.0-SNAPSHOT.jar:/app.jar</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=Asia/Shanghai</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RP_PROFILES=docker</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;JAVA_OPTS=-Xmx1g -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8081&#x27;</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;8081:8081&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;8082:8080&#x27;</span></span><br><span class="line">  <span class="attr">ui:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;reportportal/service-ui:4.2.2&#x27;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RP_SERVER.PORT=8080</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RP_CONSUL.TAGS=urlprefix-/ui</span> <span class="string">opts</span> <span class="string">strip=/ui</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;RP_CONSUL.ADDRESS=registry:8500&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=Asia/Shanghai</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  <span class="attr">analyzer:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;reportportal/service-analyzer:4.2.0&#x27;</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">registry</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">gateway</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">elasticsearch</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">elasticsearch:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch-oss:6.1.1</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">./data/elasticsearch:/usr/share/elasticsearch/data</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">bootstrap.memory_lock=true</span></span><br><span class="line">    <span class="attr">ulimits:</span></span><br><span class="line">      <span class="attr">memlock:</span></span><br><span class="line">        <span class="attr">soft:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">hard:</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">default:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">bridge</span></span><br><span class="line">    <span class="attr">ipam:</span></span><br><span class="line">      <span class="attr">config:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">subnet:</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.0</span><span class="string">/24</span></span><br><span class="line">          <span class="attr">gateway:</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ReportPortal</tag>
      </tags>
  </entry>
  <entry>
    <title>AILog：智能化测试计划与方案</title>
    <url>/2018/03/30/projects/ai-log/AILog%EF%BC%9A%E6%99%BA%E8%83%BD%E5%8C%96%E6%B5%8B%E8%AF%95%E8%AE%A1%E5%88%92%E4%B8%8E%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<p>最终项目夭折了，原因在于选型会议选择了另外一个工具基础上二次开发，另外一个原因是其实本身没有那么多自动化用例的日志可供分析。我们不是平台部门，是个小业务部门</p>
<span id="more"></span>
<h1 id="计划与交付件"><a href="#计划与交付件" class="headerlink" title="计划与交付件"></a>计划与交付件</h1><p>聚焦核心诉求，降低界面可视化等优先级。<br>【用例优化建议：kw、参数等提取抽象】</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>进度</th>
<th>交付件</th>
</tr>
</thead>
<tbody><tr>
<td>4.09</td>
<td>方案、技术选型、元数据</td>
<td><strong>总体设计方案.pptx</strong></td>
</tr>
<tr>
<td>5.25</td>
<td>采集、传输、存储</td>
<td>Only Code</td>
</tr>
<tr>
<td>6.01</td>
<td>统计、<small>可视化<small></td>
<td>RF、Cloud Test执行结果统计展示</td>
</tr>
<tr>
<td>7.20</td>
<td>整合被测应用日志、时间同步</td>
<td>关联展示日志片段</td>
</tr>
<tr>
<td>8.10</td>
<td>人工打Tag</td>
<td>聚类展示</td>
</tr>
<tr>
<td>9.07</td>
<td>智能诊断用例失败原因</td>
<td>推测失败原因、提示历史解决方案</td>
</tr>
<tr>
<td>10.19</td>
<td>频繁项集挖掘与聚类算法</td>
<td>相近用例步骤、demo用例提示</td>
</tr>
<tr>
<td>11.09</td>
<td>铺开测试、高斯异常检测</td>
<td><strong>最终展示</strong></td>
</tr>
<tr>
<td>11.16</td>
<td>提供error日志对应用例</td>
<td>辅助精准化测试接口</td>
</tr>
<tr>
<td>11.23</td>
<td>提供精益看板数据</td>
<td>执行(历史)结果数据接口</td>
</tr>
</tbody></table>
<h1 id="方案与计划"><a href="#方案与计划" class="headerlink" title="方案与计划"></a>方案与计划</h1><p>采集使用flume，传输协议就avro，同时存储在hdfs和kafka中</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> kafka学习和搭建</li>
<li><input checked="" disabled="" type="checkbox"> flume学习</li>
<li><input checked="" disabled="" type="checkbox"> avro学习</li>
<li><input checked="" disabled="" type="checkbox"> confluent kafka avro搭建与demo</li>
<li><input disabled="" type="checkbox"> 归纳常用的日志，编写对应的agent配置</li>
<li><input disabled="" type="checkbox"> 高可用controller配置</li>
<li><input disabled="" type="checkbox"> 打通flume到hdfs</li>
<li><input disabled="" type="checkbox"> 打通flume到kafka</li>
<li><input disabled="" type="checkbox"> ansible部署playbook+jenkins辅助</li>
</ul>
<h1 id="flume简单笔记"><a href="#flume简单笔记" class="headerlink" title="flume简单笔记"></a>flume简单笔记</h1><p>source有两类：</p>
<ul>
<li>驱动型source:是外部主动发送数据给Flume，驱动Flume接受数据。</li>
<li>轮询source:是Flume周期性主动去获取数据。</li>
</ul>
<h1 id="日志类型"><a href="#日志类型" class="headerlink" title="日志类型"></a>日志类型</h1><ol>
<li>linux系统日志</li>
<li>web</li>
<li>was</li>
<li>tomcat</li>
<li>jetty</li>
</ol>
<h2 id="测试工具日志"><a href="#测试工具日志" class="headerlink" title="测试工具日志"></a>测试工具日志</h2><h3 id="RobotFramework"><a href="#RobotFramework" class="headerlink" title="RobotFramework"></a>RobotFramework</h3><h4 id="原生单进程pybot"><a href="#原生单进程pybot" class="headerlink" title="原生单进程pybot"></a>原生单进程pybot</h4><p>在所有用例执行完后，会生成output.xml，解析xml能获取各用例的执行。非实时。</p>
<h4 id="jobsubmit用例级并行"><a href="#jobsubmit用例级并行" class="headerlink" title="jobsubmit用例级并行"></a>jobsubmit用例级并行</h4><p>在各自进程中系统调用pybot执行用例，解析output.xml生成执行结果，准实时。</p>
<h4 id="推送方式"><a href="#推送方式" class="headerlink" title="推送方式"></a>推送方式</h4><p><strong>数据清洗放在最早的此处</strong><br>【TODO】未定</p>
<ol>
<li>flume配置源为http，解析json</li>
<li>flume配置源为avro，解析用例结果的代码推avro请求</li>
<li>flume配置元为exec，调用解析代码，output存chanel</li>
<li>解析代码推二进制到kafka，然后转储到hdfs</li>
</ol>
<h3 id="CloudTest"><a href="#CloudTest" class="headerlink" title="CloudTest"></a>CloudTest</h3><h3 id="协议自动化"><a href="#协议自动化" class="headerlink" title="协议自动化"></a>协议自动化</h3><h1 id="avro结构定义"><a href="#avro结构定义" class="headerlink" title="avro结构定义"></a>avro结构定义</h1><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="表结构"><a href="#表结构" class="headerlink" title="表结构"></a>表结构</h1><h2 id="项目表project"><a href="#项目表project" class="headerlink" title="项目表project"></a>项目表project</h2><table>
<thead>
<tr>
<th>field</th>
<th>type</th>
<th>comment</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>int</td>
<td>自增id</td>
</tr>
<tr>
<td>name</td>
<td>varchar(256)</td>
<td>项目名</td>
</tr>
<tr>
<td>responsible</td>
<td>varchar(128)</td>
<td>责任人</td>
</tr>
<tr>
<td>create_date</td>
<td>datetime</td>
<td>创建时间</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="任务表task"><a href="#任务表task" class="headerlink" title="任务表task"></a>任务表task</h2><table>
<thead>
<tr>
<th>field</th>
<th>type</th>
<th>comment</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>int</td>
<td>自增id</td>
</tr>
<tr>
<td>name</td>
<td>varchar(256)</td>
<td>任务名/taskId</td>
</tr>
<tr>
<td>responsible</td>
<td>varchar(128)</td>
<td>责任人</td>
</tr>
<tr>
<td>create_date</td>
<td>datetime</td>
<td>创建时间</td>
</tr>
<tr>
<td>project_id</td>
<td>int</td>
<td>项目表的id</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="测试套表test-suite"><a href="#测试套表test-suite" class="headerlink" title="测试套表test_suite"></a>测试套表test_suite</h2><table>
<thead>
<tr>
<th>field</th>
<th>type</th>
<th>comment</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>int</td>
<td>自增id</td>
</tr>
<tr>
<td>name</td>
<td>varchar(256)</td>
<td>测试套名</td>
</tr>
<tr>
<td>long_name</td>
<td>varchar(2048)</td>
<td>从顶往下的长测试套名</td>
</tr>
<tr>
<td>project_id</td>
<td>int</td>
<td>项目表的id</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="测试用例表test-case"><a href="#测试用例表test-case" class="headerlink" title="测试用例表test_case"></a>测试用例表test_case</h2><table>
<thead>
<tr>
<th>field</th>
<th>type</th>
<th>comment</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>int</td>
<td>自增id</td>
</tr>
<tr>
<td>name</td>
<td>varchar(256)</td>
<td>测试套名</td>
</tr>
<tr>
<td>long_name</td>
<td>varchar(2048)</td>
<td>从顶往下的长测试套名</td>
</tr>
<tr>
<td>project_id</td>
<td>int</td>
<td>项目表的id</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="测试步骤"><a href="#测试步骤" class="headerlink" title="测试步骤"></a>测试步骤</h2><p>kw，参数、报错信息</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.huawei.unistar.ailog.domain;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> javax.persistence.*;  </span><br><span class="line">  </span><br><span class="line"><span class="meta">@Entity</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Suite</span> &#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Suite</span><span class="params">()</span> &#123;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Suite</span><span class="params">(Integer id, Integer projectId, String name, String doc)</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.id = id;  </span><br><span class="line"> <span class="built_in">this</span>.projectId = projectId;  </span><br><span class="line"> <span class="built_in">this</span>.name = name;  </span><br><span class="line"> <span class="built_in">this</span>.doc = doc;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Id</span>  </span><br><span class="line"> <span class="meta">@GeneratedValue(strategy = GenerationType.IDENTITY)</span>  </span><br><span class="line">    <span class="keyword">private</span> Integer id;  </span><br><span class="line">  </span><br><span class="line"> <span class="keyword">private</span> Integer projectId;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@Column(nullable = false)</span>  </span><br><span class="line">    <span class="keyword">private</span> String name;  </span><br><span class="line">  <span class="meta">@Column(length = 4096)</span>  </span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">doc</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;  </span><br><span class="line">  </span><br><span class="line"> <span class="keyword">public</span> Integer <span class="title function_">getId</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="keyword">return</span> id;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(Integer id)</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.id = id;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">getProjectId</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="keyword">return</span> projectId;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setProjectId</span><span class="params">(Integer projectId)</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.projectId = projectId;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="keyword">return</span> name;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.name = name;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getDoc</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="keyword">return</span> doc;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDoc</span><span class="params">(String doc)</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.doc = doc;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SuiteTreePath</span> &#123;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@EmbeddedId</span>  </span><br><span class="line">  <span class="keyword">private</span> TreePathPK id;  </span><br><span class="line"> <span class="keyword">private</span> Integer distance;  </span><br><span class="line">  </span><br><span class="line"> <span class="keyword">public</span> Integer <span class="title function_">getDistance</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="keyword">return</span> distance;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDistance</span><span class="params">(Integer distance)</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.distance = distance;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TreePathPK</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;  </span><br><span class="line">    <span class="keyword">private</span> Integer ancestor;  </span><br><span class="line"> <span class="keyword">private</span> Integer descendant;  </span><br><span class="line">  </span><br><span class="line"> <span class="keyword">public</span> <span class="title function_">TreePathPK</span><span class="params">(Integer ancestor, Integer descendant)</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.ancestor = ancestor;  </span><br><span class="line"> <span class="built_in">this</span>.descendant = descendant;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">  <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">equals</span><span class="params">(Object o)</span> &#123;  </span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span> == o) <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line"> <span class="keyword">if</span> (o == <span class="literal">null</span> || getClass() != o.getClass()) <span class="keyword">return</span> <span class="literal">false</span>;  </span><br><span class="line">  </span><br><span class="line">  <span class="type">TreePathPK</span> <span class="variable">that</span> <span class="operator">=</span> (TreePathPK) o;  </span><br><span class="line">  </span><br><span class="line"> <span class="keyword">if</span> (ancestor != <span class="literal">null</span> ? !ancestor.equals(that.ancestor) : that.ancestor != <span class="literal">null</span>) <span class="keyword">return</span> <span class="literal">false</span>;  </span><br><span class="line"> <span class="keyword">return</span> descendant != <span class="literal">null</span> ? descendant.equals(that.descendant) : that.descendant == <span class="literal">null</span>;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hashCode</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> ancestor != <span class="literal">null</span> ? ancestor.hashCode() : <span class="number">0</span>;  </span><br><span class="line">  result = <span class="number">31</span> * result + (descendant != <span class="literal">null</span> ? descendant.hashCode() : <span class="number">0</span>);  </span><br><span class="line"> <span class="keyword">return</span> result;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>AILog</tag>
      </tags>
  </entry>
  <entry>
    <title>Avro 序列化传输协议实战</title>
    <url>/2018/05/13/projects/ai-log/Avro%20%E5%BA%8F%E5%88%97%E5%8C%96%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<p>测试岗位却不甘止步于业务测试，遂尝试智能化测试，当前的思路是通过日志大数据分析，协助自动化用例的诊断和建议。其中传输协议打算使用avro，原因是使用hadoop集群。本文记录官网入门步骤中未尽之处与项目实际应用经验</p>
<span id="more"></span>

<h1 id="pom"><a href="#pom" class="headerlink" title="pom"></a>pom</h1><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.huawei.unistar<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>avro<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.avro<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>avro<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.avro<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>avro-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>generate-sources<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>schema<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">sourceDirectory</span>&gt;</span>$&#123;project.basedir&#125;/src/main/avro/<span class="tag">&lt;/<span class="name">sourceDirectory</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">outputDirectory</span>&gt;</span>$&#123;project.basedir&#125;/src/main/java/<span class="tag">&lt;/<span class="name">outputDirectory</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.6<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.6<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h1 id="json定义文件存放目录"><a href="#json定义文件存放目录" class="headerlink" title="json定义文件存放目录"></a>json定义文件存放目录</h1><p>这一步比较特殊，需要将<code>user.avsc</code>放在main下的avro目录，以avsc结尾。然后调用maven插件<code>mvn org.apache.avro:avro-maven-plugin:schema</code>，maven插件好像有bug，不能在pom.xml中指定sourceDirectory。<br>也可以手工调用<code>java -jar /path/to/avro-tools-1.8.1.jar compile schema user.avsc .</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├─src</span><br><span class="line">│  ├─main</span><br><span class="line">│  │  ├─avro</span><br><span class="line">│  │  │      user.avsc</span><br><span class="line">│  │  │</span><br><span class="line">│  │  ├─java</span><br><span class="line">│  │  │      SpDemo.java</span><br><span class="line">│  │  │</span><br><span class="line">│  │  └─resources</span><br><span class="line">│  └─test</span><br><span class="line">│      └─java</span><br><span class="line">└─target</span><br><span class="line">    ├─generated-sources</span><br><span class="line">    │  └─avro</span><br><span class="line">    │      └─example</span><br><span class="line">    │          └─avro</span><br><span class="line">    │                  User.java</span><br></pre></td></tr></table></figure>
<h1 id="本地序列化与反序列化"><a href="#本地序列化与反序列化" class="headerlink" title="本地序列化与反序列化"></a>本地序列化与反序列化</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> example.avro.User;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.Schema;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.file.DataFileReader;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.file.DataFileWriter;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.generic.GenericData;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.generic.GenericDatumReader;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.generic.GenericDatumWriter;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.generic.GenericRecord;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.io.DatumReader;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.io.DatumWriter;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.specific.SpecificDatumReader;  </span><br><span class="line"><span class="keyword">import</span> org.apache.avro.specific.SpecificDatumWriter;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> java.io.File;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LocalDemo</span> &#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">specific</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="type">User</span> <span class="variable">user1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();  </span><br><span class="line">  user1.setName(<span class="string">&quot;Alyssa&quot;</span>);  </span><br><span class="line">  user1.setFavoriteNumber(<span class="number">256</span>);  </span><br><span class="line">  <span class="comment">// Leave favorite color null  </span></span><br><span class="line">  </span><br><span class="line"> <span class="comment">// Alternate constructor  User user2 = new User(&quot;Ben&quot;, 7, &quot;red&quot;);  </span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Construct via builder  </span></span><br><span class="line">  <span class="type">User</span> <span class="variable">user3</span> <span class="operator">=</span> User.newBuilder()  </span><br><span class="line">                .setName(<span class="string">&quot;Charlie&quot;</span>)  </span><br><span class="line">                .setFavoriteColor(<span class="string">&quot;blue&quot;</span>)  </span><br><span class="line">                .setFavoriteNumber(<span class="literal">null</span>)  </span><br><span class="line">                .build();  </span><br><span class="line">  </span><br><span class="line">  <span class="type">File</span> <span class="variable">serializedFile</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;users.avro&quot;</span>);  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Serialize user1, user2 and user3 to disk  </span></span><br><span class="line">  DatumWriter&lt;User&gt; userDatumWriter = <span class="keyword">new</span> <span class="title class_">SpecificDatumWriter</span>&lt;User&gt;(User.class);  </span><br><span class="line"> <span class="keyword">try</span> &#123;  </span><br><span class="line">            DataFileWriter&lt;User&gt; dataFileWriter = <span class="keyword">new</span> <span class="title class_">DataFileWriter</span>&lt;User&gt;(userDatumWriter);  </span><br><span class="line">  dataFileWriter.create(user1.getSchema(), serializedFile);  </span><br><span class="line">  dataFileWriter.append(user1);  </span><br><span class="line">  dataFileWriter.append(user2);  </span><br><span class="line">  dataFileWriter.append(user3);  </span><br><span class="line">  dataFileWriter.close();  </span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">// Deserialize Users from disk  </span></span><br><span class="line">  DatumReader&lt;User&gt; userDatumReader = <span class="keyword">new</span> <span class="title class_">SpecificDatumReader</span>&lt;User&gt;(User.class);  </span><br><span class="line">  DataFileReader&lt;User&gt; dataFileReader = <span class="literal">null</span>;  </span><br><span class="line">  <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> <span class="literal">null</span>;  </span><br><span class="line"> <span class="keyword">try</span> &#123;  </span><br><span class="line">            dataFileReader = <span class="keyword">new</span> <span class="title class_">DataFileReader</span>&lt;User&gt;(serializedFile, userDatumReader);  </span><br><span class="line"> <span class="keyword">while</span> (dataFileReader.hasNext()) &#123;  </span><br><span class="line">                <span class="comment">// Reuse user object by passing it to next(). This saves us from  </span></span><br><span class="line"> <span class="comment">// allocating and garbage collecting many objects for files with // many items.  user = dataFileReader.next(user);  </span></span><br><span class="line">  System.out.println(user);  </span><br><span class="line">  &#125;  </span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">  &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">generic</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="comment">// load schema from serialized file  </span></span><br><span class="line">  <span class="type">File</span> <span class="variable">schemaFile</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;user.avsc&quot;</span>);  </span><br><span class="line">  <span class="type">Schema</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="literal">null</span>;  </span><br><span class="line"> <span class="keyword">try</span> &#123;  </span><br><span class="line">            schema = <span class="keyword">new</span> <span class="title class_">Schema</span>.Parser().parse(schemaFile);  </span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">  &#125;  </span><br><span class="line">        <span class="type">GenericRecord</span> <span class="variable">user1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GenericData</span>.Record(schema);  </span><br><span class="line">  user1.put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Alyssa&quot;</span>);  </span><br><span class="line">  user1.put(<span class="string">&quot;favorite_number&quot;</span>, <span class="number">256</span>);  </span><br><span class="line">  <span class="comment">// Leave favorite color null  </span></span><br><span class="line">  </span><br><span class="line">  <span class="type">GenericRecord</span> <span class="variable">user2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GenericData</span>.Record(schema);  </span><br><span class="line">  user2.put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Ben&quot;</span>);  </span><br><span class="line">  user2.put(<span class="string">&quot;favorite_number&quot;</span>, <span class="number">7</span>);  </span><br><span class="line">  user2.put(<span class="string">&quot;favorite_color&quot;</span>, <span class="string">&quot;red&quot;</span>);  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Serialize user1 and user2 to disk  </span></span><br><span class="line">  <span class="type">File</span> <span class="variable">serializedFile</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;users2.avro&quot;</span>);  </span><br><span class="line">  DatumWriter&lt;GenericRecord&gt; datumWriter = <span class="keyword">new</span> <span class="title class_">GenericDatumWriter</span>&lt;GenericRecord&gt;(schema);  </span><br><span class="line">  DataFileWriter&lt;GenericRecord&gt; dataFileWriter = <span class="keyword">new</span> <span class="title class_">DataFileWriter</span>&lt;GenericRecord&gt;(datumWriter);  </span><br><span class="line"> <span class="keyword">try</span> &#123;  </span><br><span class="line">            dataFileWriter.create(schema, serializedFile);  </span><br><span class="line">  dataFileWriter.append(user1);  </span><br><span class="line">  dataFileWriter.append(user2);  </span><br><span class="line">  dataFileWriter.close();  </span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">        DatumReader&lt;GenericRecord&gt; datumReader = <span class="keyword">new</span> <span class="title class_">GenericDatumReader</span>&lt;GenericRecord&gt;(schema);  </span><br><span class="line"> <span class="keyword">try</span> &#123;  </span><br><span class="line">            DataFileReader&lt;GenericRecord&gt; dataFileReader = <span class="keyword">new</span> <span class="title class_">DataFileReader</span>&lt;GenericRecord&gt;(serializedFile, datumReader);  </span><br><span class="line">  <span class="type">GenericRecord</span> <span class="variable">user</span> <span class="operator">=</span> <span class="literal">null</span>;  </span><br><span class="line"> <span class="keyword">while</span> (dataFileReader.hasNext()) &#123;  </span><br><span class="line">                user = dataFileReader.next(user);  </span><br><span class="line">  System.out.println(user);  </span><br><span class="line">  &#125;  </span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">  &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;  </span><br><span class="line">        <span class="type">LocalDemo</span> <span class="variable">localDemo</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LocalDemo</span>();  </span><br><span class="line">  localDemo.specific();  </span><br><span class="line">  localDemo.generic();  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="http://blog.kazaff.me/2014/07/07/%E6%98%AF%E4%BB%80%E4%B9%88%E7%B3%BB%E5%88%97%E4%B9%8BAvro/">Avro是什么</a></li>
<li><a href="http://www.cnblogs.com/agoodegg/p/3309041.html">实战代码</a></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>AILog</tag>
        <tag>Avro</tag>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title>Flume 笔记</title>
    <url>/2018/05/25/projects/ai-log/Flume%20%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>测试岗位却不甘止步于业务测试，遂尝试智能化测试，当前的思路是通过日志大数据分析，协助自动化用例的诊断和建议。其中本地日志采用flume采集，发送到kafka</p>
<span id="more"></span>
<h1 id="目录下日志"><a href="#目录下日志" class="headerlink" title="目录下日志"></a>目录下日志</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Flume2KafkaAgent.sources=mysource  </span><br><span class="line">Flume2KafkaAgent.channels=mychannel  </span><br><span class="line">Flume2KafkaAgent.sinks=mysink  </span><br><span class="line">  </span><br><span class="line">Flume2KafkaAgent.sources.mysource.type=spooldir  </span><br><span class="line">Flume2KafkaAgent.sources.mysource.channels=mychannel  </span><br><span class="line">Flume2KafkaAgent.sources.mysource.spoolDir=/tmp/hadoop</span><br><span class="line">  </span><br><span class="line">Flume2KafkaAgent.sinks.mysink.channel=mychannel  </span><br><span class="line">Flume2KafkaAgent.sinks.mysink.type=org.apache.flume.sink.kafka.KafkaSink  </span><br><span class="line">Flume2KafkaAgent.sinks.mysink.kafka.bootstrap.servers=10.75.76.163:9092</span><br><span class="line">Flume2KafkaAgent.sinks.mysink.kafka.topic=flume-data  </span><br><span class="line">Flume2KafkaAgent.sinks.mysink.kafka.batchSize=20  </span><br><span class="line">Flume2KafkaAgent.sinks.mysink.kafka.producer.requiredAcks=1  </span><br><span class="line">  </span><br><span class="line">Flume2KafkaAgent.channels.mychannel.type=memory  </span><br><span class="line">Flume2KafkaAgent.channels.mychannel.capacity=30000  </span><br><span class="line">Flume2KafkaAgent.channels.mychannel.transactionCapacity=100  </span><br></pre></td></tr></table></figure>
<h1 id="单一日志文件"><a href="#单一日志文件" class="headerlink" title="单一日志文件"></a>单一日志文件</h1><p>还没测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">single-tail.sources=mysource  </span><br><span class="line">single-tail.channels=mychannel  </span><br><span class="line">single-tail.sinks=mysink  </span><br><span class="line">  </span><br><span class="line">single-tail.sources.mysource.type=exec  </span><br><span class="line">single-tail.sources.mysource.shell = /bin/bash -c</span><br><span class="line">single-tail.sources.mysource.command = tail -F /tmp/wjs.log</span><br><span class="line">single-tail.sources.mysource.channels=mychannel  </span><br><span class="line"></span><br><span class="line">single-tail.channels.mychannel.type=memory  </span><br><span class="line">single-tail.channels.mychannel.capacity=30000  </span><br><span class="line">single-tail.channels.mychannel.transactionCapacity=100  </span><br><span class="line"></span><br><span class="line">single-tail.sinks.mysink.channel=mychannel  </span><br><span class="line">single-tail.sinks.mysink.type=org.apache.flume.sink.kafka.KafkaSink  </span><br><span class="line">single-tail.sinks.mysink.kafka.bootstrap.servers=10.75.76.163:9092</span><br><span class="line">single-tail.sinks.mysink.kafka.topic=flume-data  </span><br><span class="line">single-tail.sinks.mysink.kafka.batchSize=20  </span><br><span class="line">single-tail.sinks.mysink.kafka.producer.requiredAcks=1  </span><br></pre></td></tr></table></figure>
<h1 id="递归多层目录的taildir"><a href="#递归多层目录的taildir" class="headerlink" title="递归多层目录的taildir"></a>递归多层目录的taildir</h1><p>使用的是这个大神修改的taildir<br><a href="https://github.com/qwurey/flume-source-taildir-recursive">https://github.com/qwurey/flume-source-taildir-recursive</a><br>代码down下来不能直接<code>mvn package</code>，要改pom.xml，默认是1.6.0，但是作者在写代码的之后，官方将某个类挪了一个位置，import报错，编译不了。改成1.8.0可以。默认情况下没有打成jar包，也许是因为windows平台上maven测试过不了。可以到flume-taildir-source\target\classes这个目录执行一下<code>jar cvf flume-source-taildir-recursive.jar .</code></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flume-ng-sources<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flume<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>vim conf/taildirr.conf</p>
</blockquote>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">taildirr.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">taildirr.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">taildirr.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">taildirr.sources.r1.type</span> = <span class="string">com.urey.flume.source.taildir.TaildirSource</span></span><br><span class="line"><span class="attr">taildirr.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">taildirr.sources.r1.positionFile</span> = <span class="string">/home/hadoop/.flume/taildir_position.json</span></span><br><span class="line"><span class="attr">taildirr.sources.r1.filegroups</span> = <span class="string">f1</span></span><br><span class="line"><span class="attr">taildirr.sources.r1.filegroups.f1</span> = <span class="string">/tmp/wjs/.*</span></span><br><span class="line"><span class="attr">taildirr.sources.r1.batchSize</span> = <span class="string">100</span></span><br><span class="line"><span class="attr">taildirr.sources.r1.backoffSleepIncrement</span>= <span class="string">1000</span></span><br><span class="line"><span class="attr">taildirr.sources.r1.maxBackoffSleep</span>= <span class="string">5000</span></span><br><span class="line"><span class="attr">taildirr.sources.r1.recursiveDirectorySearch</span> = <span class="string">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">taildirr.sinks.k1.type</span> = <span class="string">org.apache.flume.sink.kafka.KafkaSink</span></span><br><span class="line"><span class="attr">taildirr.sinks.k1.kafka.bootstrap.servers</span>=<span class="string">10.75.76.163:9092</span></span><br><span class="line"><span class="attr">taildirr.sinks.k1.kafka.topic</span>=<span class="string">flume-taildir-recursive1</span></span><br><span class="line"><span class="attr">taildirr.sinks.k1.kafka.batchSize</span>=<span class="string">20 </span></span><br><span class="line"><span class="attr">taildirr.sinks.k1.kafka.producer.requiredAcks</span>=<span class="string">1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">taildirr.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">taildirr.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">taildirr.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">taildirr.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">taildirr.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>

<h3 id="启动命令"><a href="#启动命令" class="headerlink" title="启动命令"></a>启动命令</h3><blockquote>
<p>bin/flume-ng agent -n taildirr -c conf -f conf/taildirr.conf -Dflume.root.logger=INFO,console</p>
</blockquote>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://blog.csdn.net/u012373815/article/details/54351323">flume组织source、channel、sink</a></li>
<li><a href="https://blog.csdn.net/m0_37739193/article/details/72962192">taildir递归多层目录</a></li>
<li><a href="https://flume.apache.org/FlumeUserGuide.html">flume官方文档</a></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>AILog</tag>
        <tag>Flume</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka 实战之 schema-registry</title>
    <url>/2018/05/18/projects/ai-log/Kafka%20%E5%AE%9E%E6%88%98%E4%B9%8B%20schema-registry/</url>
    <content><![CDATA[<p>测试岗位却不甘止步于业务测试，遂尝试智能化测试，当前的思路是通过日志大数据分析，协助自动化用例的诊断和建议。其中传输协议打算使用avro，原因是使用hadoop集群。本文使用confluent公司提供的schema-registry存放avro的schema。</p>
<span id="more"></span>
<h1 id="部署动作"><a href="#部署动作" class="headerlink" title="部署动作"></a>部署动作</h1><p>直接用confluent公司的opensource好像很方便，但是启动之后经常少broker，用不了。那就用他们的docker镜像吧，基于他们的单节点尝试的。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">zookeeper:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">confluentinc/cp-zookeeper:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/tony/kafka/zk-data:/var/lib/zookeeper/data</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/tony/kafka/zk-txn-logs:/var/lib/zookeeper/log</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;2181:2181&quot;</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">ZOOKEEPER_CLIENT_PORT:</span> <span class="number">2181</span></span><br><span class="line">      <span class="attr">ZOOKEEPER_TICK_TIME:</span> <span class="number">2000</span></span><br><span class="line">    <span class="attr">extra_hosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;moby:127.0.0.1&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">kafka:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">confluentinc/cp-kafka:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/tony/kafka/kafka-data:/var/lib/kafka/data</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;9092:9092&quot;</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zookeeper</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">KAFKA_BROKER_ID:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">KAFKA_ZOOKEEPER_CONNECT:</span> <span class="string">localhost:2181</span></span><br><span class="line">      <span class="attr">KAFKA_ADVERTISED_LISTENERS:</span> <span class="string">PLAINTEXT://$&#123;localhost_ip&#125;:9092</span></span><br><span class="line">      <span class="attr">KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zookeeper</span></span><br><span class="line">    <span class="attr">extra_hosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;moby:127.0.0.1&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">schema-reristry:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">confluentinc/cp-schema-registry:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8081:8081&quot;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL:</span> <span class="string">localhost:2181</span></span><br><span class="line">      <span class="attr">SCHEMA_REGISTRY_HOST_NAME:</span> <span class="string">localhost</span></span><br><span class="line">      <span class="attr">SCHEMA_REGISTRY_LISTENERS:</span> <span class="string">http://$&#123;localhost_ip&#125;:8081</span></span><br><span class="line">      <span class="attr">SCHEMA_REGISTRY_DEBUG:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zookeeper</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">kafka-rest:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">confluentinc/cp-kafka-rest:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8082:8082&quot;</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">KAFKA_REST_ZOOKEEPER_CONNECT:</span> <span class="string">localhost:2181</span></span><br><span class="line">      <span class="attr">KAFKA_REST_LISTENERS:</span> <span class="string">http://$&#123;localhost_ip&#125;:8082</span></span><br><span class="line">      <span class="attr">KAFKA_REST_SCHEMA_REGISTRY_URL:</span> <span class="string">http://localhost:8081</span></span><br><span class="line">      <span class="attr">KAFKA_REST_HOST_NAME:</span> <span class="string">$&#123;localhost_ip&#125;</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zookeeper</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">schema-reristry</span></span><br></pre></td></tr></table></figure>
<p>kafka-manager，临时命令</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">docker</span> <span class="string">run</span> <span class="string">-it</span> <span class="string">--rm</span>  <span class="string">-p</span> <span class="number">9000</span><span class="string">:9000</span> <span class="string">-e</span> <span class="string">ZK_HOSTS=&quot;10.75.76.163:2181&quot;</span> <span class="string">-e</span> <span class="string">APPLICATION_SECRET=letmein</span> <span class="string">sheepkiller/kafka-manager</span></span><br></pre></td></tr></table></figure>

<h1 id="准备动作"><a href="#准备动作" class="headerlink" title="准备动作"></a>准备动作</h1><p>使用confluent提供的一键包，avro的maven插件，先写java版本，后面再补充python实现。</p>
<h2 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span> <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span> <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.unistar<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">kafka.version</span>&gt;</span>0.11.0.0-cp1<span class="tag">&lt;/<span class="name">kafka.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">kafka.scala.version</span>&gt;</span>2.10<span class="tag">&lt;/<span class="name">kafka.scala.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">confluent.version</span>&gt;</span>3.3.0<span class="tag">&lt;/<span class="name">confluent.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">avro.version</span>&gt;</span>1.8.2<span class="tag">&lt;/<span class="name">avro.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>confluent<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://packages.confluent.io/maven/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- further repository entries here --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/com.squareup.okhttp3/okhttp --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.squareup.okhttp3<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>okhttp<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;kafka.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.avro/avro --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.avro<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>avro<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;avro.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.confluent<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-avro-serializer<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;confluent.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/joda-time/joda-time --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--note at 2018-05-19:avro 1.8.2 在序列化date的时候仍然使用joda time，github上master代码已经改为java.time.*--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>joda-time<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>joda-time<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.avro<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>avro-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;avro.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>generate-sources<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>schema<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>protocol<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>idl-protocol<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">sourceDirectory</span>&gt;</span>$&#123;project.basedir&#125;/src/main/avro/<span class="tag">&lt;/<span class="name">sourceDirectory</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">outputDirectory</span>&gt;</span>$&#123;project.basedir&#125;/src/main/java/<span class="tag">&lt;/<span class="name">outputDirectory</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><p>在${project.basedir}目录使用<code>tree /f</code>(windows)即可生成如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">│  pom.xml</span><br><span class="line">│</span><br><span class="line">├─src</span><br><span class="line">│  ├─main</span><br><span class="line">│  │  ├─avro</span><br><span class="line">│  │  │      Testase.avsc</span><br><span class="line">│  │  │</span><br><span class="line">│  │  ├─java</span><br><span class="line">│  │  │  │  BasicConsumerLoop.java</span><br><span class="line">│  │  │  │  ConfluentConsumer.java</span><br><span class="line">│  │  │  │  ConsumerDemo.java</span><br><span class="line">│  │  │  │  ProducerDemo.java</span><br><span class="line">│  │  │  │</span><br><span class="line">│  │  │  └─com</span><br><span class="line">│  │  │      └─huawei</span><br><span class="line">│  │  │          └─unistar</span><br><span class="line">│  │  │              └─test</span><br><span class="line">│  │  │                      SchemaMain.java</span><br><span class="line">│  │  │</span><br><span class="line">│  │  └─resources</span><br><span class="line">│  └─test</span><br><span class="line">│      └─java</span><br><span class="line">└─target</span><br><span class="line">    └─generated-sources</span><br><span class="line">        └─avro</span><br><span class="line">            └─com</span><br><span class="line">                └─huawei</span><br><span class="line">                    └─unistar</span><br><span class="line">                        └─aitest</span><br><span class="line">                                capability.java</span><br><span class="line">                                Testcase.java</span><br></pre></td></tr></table></figure>
<h1 id="avro-schema"><a href="#avro-schema" class="headerlink" title="avro schema"></a>avro schema</h1><p>在${project.basedir}目录执行如下命令，用maven插件将*.avsc文件生成对应的java文件。</p>
<blockquote>
<p>mvn org.apache.avro:avro-maven-plugin:1.8.2:schema</p>
</blockquote>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>  </span><br><span class="line">  <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span> <span class="string">&quot;com.huawei.unistar.aitest&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;record&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Testcase&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Represents an testcase&#x27;s execution history&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span>  </span><br><span class="line">    <span class="punctuation">&#123;</span>  </span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;app&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;被测产品，应用或模块&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="punctuation">&#123;</span>  </span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;testTool&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;测试工具&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="punctuation">&#123;</span>  </span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;startDate&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span>  </span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;long&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;logicalType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;timestamp-millis&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;用例开始时间&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="punctuation">&#123;</span>  </span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;endDate&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span>  </span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;long&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;logicalType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;timestamp-millis&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;用例结束时间&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="punctuation">&#123;</span>  </span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;elapsed&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span>  </span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;int&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;logicalType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;time-millis&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;用例执行时长&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="punctuation">&#123;</span>  </span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;suite&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span>  </span><br><span class="line">        <span class="string">&quot;null&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="string">&quot;string&quot;</span>  </span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span> <span class="keyword">null</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;用例所属测试套&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="punctuation">&#123;</span>  </span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;case&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;用例名&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="punctuation">&#123;</span>  </span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;result&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;执行结果&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="punctuation">&#123;</span>  </span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;capability&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span>  </span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;enum&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Capability&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;symbols&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span>  </span><br><span class="line">          <span class="string">&quot;HTTP&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="string">&quot;DATABASE&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="string">&quot;GUI&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="string">&quot;DEFAULT&quot;</span>  </span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;测试能力，枚举值。default：无法识别/未提及&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span>  </span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="punctuation">&#123;</span>  </span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;errorMsg&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span>  </span><br><span class="line">        <span class="string">&quot;null&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="string">&quot;string&quot;</span>  </span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span> <span class="keyword">null</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;doc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;失败日志，默认为空。失败时必填&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span>  </span><br><span class="line">  <span class="punctuation">]</span>  </span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h1 id="与schema-registry通信"><a href="#与schema-registry通信" class="headerlink" title="与schema-registry通信"></a>与schema-registry通信</h1><p>该部分主要参考<a href="https://dzone.com/articles/kafka-avro-serialization-and-the-schema-registry">这个例子</a>，只是将schema从hardcode改为从avsc文件读取而已。例子有其他api的调用。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.huawei.unistar.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> okhttp3.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SchemaMain</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">MediaType</span> <span class="variable">SCHEMA_CONTENT</span> <span class="operator">=</span> MediaType.parse(<span class="string">&quot;application/vnd.schemaregistry.v1+json&quot;</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">String</span> <span class="variable">CASE_SCHEMA</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SchemaMain</span><span class="params">(String schemaFilePath)</span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">BufferedReader</span> <span class="variable">bufferedReader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">FileReader</span>(<span class="keyword">new</span> <span class="title class_">File</span>(schemaFilePath)));</span><br><span class="line">            <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">            <span class="type">StringBuilder</span> <span class="variable">jsonStr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">            <span class="keyword">while</span> ((line = bufferedReader.readLine()) != <span class="literal">null</span>) &#123;</span><br><span class="line">                jsonStr.append(line);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">String</span> <span class="variable">finalString</span> <span class="operator">=</span> jsonStr.toString().replaceAll(<span class="string">&quot;\&quot;&quot;</span>, <span class="string">&quot;\\\\\&quot;&quot;</span>);</span><br><span class="line">            CASE_SCHEMA = <span class="string">&quot; &#123;\&quot;schema\&quot;: \&quot; &quot;</span> + finalString + <span class="string">&quot;\&quot;&#125;&quot;</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String... args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">path</span> <span class="operator">=</span> <span class="string">&quot;D:\\2.code\\javacode\\kafka\\src\\Testase.avsc&quot;</span>;</span><br><span class="line">        <span class="type">SchemaMain</span> <span class="variable">schemaMain</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SchemaMain</span>(path);</span><br><span class="line">        System.out.println(CASE_SCHEMA);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">OkHttpClient</span> <span class="variable">client</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OkHttpClient</span>();</span><br><span class="line">        <span class="comment">//POST A NEW SCHEMA</span></span><br><span class="line">        <span class="type">Request</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Request</span>.Builder()</span><br><span class="line">                .post(RequestBody.create(SCHEMA_CONTENT, CASE_SCHEMA))</span><br><span class="line">                .url(<span class="string">&quot;http://10.75.76.163:8081/subjects/Case/versions&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        <span class="type">String</span> <span class="variable">output</span> <span class="operator">=</span> client.newCall(request).execute().body().string();</span><br><span class="line">        System.out.println(output);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//LIST ALL SCHEMAS</span></span><br><span class="line">        request = <span class="keyword">new</span> <span class="title class_">Request</span>.Builder()</span><br><span class="line">                .url(<span class="string">&quot;http://10.75.76.163:8081/subjects&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        output = client.newCall(request).execute().body().string();</span><br><span class="line">        System.out.println(output);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ol>
<li><a href="https://dzone.com/articles/kafka-avro-serialization-and-the-schema-registry">较完整例子</a></li>
<li><a href="https://docs.confluent.io/current/schema-registry/docs/api.html">schema-registry的API文档</a></li>
<li><a href="https://docs.confluent.io/current/quickstart/cos-quickstart.html">confluent opensource简单部署(不用KSQL只用执行到”Step 3”)</a></li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>AILog</tag>
        <tag>Avro</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka 简单使用</title>
    <url>/2018/05/09/projects/ai-log/Kafka%20%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>在智能测试日志分析方案中，使用kafka作为消息集成的关键组件，简单记录一下使用的命令和docker搭建笔记。</p>
<span id="more"></span>
<h1 id="搭建部署"><a href="#搭建部署" class="headerlink" title="搭建部署"></a>搭建部署</h1><p>由于本人是半个docker狂魔，docker搭建在保持环境干净，启动停止应用上有突出的优势，遂使用docker形式作为先行方案。根据<a href="https://domino.research.ibm.com/library/cyberdig.nsf/papers/0929052195DD819C85257D2300681E7B/$File/rc25482.pdf">ibm上的论文</a>表示，cpu和内存损失较少，在网络IO上损耗多一点。在生产应用发现瓶颈后再去考虑native部署。</p>
<h2 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h2><blockquote>
<p>mkdir -p /home/tony/zookeeper/data /home/tony/zookeeper/datalog</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --restart always --name zookeeper \</span><br><span class="line">-p 2181:2181 \</span><br><span class="line">-v /home/tony/zookeeper/data:/data \</span><br><span class="line">-v /home/tony/zookeeper/datalog:/datalog \</span><br><span class="line">zookeeper:3.4</span><br></pre></td></tr></table></figure>
<h2 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h2><p>hub.docker.com上有好多镜像，最高的要自己build，在proxy环境下比较麻烦，构建过程中在alpine中用wget下载https报错。有些镜像是捆绑zookeeper，最后选择的是分开的，提供了data和logs映射的镜像。<br>远程连接kafka机器的broker需要注意，<code>config/server.properties</code>中<code>advertised.host.name</code>要配置为宿主机被访问的外网ip。如果是新版（0.10）以后，可以配置<code>advertised.listeners=PLAINTEXT://59.64.11.22:9092</code></p>
<blockquote>
<p>chown -R 1000:1000 data/ logs/</p>
</blockquote>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="language-bash"> -d --restart always --name kafka \</span></span><br><span class="line"><span class="language-bash">-p 7203:7203 \</span></span><br><span class="line"><span class="language-bash">-p 9092:9092 \</span></span><br><span class="line"><span class="language-bash">-v /home/tony/kafka/data:/data \</span></span><br><span class="line"><span class="language-bash">-v /home/tony/kafka/logs:/logs \</span></span><br><span class="line"><span class="language-bash">--<span class="built_in">link</span> zookeeper:zkhost \</span></span><br><span class="line"><span class="language-bash">-e ZOOKEEPER_IP=zkhost \</span></span><br><span class="line"><span class="language-bash">-e KAFKA_ADVERTISED_HOST_NAME=10.75.76.163 \</span></span><br><span class="line"><span class="language-bash">ches/kafka</span></span><br></pre></td></tr></table></figure>
<h1 id="控制台命令"><a href="#控制台命令" class="headerlink" title="控制台命令"></a>控制台命令</h1><p>可以进入到容器内执行，也可以在本地用官网最近的二进制文件。</p>
<h2 id="topic"><a href="#topic" class="headerlink" title="topic"></a>topic</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看所有topic</span></span><br><span class="line">bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br><span class="line"><span class="comment"># 创建</span></span><br><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic <span class="built_in">test</span></span><br><span class="line"><span class="comment"># 查看topic具体的信息</span></span><br><span class="line">bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<h2 id="producer"><a href="#producer" class="headerlink" title="producer"></a>producer</h2><blockquote>
<p>bin/kafka-console-producer.sh –broker-list localhost:9092 –topic test</p>
</blockquote>
<h2 id="consumer"><a href="#consumer" class="headerlink" title="consumer"></a>consumer</h2><blockquote>
<p>bin/kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic test –from-beginning</p>
</blockquote>
<h1 id="client"><a href="#client" class="headerlink" title="client"></a>client</h1><h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p>根据官网和infoQ的文章表示，在高性能要求的环境下，封装C库<code>Librdkafka</code>的confluent-kafka有较高性能。但是纯python实现的kafka-python功能一样全面，pip直接完事。另外还有更加”python-like”的<code>pykafka</code>，本身是纯python实现，也可以切换为libdkafka的实现。</p>
<h3 id="kafka-python"><a href="#kafka-python" class="headerlink" title="kafka-python"></a>kafka-python</h3><h4 id="producer-1"><a href="#producer-1" class="headerlink" title="producer"></a>producer</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaProducer  </span><br><span class="line">producer = KafkaProducer(bootstrap_servers=<span class="string">&#x27;10.75.76.163:9092&#x27;</span>, linger_ms=<span class="number">0</span>)  </span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):  </span><br><span class="line">    producer.send(<span class="string">&#x27;test&#x27;</span>, <span class="string">b&quot;from_windows4&quot;</span>)  </span><br><span class="line">producer.close()</span><br></pre></td></tr></table></figure>
<h4 id="consumer-1"><a href="#consumer-1" class="headerlink" title="consumer"></a>consumer</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaConsumer  </span><br><span class="line">consumer = KafkaConsumer(<span class="string">&quot;test&quot;</span>, bootstrap_servers=[<span class="string">&#x27;10.75.76.163:9092&#x27;</span>], api_version=(<span class="number">0</span>, <span class="number">10</span>))  </span><br><span class="line"><span class="keyword">for</span> msg <span class="keyword">in</span> consumer:  </span><br><span class="line">    <span class="built_in">print</span> (msg)</span><br><span class="line">consumer.close()</span><br></pre></td></tr></table></figure>
<h3 id="pykafka"><a href="#pykafka" class="headerlink" title="pykafka"></a>pykafka</h3><p><a href="https://github.com/Parsely/pykafka">https://github.com/Parsely/pykafka</a><br>以下示例仅用于helloworld测试，实际可能需要while(True)去生产或消费、异步地</p>
<h4 id="producer-2"><a href="#producer-2" class="headerlink" title="producer"></a>producer</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-  </span></span><br><span class="line"><span class="keyword">from</span> pykafka <span class="keyword">import</span> KafkaClient  </span><br><span class="line">client = KafkaClient(hosts=<span class="string">&quot;10.75.76.163:9092&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(client.topics)  </span><br><span class="line">topic = client.topics[<span class="string">&#x27;test&#x27;</span>]  </span><br><span class="line"><span class="comment"># 同步用法  </span></span><br><span class="line"><span class="keyword">with</span> topic.get_sync_producer() <span class="keyword">as</span> producer:  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):  </span><br><span class="line">        producer.produce(<span class="string">&#x27;pykafka produce test sync_message &#x27;</span> + <span class="built_in">str</span>(i ** <span class="number">2</span>))  </span><br><span class="line"><span class="comment"># 异步用法  </span></span><br><span class="line"><span class="keyword">with</span> topic.get_producer() <span class="keyword">as</span> producer:  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  </span><br><span class="line">        producer.produce(<span class="string">&#x27;pykafka produce test async_message &#x27;</span> + <span class="built_in">str</span>(i ** <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<h4 id="consumer-2"><a href="#consumer-2" class="headerlink" title="consumer"></a>consumer</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> pykafka <span class="keyword">import</span> KafkaClient</span><br><span class="line">client = KafkaClient(hosts=<span class="string">&quot;10.75.76.163:9092&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(client.topics)</span><br><span class="line">topic = client.topics[<span class="string">&#x27;test&#x27;</span>]</span><br><span class="line">consumer = topic.get_simple_consumer()</span><br><span class="line"><span class="keyword">for</span> message <span class="keyword">in</span> consumer:</span><br><span class="line">    <span class="keyword">if</span> message <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span> message.offset, message.value</span><br></pre></td></tr></table></figure>
<h3 id="confluent-kafka"><a href="#confluent-kafka" class="headerlink" title="confluent-kafka"></a>confluent-kafka</h3><p>windows搞这个库比较麻烦，先往后放一放，遇到性能瓶颈再优化。</p>
<h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><p>基本照抄官网例子，java的客户端文档不在client章节，在api章节(<a href="https://kafka.apache.org/documentation/#producerapi">https://kafka.apache.org/documentation/#producerapi</a>)</p>
<h3 id="依赖pom文件"><a href="#依赖pom文件" class="headerlink" title="依赖pom文件"></a>依赖pom文件</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.10.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="producer-3"><a href="#producer-3" class="headerlink" title="producer"></a>producer</h3><p><a href="https://kafka.apache.org/11/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html">https://kafka.apache.org/11/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Properties;  </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProducerDemo</span> &#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;  </span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();  </span><br><span class="line">  properties.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;10.75.76.163:9092&quot;</span>);  </span><br><span class="line">  properties.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);  </span><br><span class="line">  properties.put(<span class="string">&quot;retries&quot;</span>, <span class="number">0</span>);  </span><br><span class="line">  properties.put(<span class="string">&quot;batch.size&quot;</span>, <span class="number">16384</span>);  </span><br><span class="line">  properties.put(<span class="string">&quot;linger.ms&quot;</span>, <span class="number">1</span>);  </span><br><span class="line">  properties.put(<span class="string">&quot;buffer.memory&quot;</span>, <span class="number">33554432</span>);  </span><br><span class="line">  properties.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);  </span><br><span class="line">  properties.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);  </span><br><span class="line">  Producer&lt;String, String&gt; producer = <span class="literal">null</span>;  </span><br><span class="line"> <span class="keyword">try</span> &#123;  </span><br><span class="line">            producer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);  </span><br><span class="line"> <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;  </span><br><span class="line">                <span class="type">String</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="string">&quot;Message &quot;</span> + i;  </span><br><span class="line">  producer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;String, String&gt;(<span class="string">&quot;test&quot;</span>, msg));  </span><br><span class="line">  System.out.println(<span class="string">&quot;Sent:&quot;</span> + msg);  </span><br><span class="line">  &#125;  </span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;  </span><br><span class="line">            producer.close();  </span><br><span class="line">  &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="consumer-3"><a href="#consumer-3" class="headerlink" title="consumer"></a>consumer</h3><p><a href="https://kafka.apache.org/11/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html">https://kafka.apache.org/11/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConsumerDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;10.75.76.163:9092&quot;</span>);</span><br><span class="line">        properties.put(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;group-1&quot;</span>);</span><br><span class="line">        properties.put(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        properties.put(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);</span><br><span class="line">        properties.put(<span class="string">&quot;auto.offset.reset&quot;</span>, <span class="string">&quot;earliest&quot;</span>);</span><br><span class="line">        properties.put(<span class="string">&quot;session.timeout.ms&quot;</span>, <span class="string">&quot;30000&quot;</span>);</span><br><span class="line">        properties.put(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        properties.put(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line">        kafkaConsumer.subscribe(Arrays.asList(<span class="string">&quot;test&quot;</span>));</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(<span class="number">100</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.printf(<span class="string">&quot;offset = %d, value = %s&quot;</span>, record.offset(), record.value());</span><br><span class="line">                System.out.println();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>AILog</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>日志大数据笔记</title>
    <url>/2018/03/29/projects/ai-log/%E6%97%A5%E5%BF%97%E5%A4%A7%E6%95%B0%E6%8D%AE%EF%BC%88%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%89/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>测试岗位却不甘止步于业务测试，遂尝试智能化测试，当前的思路是通过日志大数据分析，协助自动化用例的诊断和建议。</p>
<h1 id="他山之石"><a href="#他山之石" class="headerlink" title="他山之石"></a>他山之石</h1><h2 id="《从日志统计到大数据分析》"><a href="#《从日志统计到大数据分析》" class="headerlink" title="《从日志统计到大数据分析》"></a>《从日志统计到大数据分析》</h2><p>知乎专栏作家桑文锋[<a href="http://SensorsData.cn]">http://SensorsData.cn]</a>(<a href="https://link.zhihu.com/">https://link.zhihu.com/</a>?<br>target=http%3A//SensorsData.cn)  神策数据创始人&amp;CEO</p>
<p>数据处理流程图<br><img src="https://pic1.zhimg.com/80/8c2c54621e4ef9777afd5a4f2abfc959_hd.jpg" alt="enter image description here"></p>
<h3 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h3><ol>
<li>全<br>多个来源、C/S（B/S）</li>
<li>细<br>多个维度，ip、url、时间、userid等等尽可能多</li>
<li>数据格式</li>
</ol>
<ul>
<li>Protocol Buffer：Google使用，较为重型</li>
<li>JSON：学习成本低</li>
<li>  <a href="https://link.zhihu.com/?target=http://thrift.apache.org/">Thrift</a>——由Facebook开源的一套开发框架和数据格式，相比PB，在解析效率上低点，但周边组件比较完善。</li>
<li>  <a href="https://link.zhihu.com/?target=http://avro.apache.org/">Avro</a>——由Hadoop创始人Doug Cutting主导开发的，使用接口上和Thrift类似，有客户公司在使用。<br>在简单看看文档后，估计会使用json。</li>
</ul>
<ol start="4">
<li>数据类型<br>被测应用自身日志、环境日志（cpu、容器内env）、测试脚本日志；<br>应用代码、测试脚本（代码本身）<br>数据库数据？</li>
</ol>
<h3 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h3><p>【这段完全照抄】<br>1，FTP：数据量小且时效性要求不高，用FTP是最省事的。<br>2，<a href="https://link.zhihu.com/?target=http://sqoop.apache.org/">Sqoop</a>：用于传统数据库和Hadoop之间的数据传输。<br><del>3，<a href="https://link.zhihu.com/?target=https://github.com/facebookarchive/scribe/wiki">Scribe</a>：Facebook开源的一套日志传输系统，github上已经不维护了。</del><br>4，<a href="https://link.zhihu.com/?target=https://flume.apache.org/">Flume</a>：Cloudera开源的一套日志传输系统，和Scribe类似。我们在百度做的Minos，可以说是和Flume、Scribe类似，那为啥要重复造轮子？主要百度的数据源和服务器太多了，需要做许多功能来满足运维管理的问题。<br>5，<a href="https://link.zhihu.com/?target=http://kafka.apache.org/">Kafka</a>：Linkedin开源的一套消息传输系统，和百度Bigpipe类似。我们Bigpipe开发了一半的时候，Kafka的论文发表了。Bigpipe会做去重，Kafka目前还没有这样的机制，需要自己去实现。两者都通过副本的机制，保证数据不丢。<br>Flume/Logstash/Beat 是同一类软件，如果抽象功能的话可以认为是一个插件执行器，有一些常用的插件（例如日志采集，Binlog解析，执行脚本等），也可以根据需求将自己的代码作为插件发布。</p>
<h4 id="知乎靠谱答案"><a href="#知乎靠谱答案" class="headerlink" title="知乎靠谱答案"></a>知乎靠谱答案</h4><p>Kafka 一般作为Pub-Sub管道，没有抓取功能。一开始设计的时候主要是Jay Krep觉得Linkedin里面数据源，消费者之间关系太复杂，如果是N个数据源，M个消费者，需要拉N*M个线，并且接口和协议不同，所以使用了一种消息中间件来解耦数据源和消费者。但Kafka本身也不算消息中间件，中间件一般会有Queue和Topic两种模型，Kafka主要是Topic类的模型。</p>
<p>对搭建日志系统而言，也没什么新花样，以下这些依样画葫芦就可以了：</p>
<ol>
<li>日志采集（Logstash/Flume，SDK wrapper）</li>
<li>实时消费 (Storm, Flink, Spark Streaming)</li>
<li>离线存储 （HDFS or Object Storage or NoSQL) + 离线分析（Presto，Hive，Hadoop）</li>
<li>有一些场景可能需要搜索，可以加上ES或ELK<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4></li>
<li>大概率采用Flume/kafka/hdfs(spark-ml)</li>
<li>重点关注<strong>部署与运维成本</strong></li>
</ol>
<h3 id="数据建模-存储"><a href="#数据建模-存储" class="headerlink" title="数据建模/存储"></a>数据建模/存储</h3><h4 id="多维数据模型"><a href="#多维数据模型" class="headerlink" title="多维数据模型"></a>多维数据模型</h4><p><img src="https://pic1.zhimg.com/80/f0c4386cb9f49243d12c05def4b3564f_hd.jpg"><br>在互联网产品中，最重要的有两类数据——业务数据和<code>用户行为数据</code>。对于用户行为数据，我们可以讲用户的每一次操作理解为一个事件（Event），事件有个类型如提交订单、提出问题等，事件发生时有响应的上下文，如使用的操作系统、浏览器版本等系统属性，也有事件特有的如运费、订单价格等属性，这些属性就是一系列的维度，还有一部分是事件发生的用户ID。即：  </p>
<blockquote>
<p>Event Type + Properties + UserID</p>
</blockquote>
<p>这里就形成了一系列的维度，描述的最细粒度的事件现场。通过UserID，我们还会关联到UserID这一维度的详情（User Profile），包括姓名、出生日期、身高、是否有小孩等。</p>
<h4 id="ETL存储"><a href="#ETL存储" class="headerlink" title="ETL存储"></a>ETL存储</h4><p>做好数据源，减少ETL。</p>
<h4 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h4><p>对于智能化测试来说，一个用例的执行应该就是一个事件，事件的属性可以是通过与否、报错信息、执行时间等，UserID可以是模块或者用例id吧。建模还是需要仔细考虑的。<br>不过数据源和ETL应该都只有测试自己搞了。</p>
<h3 id="数据统计、分析、挖掘"><a href="#数据统计、分析、挖掘" class="headerlink" title="数据统计、分析、挖掘"></a>数据统计、分析、挖掘</h3><h4 id="数据驱动"><a href="#数据驱动" class="headerlink" title="数据驱动"></a>数据驱动</h4><p>能不能做好数据，开放自助查询的功能？</p>
<h4 id="查询模式："><a href="#查询模式：" class="headerlink" title="查询模式："></a>查询模式：</h4><ul>
<li>  K-V（Key-Value）查询就是我们给出一个key，然后返回这个key相关的value内容。比如我们通过一个UserID，返回用户的一些画像信息，比如有没有房。再比如，通过UserID返回最近一段时间的详细访问行为序列。这里推荐使用HBase。  </li>
<li>  OLAP（Online Analytical Processing）查询就是前面讲的多维数据分析，这里不赘述。可以使用的工具有InfoBright、Vertica、Impala、Redshift等。</li>
<li>  Ad Hoc查询就是有各种各样的不确定的需求，需要响应。这块可以用Hive，或者Spark SQL来满足，再不行就写程序自己实现吧。</li>
<li>ES，支持一些模糊的查询<h4 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h4></li>
</ul>
<ol>
<li>哪个模块失败数最多</li>
<li>什么时间段执行最多问题</li>
<li>什么类型的报错最多<h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4></li>
<li>用例失败原因<h4 id="挖掘"><a href="#挖掘" class="headerlink" title="挖掘"></a>挖掘</h4></li>
<li>协助写用例 (推荐步骤、类似用例）</li>
<li>推断模块稳定性</li>
</ol>
<h3 id="可视化与反馈"><a href="#可视化与反馈" class="headerlink" title="可视化与反馈"></a>可视化与反馈</h3><h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><ol>
<li>对接看板，提供数据或时序交互，有点像数据底座的功能</li>
<li>Echarts或D3提供web版基本的可视化功能</li>
<li><a href="http://www.tableau.com">Tableau</a> ？</li>
</ol>
<h3 id="整体数据流与架构图"><a href="#整体数据流与架构图" class="headerlink" title="整体数据流与架构图"></a>整体数据流与架构图</h3><p><img src="https://pic1.zhimg.com/80/dab490303b0bc3fe47dd0bffa16d20b9_hd.jpg"><br>元数据和调度器分别是数据平台的心脏和大脑。</p>
<h3 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h3><p>如果有很多请求的时候，需要优先级调度；（现在可能用不上）<br>如果请求有依赖的时候，使用DAG调度；（Azkaban可以完成）</p>
<h3 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h3><p>开源实现可以参考Hcatalog，封装了hive meta。</p>
<p><strong>元数据提供的服务</strong>  主要有三点：  </p>
<ol>
<li> 数据的Schema：表、字段定义等。</li>
<li>数据的就绪状态：数据就绪时间、存放位置等动态信息。</li>
<li>元数据的访问API。</li>
</ol>
<p><strong>扩展的服务</strong>还包括：  </p>
<ul>
<li>  权限控制（ACL）：严格来说ACL不算元数据的一部分，但这两者关系太紧密，一般放在一起考虑。</li>
<li>  元数据的变更记录：谁做了什么操作好做审计，另外可以有元数据的版本信息，这样对历史数据的存取更方便一些。</li>
</ul>
]]></content>
      <tags>
        <tag>AILog</tag>
      </tags>
  </entry>
  <entry>
    <title>科目四突击</title>
    <url>/2021/10/12/%E7%A7%91%E7%9B%AE%E5%9B%9B%E7%AA%81%E5%87%BB/</url>
    <content><![CDATA[<p>第四季度，必须考过专业级</p>
<span id="more"></span>

<h1 id="科目四：软件设计与重构-考纲"><a href="#科目四：软件设计与重构-考纲" class="headerlink" title="科目四：软件设计与重构 考纲"></a>科目四：软件设计与重构 考纲</h1><h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><ul>
<li>理解软件需求分析基本概念和原则；</li>
<li>理解软件需求分析流程每个阶段关键活动及注意事项，如需求获取、分解、排序、验收、跟踪、变更等过程，以及需求相关文档等输出件的写作和验收要求；</li>
<li>理解需求分析需要关注的场景和维度，如功能需求、DFX需求（可维护性需求、系统资源与性能要求、安全需求等非功能性需求）识别；</li>
<li>理解需求分析和评估方法，如需求分解方法 、排序方法、安全威胁分析方法、系统资源占用分析、ASTRIDE分析方法等。<h2 id="软件设计与建模"><a href="#软件设计与建模" class="headerlink" title="软件设计与建模"></a>软件设计与建模</h2></li>
<li>理解常见软件设计概念，了解常见的软件结构；</li>
<li>熟悉常用的软件设计方法和原则，如面向对象设计方法、SOLID原则等，了解领域驱动设计、演进式设计的实践；</li>
<li>熟练掌握软件建模方法和工具，如UML图、4+1视图等，能够使用工具表现合理的抽象封装；</li>
<li>了解23种经典设计模式的特点和应用场景，熟练掌握抽象工厂、适配器、工厂方法、观察者、策略 、状态、代理、外观、单件(singleton)、模板方法、装饰器模式的应用与实现。<h2 id="可信设计"><a href="#可信设计" class="headerlink" title="可信设计"></a>可信设计</h2></li>
<li>掌握常见软件设计中各个领域应用的安全威胁及对应的安全设计方法，包括身份和访问控制管理、密钥管理、会话管理、安全设计、隐私保护、密码学算法应用等；</li>
<li>掌握常见的安全设计原则及安全设计方法，包括安全开发设计指导规则(HCSEC Golden Rules)、安全设计原则、安全设计模式、威胁建模工程方法（ASTRIDE）等。<h2 id="重构分析与实现"><a href="#重构分析与实现" class="headerlink" title="重构分析与实现"></a>重构分析与实现</h2></li>
<li>掌握重构的概念和原则，熟悉不同层级（函数级、模块级、架构级）软件重构的流程和方法；</li>
<li>掌握重构防护网的建设方法，能够识别重构的风险并建立相关质量保障措施；</li>
<li>掌握经典的坏味道识别方法；</li>
<li>掌握软件宏观和微观层面的代码重构手法，熟练掌握经典重构手法及其对应的反向重构方法的实施。</li>
</ul>
<h2 id="需求分析-1"><a href="#需求分析-1" class="headerlink" title="需求分析"></a>需求分析</h2><h3 id="需求分析基本概念和原则"><a href="#需求分析基本概念和原则" class="headerlink" title="需求分析基本概念和原则"></a>需求分析基本概念和原则</h3><p>需求分析的任务就是解决“做什么”的问题，就是要全面地理解用户的各项要求，并准确地表达所接受的用户需求。</p>
<p>需求分析的输入是目标，问题和场景，输出是形式化的功能规约，质量属性和设计约束，分析过程中要考虑众多涉众利益和DFX属性。</p>
<p>非功能需求等于质量需求，非功能需求主要指不明确的功能性需求，需求分析阶段应将不明确的功能性需求细化成功能性需求。</p>
<p>需求包括功能性需求、质量性能需求和约束。</p>
<h3 id="需求分析活动和注意事项"><a href="#需求分析活动和注意事项" class="headerlink" title="需求分析活动和注意事项"></a>需求分析活动和注意事项</h3><p>总的来说，分为：</p>
<ol>
<li>问题识别（确定业务目标、达成标准）</li>
<li>分析与综合（细化功能、非功能需求，排优先级）</li>
<li>规格说明（需求规格说明书）</li>
<li>评审（达成共同的理解和认识）</li>
</ol>
<p>我司常用《基于用例（Use-Case）技术需求分析方法》，具体的活动是：</p>
<ol>
<li>收集需求（访谈、考察、研讨等形式，识别功能、性能、质量、约束）优先级排序也在此</li>
<li>定义系统边界（明确系统的分析范围）</li>
<li>识别Actor（系统边界外、与系统有交互、人/物/定时器）谁使用系统、谁提供信息给系统、谁维护管理系统、自动触发的事件</li>
<li>识别Use Case（对Actor可见，对Actor有价值、系统实现）系统执行的一系列动作，生成Actor可观测、有价值的结果</li>
<li>整理场景（可在哪些用户场景使用，有哪些输入，适当组合归并）主场景、可选场景、异常场景</li>
<li>描述Use Case（详细、完整的用例阐述）用例图为骨架，用例规约为肉。名称、标识、简要说明、actor、前置条件、后置条件、正常/异常事件流、DFX、遗留问题</li>
</ol>
<p>需求分析输出的质量准则包括<strong>完整性</strong>，<strong>正确性</strong>，<strong>可验证性</strong>和<strong>一致性</strong>。</p>
<p>补充需求获取的方法：</p>
<ol>
<li>实地观察个人的工作情况</li>
<li>访谈，但要真实理解用户想解决的问题，不要被他的解决方案掩盖了实际的需求</li>
<li>特定群体调查（对一组人员调查，了解工作态度和共同看法）</li>
<li>问卷调查（统计意义上的数据）</li>
<li>用户指导（最终用户直接告诉，他们是如何操作系统的）</li>
<li>原型制作（涉及生命安全、高成本的）</li>
<li>统计版本（有统计功能的程序记录用户完成任务的方式）</li>
</ol>
<p>补充需求优先级排序的方法：</p>
<ol>
<li>入选与落选法： 二分法决定下一版本需求</li>
<li>三层分级：关注高优先级，如果还是超出工作量，再三分</li>
<li>KANO模型法：基本型需求必须满足，期望型需求实现程度与客户满意度成正比</li>
<li>两两比较：小于20条需求可用</li>
<li>100美元法： 团队对需求标价，价高者优先级高</li>
<li>二八原则：优先满足收入占比80%的核心用户需求</li>
<li>性价比法：核心业务需求优先，投入产出比高的优先</li>
</ol>
<h3 id="需求管理"><a href="#需求管理" class="headerlink" title="需求管理"></a>需求管理</h3><p>需求管理活动：</p>
<ol>
<li>变更控制（保持项目计划与需求的同步、）</li>
<li>版本控制（项目团队和用户达成共识，定义需求基线）</li>
<li>状态跟踪（项目过程中，跟踪需求状态和变更情况）</li>
<li>需求跟踪（需求与设计、代码、测试用例联系起来）</li>
</ol>
<h2 id="可信设计-1"><a href="#可信设计-1" class="headerlink" title="可信设计"></a>可信设计</h2><p>安全经典三要素：机密性(Confidentiality)，完整性(Integrity)，可用性(Availablity)<br>安全目标：完整性，保密性，可用性，<strong>隐私保护</strong>，<strong>可追溯性</strong>。</p>
<p>安全设计原则：</p>
<ol>
<li>开放设计原则，安全不依赖保密，私有的“加密”算法。</li>
<li>失败-默认安全原则，失败安全，默认安全。</li>
<li>权限分离原则，分离不同进程的权责，三权分立（系统管理员，安全管理员，安全审计员）。</li>
<li>最小权限原则，确保应用程序使用最低权限运行，禁止使用最高权限连接数据库。</li>
<li>经济适用原则，简单，精巧，组件化，不要过度设计，更安全有效的组件化架构设计。</li>
<li>最小公共化原则，共享内存最小化，端口绑定最小化，减少连接，防御DoS攻击。</li>
<li>完全仲裁原则，每次访问都要校验用户权限，DNS缓存欺骗。</li>
<li>心理可承受原则，12306验证码，为用户着想的验证码，记住密码。</li>
<li>纵深防御原则，是一个综合性很高的防御原则，一般要求系统架构师综合运用其他的各类安全设计原则，采用多点、多重的安全校验机制，高屋建瓴地从系统架构层面来关注整个系统级的安全防御机制，而不能只依赖单一安全机制。</li>
</ol>
<p>安全架构设计原则解读：</p>
<p>构建最小权限、纵深防御、最小公共化、权限分离、不轻信、开放设计、完全仲裁、失效安全、保护薄弱环节、安全机制经济性、用户接受度以及加强隐私保护的安全体系，确保系统、网络和数据的机密性、完整性、可用性、可追溯性。</p>
<h3 id="ASTRIDE-Low-Level威胁分析"><a href="#ASTRIDE-Low-Level威胁分析" class="headerlink" title="ASTRIDE Low Level威胁分析"></a>ASTRIDE Low Level威胁分析</h3><p>威胁建模流程：绘制数据流图，威胁分析，风险评估，制定消减措施，产品响应。</p>
<h4 id="数据流图元素"><a href="#数据流图元素" class="headerlink" title="数据流图元素"></a>数据流图元素</h4><p>外部交互方：能驱动系统业务，但不受系统控制的人和物（如用户，管理员，第三方系统等）.通常表示目标系统的输入/输出。涉及到个人数据需要在元素概述中详细列举元素涉及的高、中、低影响的个人数据。</p>
<p>处理过程：一个过程执行一个任务时的逻辑表示，例如Web Server 、ftp server、LMT server</p>
<p>数据存储：数据存储表示文件、数据库、注册表项、内存等。涉及到个人数据需要在元素概述中详细列举元素涉及的高、中、低影响的个人数据。</p>
<p>数据流：数据在系统中的移动方向，如网络通讯、共享内存、函数调用等。涉及到个人数据需要在元素概述中详细列举元素涉及的高、中、低影响的个人数据。</p>
<p>信任边界：当数据流穿越不同的信任级别（区域）时，就存在信任边界，例如从用户态到内核态，从客户端到服务端等。</p>
<h4 id="威胁分析"><a href="#威胁分析" class="headerlink" title="威胁分析"></a>威胁分析</h4><p>Spoofing仿冒，Tampering篡改，Repudiation抵赖，Imformation Disclosure信息泄漏，Denial of Service拒绝服务，Elevation of Privilege权限提升，Privacy：隐私（非法处理个人数据）。</p>
<p>外部交互方：能驱动系统业务，但不受系统控制的人和物（如用户，管理员，第三方系统等）.通常表示目标系统的输入/输出。涉及到个人数据需要在元素概述中详细列举元素涉及的高、中、低影响的个人数据。</p>
<p>处理过程：一个过程执行一个任务时的逻辑表示，例如Web Server 、ftp server、LMT server</p>
<p>数据存储：数据存储表示文件、数据库、注册表项、内存等。涉及到个人数据需要在元素概述中详细列举元素涉及的高、中、低影响的个人数据。</p>
<p>数据流：数据在系统中的移动方向，如网络通讯、共享内存、函数调用等。涉及到个人数据需要在元素概述中详细列举元素涉及的高、中、低影响的个人数据。</p>
<p>信任边界：当数据流穿越不同的信任级别（区域）时，就存在信任边界，例如从用户态到内核态，从客户端到服务端等。</p>
<table>
<thead>
<tr>
<th>元素</th>
<th>S(spoofing)仿冒</th>
<th>T(tampering)篡改</th>
<th>R(Repudiation)抵赖</th>
<th>D(Info disclosure)信息泄露</th>
<th>D(denial of service)拒绝服务</th>
<th>E(Elevation of Privilege)提权</th>
<th>P(privacy)隐私</th>
</tr>
</thead>
<tbody><tr>
<td>外部交互方</td>
<td>√</td>
<td>-</td>
<td>√</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>√</td>
</tr>
<tr>
<td>处理过程</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>-</td>
</tr>
<tr>
<td>数据存储</td>
<td>-</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>-</td>
<td>√</td>
</tr>
<tr>
<td>数据流</td>
<td>-</td>
<td>√</td>
<td>-</td>
<td>√</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
</tbody></table>
<ul>
<li>外部交互： 仿冒S， 抵赖R</li>
<li>处理过程： 全部</li>
<li>数据存储： 篡改T，抵赖R（审计日志），信息泄露I，拒绝服务D</li>
<li>数据流： 篡改T，信息泄露I，拒绝D</li>
</ul>
<ol>
<li><p>仿冒： 外部交互方（克隆手机）、处理过程（假的BTS基站）</p>
</li>
<li><p>篡改T： 处理过程（修改特性）、数据存储（改账单）、数据流（中间人攻击）</p>
</li>
<li><p>抵赖R： 外部交互方（管理员操作）、处理过程（日志逻辑）、数据存储（修改审计日志）</p>
</li>
<li><p>信息泄露： 处理过程（黑客秘钥）、数据存储（明文口令）、数据流（明文口令）</p>
</li>
<li><p>拒绝服务： 处理过程（程序崩溃）、数据存储（磁盘满）、数据流（网络断流）</p>
</li>
<li><p>提权： 处理过程（用户账户分配了其他权限）</p>
</li>
<li><p>隐私： 外部交互方（收集IMEI等）、数据存储（未匿名化）</p>
</li>
<li><p>仿冒S： 认证（密码、SSL、IPSec、SSH）</p>
</li>
<li><p>篡改T： 完整性（Hash、MAC、数字签名、ACL）</p>
</li>
<li><p>抵赖R： 防抵赖（认证、审计日志）</p>
</li>
<li><p>信息泄露I： 机密性（加密、ACL）</p>
</li>
<li><p>拒绝服务： 可用性（负载均衡、过滤、缓存）</p>
</li>
<li><p>提权： 授权（权限最小化、沙箱）</p>
</li>
<li><p>隐私： 合法（匿名化、用户可知可控、数据最小化）</p>
</li>
</ol>
<p>隐私威胁分析：可识别，不一致，不可控，不可知，不安全。<br>增量分析场景：绘制数据流图，<strong>变更识别</strong>，危险分析，风险评估，制定消减措施，产品响应。</p>
<p>场景化扩展：<strong>场景化构建</strong>，绘制数据流图，变更识别，危险分析，风险评估，制定消减措施，产品响应。</p>
<h3 id="加密算法"><a href="#加密算法" class="headerlink" title="加密算法"></a>加密算法</h3><p>安全： AES&gt;=128, SHA256, ECDSA&gt;=256, ECDH&gt;=256, RSA&gt;=2048, DSC&gt;=2048, DH&gt;=2048</p>
<p>遗留系统可用： 3DES（k1/k2/k3各不相同）, RC4&gt;=128, SHA1, RSA_1024, DSA_1024, DH_1024</p>
<p>不安全： Blowfish, DES, DESX, RC2, Skipjack, 2TDEA, TEA, SEAL, CYLINK_MEK, RC4&lt;128, SHA0, MD2/4/5, RIPEMD*, RSA&lt;1024, DH&lt;1024, ECDSA&lt;=160</p>
<p>密码哈希： PBKDF2, BCRYPT, SCRYPT, Argon2</p>
<p>PBKDF2是标准的密钥派生函数</p>
<h2 id="软件设计与建模-1"><a href="#软件设计与建模-1" class="headerlink" title="软件设计与建模"></a>软件设计与建模</h2><p>软件建模体现了软件设计的思想，在需求和实现之间架起了一座桥梁，通过模型指导软件系统的具体实现。模型并不是软件系统的一个完备表示，而是所研究的系统的一种抽象。软件建模通过不同的视角去描述一个系统。</p>
<p>软件建模体现了软件设计的思想，在需求和实现之间架起了一座桥梁，通过模型指导软件系统的具体实现。模型并不是软件系统的一个完备表示，而是所研究的系统的一种抽象。软件建模通过不同的视角去描述一个系统。</p>
<p>UML内容组成：</p>
<p>事物：结构事物（用例、接口、协作等），行为事物（交互、状态机），组织事物（包），辅助事物（注释）。</p>
<p>关系：关联，依赖，泛化，实现。</p>
<p>图：静态图（用例图，类图，对象图，组件图，部署图），动态图（顺序图，合作图，状态图，活动图）。</p>
<p>软件系统架构的定义：系统架构 = 组件 + 交互 + 重要决策集。<br>安全架构的定义：    安全架构 = 系统业务架构 + 安全控制集。</p>
<p>提供架构4+1视图集：</p>
<ul>
<li>逻辑视图：系统架构师, PM, SE。</li>
<li>运行视图：SE, 开发, 测试工程师。</li>
<li>数据视图：数据库, 开发工程师。</li>
<li>物理数图：运维, 部署工程师。</li>
<li>开发视图：开发, 配置工程师。</li>
</ul>
<p>UML 4+1视图：</p>
<ul>
<li>逻辑视图：类图，对象图。</li>
<li>实现视图：组件图。</li>
<li>部署视图：部署图。</li>
<li>行为视图：顺序图，合作图，状态图，活动图。</li>
<li>用户视图：用例图。</li>
</ul>
<p>UML在软件开发流程中的应用：</p>
<ul>
<li>需求分析：用例图。</li>
<li>概要设计，详细设计：类图，对象图，合作图，顺序图，状态图，活动图。</li>
<li>编码阶段：无</li>
<li>测试：类图，组件图，部署图。</li>
</ul>
<p>视角和类图：</p>
<ul>
<li>交互化视角：用例图。</li>
<li>结构化视角：类图。</li>
<li>行为视角：顺序图，活动图，状态图。</li>
</ul>
<p>用例图包含关系：</p>
<p>Include：包含也可以叫Use，表示本用例会用到被包含的其他用例，被包含的用例是可以被重用的。</p>
<p>Extend：扩展用例是可选的，在特定场景下可以补充基础用例，降低基础用例的复杂性。</p>
<p>Generalization：泛化体现了父子关系，表明存在派生和继承。</p>
<p>类图包含关系：</p>
<p>实现（Realization）：是一种类与接口的关系，表示类是接口所有特征和行为的实现。例如：借阅者能查找书籍。</p>
<p>依赖（Dependency）：是一种使用的关系，有单向依赖和双向依赖，但避免使用双向依赖。例如：借阅者查找结果依赖标题。</p>
<p>泛化（Generalization）：是一种继承关系，指定了子类继承父类的所有特征和行为。例如：借阅者是老师或者学生。</p>
<p>关联（Association）：是一种拥有的关系，它使一个类知道另一个类的属性和方法。例如：借阅者的借阅记录或预约记录。</p>
<p>聚合（Aggregation）：是整体与个体的关系，可以理解成把个体聚集在一起。例如：借阅者的多条借阅记录。</p>
<p>组合（Composition）：是整体与局部的关系，整体的对象负责代表局部的对象的生命周期，可以理解成整体是由局部组成的。例如：借阅记录必须要有相关书籍信息。</p>
<p><strong>各种关系的强弱顺序</strong>： 泛化=实现&gt;组合&gt;聚合&gt;关联&gt;依赖</p>
<p>三角实线=三角虚线&gt;菱形实线&gt;菱形虚线&gt;箭头实线&gt;箭头虚线</p>
<p>记忆技巧： 类图关系连线的箭头，指向内容和范围较小的类。<br>箭头指向接口、父类、依赖的内容；菱形指向整体</p>
<p>用例图描述系统在干什么。动态模型是描述系统的功能是如何完成的，用顺序图、活动图和状态图从不同的角度来描述对象和对象之间的交互。</p>
<p>动态图作用和场景：</p>
<p>顺序图：强调消息时间顺序的交互图。描述复杂的多对象间交互。并发、分支过多的场景会影响可理解性。</p>
<p>活动图：用于对目标对象计算流程和工作流程建模。描述涉及到复杂的活动步骤的用例。特别并发、分支等场景。</p>
<p>状态图：描述了系统元素的状态条件和响应，它反映了类的对象可能具有的状态，以及引起状态变化的事件。涉及到复杂的状态变化的场景，也适用于并发场景，如网络连接的会话状态等。状态图仅用于具有下列特点的类：具有若干个确定的状态，类的行为在这些状态下会受到影响变为其他状态。</p>
<p>题目：<br>用例图中的Include关系是对应的UML四个关系中哪一种关系： 依赖</p>
<h2 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h2><p>正交四原则：</p>
<ol>
<li>最小化重复</li>
<li>分离变化</li>
<li>缩小依赖范围</li>
<li>向稳定方向依赖</li>
</ol>
<p>SOLID原则：</p>
<ol>
<li>单一职责SRP，一个类，引起它变化的原因只有一个。如果一个变化，导致多处修改，则存在重复。</li>
<li>开闭原则OCP，对扩展开放，对修改关闭。多个变化导致一处修改，则对变化的识别不准，容易考虑不周，修改引入。</li>
<li>里氏替换原则LSP，基类设定一系列的规范和契约，子类需要遵守。</li>
<li>接口分离原则ISP，客户只需要了解必须了解的。不要暴漏的细节。</li>
<li>依赖倒置原则DIP，接口为稳定的契约，双方都依赖于抽象，不依赖于具体实现；上层定义接口，下层实现接口</li>
</ol>
<h3 id="23种设计模式："><a href="#23种设计模式：" class="headerlink" title="23种设计模式："></a>23种设计模式：</h3><p>创建型：</p>
<ol>
<li>Factory Method（工厂方法）：隔离创建对象的细节，使得创建对象的行为可扩展</li>
<li>Abstract Factory（抽象工厂）：该模式抽象出创建一组相关对象的接口，其中每个方法即为factory method</li>
<li>Builder（建造者）：与factory不同的是，该模式包含了对象构造的若干过程，因此天然地与template结合</li>
<li>Prototype（原型）: 用于以某个对象为模子创建一个新对象的场景，例如幻灯片中的母版与普通页、对象的克隆</li>
<li>Singleton（单例）：</li>
</ol>
<p>结构型：</p>
<ol start="6">
<li>Adapter Class/Object（适配器）：处理遗留系统的不二法宝，也可以用空方法实现接口作为抽象父类</li>
<li>Bridge（桥接）: 使用关联代替继承，解决类多维度的扩展导致的类爆炸的问题</li>
<li>Composite（组合）：将组件组装为整体使用</li>
<li>Decorator（装饰）：常见于各种wrapper，常用于在原函数执行前后做一些额外的工作</li>
<li>Facade（外观）：封装扇出，利用树状结构减少调用者的复杂度</li>
<li>Flyweight（享元）：复用变化少的对象</li>
<li>Proxy（代理）：是原对象的一个完整的替代品</li>
</ol>
<p>行为型：</p>
<ol start="13">
<li>Interpreter（解释器）：一般用于解释执行自定义的某种语法</li>
<li>Template Method（模板方法）：框架与钩子</li>
<li>Chain of Responsibility（责任链）：一组对象按照既定的顺序关联起来，依次处理请求，其中任一对象都有权停止调用传递</li>
<li>Command（命令）: 将行为抽象和解耦</li>
<li>Iterator（迭代器）：封装数据的访问行为（顺序、可见性等）</li>
<li>Mediator（中介者）：用一个中介对象来封装一系列的交互;新增一个模块处理两个模块的交互</li>
<li>Memento（备忘录）：将当前对象的状态信息保存为另一个对象，使得当前对象可以基于状态镜像快速恢复原状态</li>
<li>Observer（观察者）: 订阅/发布模型，用于事件驱动的设计</li>
<li>State（状态）：封装FSM（有限状态机）的状态与状态迁移，每个状态定义了自身的输入与状态迁移</li>
<li>Strategy（策略）：使用接口即使用strategy，用于隔离变化</li>
<li>Visitor（访问者）：数据与行为分离方法。通过这种分离，可达到一个被访问者动态添加新的操作而无需做其他的修改的效果</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>人脸年龄预测</title>
    <url>/2018/04/20/ai/%E4%BA%BA%E8%84%B8%E5%B9%B4%E9%BE%84%E9%A2%84%E6%B5%8B/</url>
    <content><![CDATA[<h1 id="实战操刀"><a href="#实战操刀" class="headerlink" title="实战操刀"></a>实战操刀</h1><h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><p><a href="https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar">https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar</a><br><a href="https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar">https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar</a><br>数据说明：<a href="https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/">https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/</a></p>
<h2 id="解析元数据"><a href="#解析元数据" class="headerlink" title="解析元数据"></a>解析元数据</h2><p>元数据wiki.mat、imdab.mat是已matlab形式的mat文件存的，可以用scipy.io.loadmat读取。<br>|属性| 值 | 含义|<br>|–|–|–|<br>|gender | nan/0/1 | 0 for female and 1 for male, <em>NaN</em> if unknown|<br>|face_score|nan/float| <em>NaN</em> 没有人脸，得分越高越确定人脸|<br>|second_face_score|nan或float|第二张人脸的的人，越高越确定，<code>_NaN_</code>表示没有第二张脸|<br>|dob|不知道|date of birth (Matlab serial date number)用来算age，有些age算出来超出常理。要丢弃|</p>
<h1 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h1><h2 id="人脸图像的年龄估计技术研究"><a href="#人脸图像的年龄估计技术研究" class="headerlink" title="人脸图像的年龄估计技术研究"></a>人脸图像的年龄估计技术研究</h2><p>王先梅，综述，主要讲述深度学习前的人脸年龄估计的技术。包括特征提取和估计算法等，很全面。</p>
<h2 id="基于卷积神经网络的人脸年龄估计算法"><a href="#基于卷积神经网络的人脸年龄估计算法" class="headerlink" title="基于卷积神经网络的人脸年龄估计算法"></a>基于卷积神经网络的人脸年龄估计算法</h2><p>周旺，南京大学。主要使用显著图方式增强数据，并对数据倾斜部分的进行迁移学习训练。能学会数据增加方式和迁移学习。提供了开源做法的指引</p>
<h2 id="人脸检测及人脸年龄与性别识别方法"><a href="#人脸检测及人脸年龄与性别识别方法" class="headerlink" title="人脸检测及人脸年龄与性别识别方法"></a>人脸检测及人脸年龄与性别识别方法</h2><p>张军挺，中国科学技术大学，faster r-cnn用cnn提取特征；多尺度LBP+AdaBoost；深度和传统方式都做了，rcnn也用了迁移学习的方法。提取后使用随机森林做预测</p>
<h2 id="Deep-expectation-of-real-and-apparent-age-from-a-single-image-without-facial-landmarks"><a href="#Deep-expectation-of-real-and-apparent-age-from-a-single-image-without-facial-landmarks" class="headerlink" title="Deep expectation of real and apparent age from a single image without facial landmarks"></a>Deep expectation of real and apparent age from a single image without facial landmarks</h2><p>LAP2015冠军，imdb-wiki数据提供者<br>旋转图片后，选择最高分的脸。<br>脸扩展40%的像素，以免脸的边缘到达图片边缘（padding时候有问题，也就是脸过大的问题），也使得所有图片保持一致。如果找不到脸，用整张图。<br>vgg16迁移<br>分类预测–&gt;加权平均</p>
<h2 id="Apparent-Age-Estimation-from-Face-Images-Combining-General-and-Children-Specialized-Deep-Learning-Models"><a href="#Apparent-Age-Estimation-from-Face-Images-Combining-General-and-Children-Specialized-Deep-Learning-Models" class="headerlink" title="Apparent Age Estimation from Face Images Combining General and Children-Specialized Deep Learning Models"></a><a href="https://cactus.orange-labs.fr/apparent-age-estimation/">Apparent Age Estimation from Face Images Combining General and Children-Specialized Deep Learning Models</a></h2><p>LAP2016，人脸年龄v2比赛冠军<br>年龄编码的方式</p>
<p>##Apparent Age Estimation Using Ensemble of Deep Learning Models<br>LAP2016， 人脸年龄v2第5名</p>
<h1 id="code"><a href="#code" class="headerlink" title="code"></a>code</h1><p><code>hog.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> feature <span class="keyword">as</span> ft</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> utils</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_hog</span>(<span class="params">img_full_path</span>):</span><br><span class="line">    ori = <span class="number">8</span></span><br><span class="line">    ppc = (<span class="number">16</span>, <span class="number">16</span>)</span><br><span class="line">    cpb = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    image = io.imread(img_full_path)</span><br><span class="line">    features = ft.hog(image,  <span class="comment"># input image</span></span><br><span class="line">                      orientations=ori,  <span class="comment"># number of bins</span></span><br><span class="line">                      pixels_per_cell=ppc,  <span class="comment"># pixel per cell</span></span><br><span class="line">                      cells_per_block=cpb,  <span class="comment"># cells per blcok</span></span><br><span class="line">                      block_norm=<span class="string">&#x27;L2-Hys&#x27;</span>,  <span class="comment"># block norm : str &#123;‘L1’, ‘L1-sqrt’, ‘L2’, ‘L2-Hys’&#125;, optional</span></span><br><span class="line">                      transform_sqrt=<span class="literal">True</span>,  <span class="comment"># power law compression (also known as gamma correction)</span></span><br><span class="line">                      feature_vector=<span class="literal">True</span>,  <span class="comment"># flatten the final vectors</span></span><br><span class="line">                      visualise=<span class="literal">False</span>)  <span class="comment"># return HOG map</span></span><br><span class="line">    <span class="keyword">return</span> features</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">task</span>(<span class="params">data_dir, stage, paths, ages, position</span>):</span><br><span class="line">    file_name = os.path.join(data_dir, <span class="string">&quot;%s_%d.txt&quot;</span> % (stage, position))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> i, img_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(paths):</span><br><span class="line">            img_path = img_path[<span class="number">1</span>:] <span class="keyword">if</span> img_path[<span class="number">0</span>] == <span class="string">&quot;/&quot;</span> <span class="keyword">else</span> img_path</span><br><span class="line">            features = extract_hog(os.path.join(data_dir, img_path))</span><br><span class="line">            line = <span class="string">&quot;,&quot;</span>.join([<span class="built_in">str</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> features]) + <span class="string">&quot;,&quot;</span> + <span class="built_in">str</span>(ages[i]) + <span class="string">&quot;\n&quot;</span></span><br><span class="line">            f.write(line)</span><br><span class="line">    <span class="keyword">return</span> file_name</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_pool_results</span>(<span class="params">data_dir, results</span>):</span><br><span class="line">    merged_file = os.path.join(data_dir, <span class="string">&quot;hog.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(merged_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> wf:</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> results:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> rf:</span><br><span class="line">                wf.writelines(rf.readlines())</span><br><span class="line">        <span class="comment"># os.remove(file)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">simple_process</span>(<span class="params">data_dir, meta_file</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;not fast enough&quot;&quot;&quot;</span></span><br><span class="line">    paths = <span class="built_in">list</span>()</span><br><span class="line">    ages = <span class="built_in">list</span>()</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(data_dir, meta_file), <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            ss = line.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">            paths.append(ss[<span class="number">0</span>])</span><br><span class="line">            ages.append(ss[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(data_dir, <span class="string">&quot;hog_all.txt&quot;</span>), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> tqdm.trange(<span class="built_in">len</span>(paths)):</span><br><span class="line">            feature = extract_hog(os.path.join(data_dir, paths[i]))</span><br><span class="line">            line = <span class="string">&quot;,&quot;</span>.join([<span class="built_in">str</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> feature]) + <span class="string">&quot;,&quot;</span> + <span class="built_in">str</span>(ages[i]) + <span class="string">&quot;\n&quot;</span></span><br><span class="line">            f.write(line)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data_dir&#x27;</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&#x27;data dir&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--process&#x27;</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&#x27;how many process&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    process = <span class="built_in">int</span>(args.process) <span class="keyword">if</span> args.process <span class="keyword">else</span> <span class="number">32</span></span><br><span class="line">    data_dir = args.data_dir <span class="keyword">if</span> args.data_dir <span class="keyword">else</span> <span class="string">&quot;/home/tony/data&quot;</span></span><br><span class="line"></span><br><span class="line">    stage = <span class="string">&quot;hog&quot;</span></span><br><span class="line">    meta_file = <span class="string">&quot;aligned_meta.txt&quot;</span></span><br><span class="line"></span><br><span class="line">    results = <span class="built_in">list</span>()</span><br><span class="line"></span><br><span class="line">    train_path, train_age = utils.read_meta_data(data_dir, meta_file)</span><br><span class="line">    <span class="comment"># train_path = train_path[0:100]</span></span><br><span class="line">    <span class="comment"># train_age = train_age[0:100]</span></span><br><span class="line">    n = <span class="built_in">int</span>(math.ceil(<span class="built_in">len</span>(train_path) / <span class="built_in">float</span>(process)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(train_path))</span><br><span class="line"></span><br><span class="line">    pool = multiprocessing.Pool(processes=process)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(train_path), n):</span><br><span class="line">        t = pool.apply_async(task, args=(data_dir, stage, train_path[i: i + n], train_age[i:i + n], i,))</span><br><span class="line">        results.append(t)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line"></span><br><span class="line">    merge_pool_results(data_dir, [t.get() <span class="keyword">for</span> t <span class="keyword">in</span> results])</span><br><span class="line">    [os.remove(os.path.join(data_dir, t.get())) <span class="keyword">for</span> t <span class="keyword">in</span> results]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>align.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> dlib</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> imutils.face_utils <span class="keyword">import</span> FaceAligner</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process <span class="keyword">as</span> pro, Pool</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line">cur_dir = os.path.dirname(__file__)</span><br><span class="line"><span class="comment"># cur_dir = os.path.dirname(os.path.abspath(__file__))</span></span><br><span class="line">data_dir = os.path.join(cur_dir, <span class="string">&quot;data&quot;</span>)</span><br><span class="line"><span class="comment"># data_dir = r&quot;d:/data&quot;  # special for windows</span></span><br><span class="line">classifier_xml = os.path.join(data_dir, <span class="string">&quot;haarcascade_frontalface_alt2.xml&quot;</span>)</span><br><span class="line">predictor_path = os.path.join(data_dir, <span class="string">&quot;shape_predictor_68_face_landmarks.dat&quot;</span>)</span><br><span class="line"></span><br><span class="line">detector = dlib.get_frontal_face_detector()</span><br><span class="line">predictor = dlib.shape_predictor(predictor_path)</span><br><span class="line">fa = FaceAligner(predictor, desiredFaceWidth=<span class="number">160</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">opencv_recognize</span>(<span class="params">img_path</span>):</span><br><span class="line">    face_patterns = cv2.CascadeClassifier(classifier_xml)</span><br><span class="line">    sample_image = cv2.imread(img_path)</span><br><span class="line">    <span class="comment"># cv2.imshow(&quot;image&quot;, sample_image)</span></span><br><span class="line">    faces = face_patterns.detectMultiScale(sample_image, scaleFactor=<span class="number">1.1</span>, minNeighbors=<span class="number">5</span>, minSize=(<span class="number">100</span>, <span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (x, y, w, h) <span class="keyword">in</span> faces:</span><br><span class="line">        cv2.rectangle(sample_image, (x, y), (x + w, y + h), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># cv2.imwrite(&#x27;/Users/abel/201612_detected.png&#x27;, sample_image)</span></span><br><span class="line">    cv2.imshow(<span class="string">&quot;image&quot;</span>, sample_image)</span><br><span class="line">    cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dlib_recognize_and_align</span>(<span class="params">img_path</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;加载人脸检测器、加载官方提供的模型构建特征提取器&#x27;&#x27;&#x27;</span></span><br><span class="line">    win = dlib.image_window()</span><br><span class="line">    detector = dlib.get_frontal_face_detector()</span><br><span class="line">    predictor = dlib.shape_predictor(predictor_path)</span><br><span class="line">    brg_img = cv2.imread(img_path)</span><br><span class="line">    rgb_img = cv2.cvtColor(brg_img, cv2.COLOR_BGRA2RGB)</span><br><span class="line">    dets = detector(rgb_img, <span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Number of faces detected: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(dets)))</span><br><span class="line">    <span class="keyword">for</span> i, d <span class="keyword">in</span> <span class="built_in">enumerate</span>(dets):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Detection &#123;&#125;: Left: &#123;&#125; Top: &#123;&#125; Right: &#123;&#125; Bottom: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">            i, d.left(), d.top(), d.right(), d.bottom()))</span><br><span class="line"></span><br><span class="line">    win.clear_overlay()</span><br><span class="line">    win.set_image(rgb_img)</span><br><span class="line">    win.add_overlay(dets)</span><br><span class="line">    dlib.hit_enter_to_continue()</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">align_and_save</span>(<span class="params">data_dir, img_path</span>):</span><br><span class="line">    full_path = os.path.join(data_dir, img_path)</span><br><span class="line">    bgr_img = cv2.imread(full_path, <span class="number">0</span>)</span><br><span class="line">    gray = bgr_img</span><br><span class="line">    <span class="comment"># gray = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)</span></span><br><span class="line">    rects = detector(gray, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(rects) != <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    img = fa.align(gray, gray, rects[<span class="number">0</span>])</span><br><span class="line">    new_file_path = os.path.join(data_dir, <span class="string">&quot;aligned&quot;</span>, img_path)</span><br><span class="line">    aligned_dir = os.path.dirname(new_file_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(aligned_dir):</span><br><span class="line">        os.makedirs(aligned_dir)</span><br><span class="line">    cv2.imwrite(new_file_path, img)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crop_train_face</span>(<span class="params">train_path, train_age</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;single process&quot;&quot;&quot;</span></span><br><span class="line">    pre_len = <span class="built_in">len</span>(train_path)</span><br><span class="line">    new_path = <span class="built_in">list</span>()</span><br><span class="line">    new_age = <span class="built_in">list</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(pre_len)):</span><br><span class="line">        img_path = data_dir + train_path[i]</span><br><span class="line">        new_file_path = align_and_save(img_path)</span><br><span class="line">        new_path.append(new_file_path)</span><br><span class="line">        new_age.append(train_age[i])</span><br><span class="line">    <span class="keyword">return</span> new_path, new_age</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">task</span>(<span class="params">data_dir, stage, img_paths, ages, position</span>):</span><br><span class="line">    file_name = os.path.join(data_dir, <span class="string">&quot;%s_%d.txt&quot;</span> % (stage, position))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> i, img_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_paths):</span><br><span class="line">            img_path = img_path[<span class="number">1</span>:] <span class="keyword">if</span> img_path[<span class="number">0</span>] == <span class="string">&quot;/&quot;</span> <span class="keyword">else</span> img_path</span><br><span class="line">            <span class="keyword">if</span> align_and_save(data_dir, img_path):</span><br><span class="line">                f.write(<span class="string">&quot;aligned/%s %d\n&quot;</span> % (img_path, ages[i]))</span><br><span class="line">    <span class="keyword">return</span> file_name</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_pool_results</span>(<span class="params">data_dir, results</span>):</span><br><span class="line">    merged_file = os.path.join(data_dir, <span class="string">&quot;aligned_meta.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(merged_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> wf:</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> results:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> rf:</span><br><span class="line">                wf.writelines(rf.readlines())</span><br><span class="line">        os.remove(file)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chunks</span>(<span class="params">arr, m</span>):</span><br><span class="line">    n = <span class="built_in">int</span>(math.ceil(<span class="built_in">len</span>(arr) / <span class="built_in">float</span>(m)))</span><br><span class="line">    <span class="keyword">return</span> [arr[i:i + n] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(arr), n)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data_dir&#x27;</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&#x27;data dir&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--process&#x27;</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&#x27;how many process&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    process = <span class="built_in">int</span>(args.process) <span class="keyword">if</span> args.process <span class="keyword">else</span> <span class="number">32</span></span><br><span class="line">    data_dir = args.data_dir <span class="keyword">if</span> args.data_dir <span class="keyword">else</span> <span class="string">&quot;/home/tony/data&quot;</span></span><br><span class="line"></span><br><span class="line">    stage = <span class="string">&quot;train&quot;</span></span><br><span class="line">    meta_file = <span class="string">&quot;wiki.txt&quot;</span></span><br><span class="line">    results = <span class="built_in">list</span>()</span><br><span class="line">    train_path, train_age = utils.read_meta_data(data_dir, meta_file)</span><br><span class="line">    n = <span class="built_in">int</span>(math.ceil(<span class="built_in">len</span>(train_path) / <span class="built_in">float</span>(process)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(train_path))</span><br><span class="line"></span><br><span class="line">    pool = Pool(processes=process)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(train_path), n):</span><br><span class="line">        t = pool.apply_async(task, args=(data_dir, stage, train_path[i: i + n], train_age[i:i + n], i,))</span><br><span class="line">        results.append(t)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line"></span><br><span class="line">    merge_pool_results(data_dir, [t.get() <span class="keyword">for</span> t <span class="keyword">in</span> results])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>unify_meta_data.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> get_meta</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> trange</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">MAX_AGE = <span class="number">117</span></span><br><span class="line">logger = logging.getLogger()</span><br><span class="line">handler = logging.StreamHandler()</span><br><span class="line">formatter = logging.Formatter(</span><br><span class="line">    <span class="string">&#x27;%(asctime)s %(name)s %(levelname)s %(message)s&#x27;</span>)</span><br><span class="line">handler.setFormatter(formatter)</span><br><span class="line">logger.addHandler(handler)</span><br><span class="line">logger.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">filter_unusual</span>(<span class="params">full_path, gender, face_score, second_face_score, age</span>):</span><br><span class="line">    <span class="comment"># label filter</span></span><br><span class="line">    gender_idx = np.where(~np.isnan(gender))[<span class="number">0</span>]</span><br><span class="line">    age_idx = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(age)) <span class="keyword">if</span> <span class="number">0</span> &lt;= age[i] &lt;= MAX_AGE]</span><br><span class="line">    <span class="comment"># face filter</span></span><br><span class="line">    <span class="comment"># face_score_idx = np.where(face_score &lt;= 0)[0]</span></span><br><span class="line">    <span class="comment"># second_face_score_idx = np.where(second_face_score&gt;0)[0]</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.intersect1d(gender_idx, age_idx)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main_process</span>(<span class="params">data_path, db, limit=<span class="literal">None</span></span>):</span><br><span class="line">    mat_path = os.path.join(data_path, db + <span class="string">&quot;_crop&quot;</span>, db + <span class="string">&quot;.mat&quot;</span>)</span><br><span class="line">    full_path, dob, gender, photo_taken, face_score, second_face_score, age = get_meta(mat_path, db)</span><br><span class="line">    ok_idx = filter_unusual(full_path, gender, face_score, second_face_score, age)</span><br><span class="line">    meta_file = os.path.join(data_path, db + <span class="string">&quot;.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(meta_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> trange(<span class="built_in">len</span>(ok_idx)):</span><br><span class="line">            <span class="keyword">if</span> limit <span class="keyword">and</span> i &gt;= <span class="built_in">int</span>(limit):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            f.write(<span class="string">&quot;%s_crop/%s %d\n&quot;</span> % (db, full_path[i][<span class="number">0</span>], age[i]))</span><br><span class="line">    <span class="keyword">return</span> meta_file</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data_path = <span class="built_in">str</span>(sys.argv[<span class="number">1</span>]) <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="string">r&quot;d:/data&quot;</span></span><br><span class="line">    data_path = <span class="string">&quot;/home/tony/data&quot;</span></span><br><span class="line">    db = <span class="string">&quot;wiki&quot;</span></span><br><span class="line">    meta_file = main_process(data_path, db)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;meta_file: &quot;</span> + meta_file)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>utils.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># utils.py</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calc_age</span>(<span class="params">taken, dob</span>):</span><br><span class="line">    birth = datetime.fromordinal(<span class="built_in">max</span>(<span class="built_in">int</span>(dob) - <span class="number">366</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># assume the photo was taken in the middle of the year</span></span><br><span class="line">    <span class="keyword">if</span> birth.month &lt; <span class="number">7</span>:</span><br><span class="line">        <span class="keyword">return</span> taken - birth.year</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> taken - birth.year - <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_meta</span>(<span class="params">mat_path, db</span>):</span><br><span class="line">    meta = loadmat(mat_path)</span><br><span class="line">    full_path = meta[db][<span class="number">0</span>, <span class="number">0</span>][<span class="string">&quot;full_path&quot;</span>][<span class="number">0</span>]</span><br><span class="line">    dob = meta[db][<span class="number">0</span>, <span class="number">0</span>][<span class="string">&quot;dob&quot;</span>][<span class="number">0</span>]  <span class="comment"># Matlab serial date number</span></span><br><span class="line">    gender = meta[db][<span class="number">0</span>, <span class="number">0</span>][<span class="string">&quot;gender&quot;</span>][<span class="number">0</span>]</span><br><span class="line">    photo_taken = meta[db][<span class="number">0</span>, <span class="number">0</span>][<span class="string">&quot;photo_taken&quot;</span>][<span class="number">0</span>]  <span class="comment"># year</span></span><br><span class="line">    face_score = meta[db][<span class="number">0</span>, <span class="number">0</span>][<span class="string">&quot;face_score&quot;</span>][<span class="number">0</span>]</span><br><span class="line">    second_face_score = meta[db][<span class="number">0</span>, <span class="number">0</span>][<span class="string">&quot;second_face_score&quot;</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># age = np.array(map(calc_age, photo_taken, dob))  # python 2/3 staff</span></span><br><span class="line">    age = [calc_age(photo_taken[i], dob[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dob))]</span><br><span class="line">    <span class="keyword">return</span> full_path, dob, gender, photo_taken, face_score, second_face_score, age</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mk_dir</span>(<span class="params"><span class="built_in">dir</span></span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        os.mkdir(<span class="built_in">dir</span>)</span><br><span class="line">    <span class="keyword">except</span> OSError:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_meta_data</span>(<span class="params">data_dir, file_name</span>):</span><br><span class="line">    path = <span class="built_in">list</span>()</span><br><span class="line">    age = <span class="built_in">list</span>()</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(data_dir, file_name)) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            ss = line.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">            path.append(ss[<span class="number">0</span>])</span><br><span class="line">            age.append(<span class="built_in">int</span>(ss[<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">return</span> path, age</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    mat_path = <span class="string">r&quot;D:\wiki_crop\wiki.mat&quot;</span></span><br><span class="line">    db = <span class="string">&quot;wiki&quot;</span></span><br><span class="line">    full_path, dob, gender, photo_taken, face_score, second_face_score, age = get_meta(mat_path, db)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>svm.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&quot;/home/tony/data&quot;</span></span><br><span class="line">hog_file = <span class="string">&quot;hog.txt&quot;</span></span><br><span class="line"></span><br><span class="line">train_data = pd.read_csv(os.path.join(data_dir, hog_file), header=<span class="literal">None</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(train_data.values[:, <span class="number">0</span>:-<span class="number">1</span>], train_data.values[:, -<span class="number">1</span>],</span><br><span class="line">                                                    test_size=<span class="number">0.1</span>, random_state=<span class="number">2018</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># PCA</span></span><br><span class="line"><span class="comment"># pca = PCA(n_components=100, whiten=True)</span></span><br><span class="line"><span class="comment"># X_train = pca.fit_transform(X_train)</span></span><br><span class="line"><span class="comment"># X_test = pca.fit_transform(X_test)</span></span><br><span class="line"><span class="comment"># print(X_train.shape)</span></span><br><span class="line"><span class="comment"># print(X_test.shape)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># svc</span></span><br><span class="line">svr = svm.LinearSVR()</span><br><span class="line">svr.fit(X_train, y_train)</span><br><span class="line">pre = svr.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># metrics</span></span><br><span class="line">mae = sklearn.metrics.mean_absolute_error(y_test, pre)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mae: %f&quot;</span> % mae)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>rfr.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&quot;/home/tony/data&quot;</span></span><br><span class="line">hog_file = <span class="string">&quot;hog.txt&quot;</span></span><br><span class="line"></span><br><span class="line">train_data = pd.read_csv(os.path.join(data_dir, hog_file), header=<span class="literal">None</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(train_data.values[:, <span class="number">0</span>:-<span class="number">1</span>], train_data.values[:, -<span class="number">1</span>],</span><br><span class="line">                                                    test_size=<span class="number">0.1</span>, random_state=<span class="number">2018</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># PCA</span></span><br><span class="line"><span class="comment"># pca = PCA(n_components=100, whiten=True)</span></span><br><span class="line"><span class="comment"># X_train = pca.fit_transform(X_train)</span></span><br><span class="line"><span class="comment"># X_test = pca.fit_transform(X_test)</span></span><br><span class="line"><span class="comment"># print(X_train.shape)</span></span><br><span class="line"><span class="comment"># print(X_test.shape)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># svc</span></span><br><span class="line">regr = RandomForestRegressor(n_estimators=<span class="number">320</span>, n_jobs=<span class="number">32</span>, random_state=<span class="number">2018</span>, verbose=<span class="number">1</span>)</span><br><span class="line">regr.fit(X_train, y_train)</span><br><span class="line">pre = regr.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># metrics</span></span><br><span class="line">mae = sklearn.metrics.mean_absolute_error(y_test, pre)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mae: %f&quot;</span> % mae)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="试验数据"><a href="#试验数据" class="headerlink" title="试验数据"></a>试验数据</h1><h2 id="各类特征pca512后，直接串连"><a href="#各类特征pca512后，直接串连" class="headerlink" title="各类特征pca512后，直接串连"></a>各类特征pca512后，直接串连</h2><h3 id="LogisticRegression"><a href="#LogisticRegression" class="headerlink" title="LogisticRegression"></a>LogisticRegression</h3><p>LogisticRegression on hog(512) resulting mae: 12.534653<br>LogisticRegression on lbp(512) resulting mae: 12.316832<br>LogisticRegression on vgg(512) resulting mae: 5.792079<br>LogisticRegression on hog_lbp(1024) resulting mae: 12.564356<br>LogisticRegression on hog_vgg(1024) resulting mae: 4.762376<br>LogisticRegression on lbp_vgg(1024) resulting mae: 5.118812<br>LogisticRegression on hog_lbp_vgg(1536) resulting mae: 4.841584</p>
<h3 id="LinearSVR"><a href="#LinearSVR" class="headerlink" title="LinearSVR"></a>LinearSVR</h3><p>LinearSVR on hog(512) resulting mae: 13.975740<br>LinearSVR on lbp(512) resulting mae: 14.171815<br>LinearSVR on vgg(512) resulting mae: 6.477576<br>LinearSVR on hog_lbp(1024) resulting mae: 22.368721<br>LinearSVR on hog_vgg(1024) resulting mae: 9.580384<br>LinearSVR on lbp_vgg(1024) resulting mae: 11.537682<br>LinearSVR on hog_lbp_vgg(1536) resulting mae: 6.361257</p>
<h3 id="SVR-rbf"><a href="#SVR-rbf" class="headerlink" title="SVR(rbf)"></a>SVR(rbf)</h3><p>SVR on hog(512) resulting mae: 11.496392<br>SVR on lbp(512) resulting mae: 11.600109<br>SVR on vgg(512) resulting mae: 11.721817<br>SVR on hog_lbp(1024) resulting mae: 11.682743<br>SVR on hog_vgg(1024) resulting mae: 11.624635<br>SVR on lbp_vgg(1024) resulting mae: 11.608328<br>SVR on hog_lbp_vgg(1536) resulting mae: 11.349862</p>
<h3 id="rf"><a href="#rf" class="headerlink" title="rf"></a>rf</h3><p>RandomForestRegressor on hog(512) resulting mae: 11.234653<br>RandomForestRegressor on lbp(512) resulting mae: 12.245545<br>RandomForestRegressor on vgg(512) resulting mae: 5.855446<br>RandomForestRegressor on hog_lbp(1024) resulting mae: 10.981188<br>RandomForestRegressor on hog_vgg(1024) resulting mae: 5.754455<br>RandomForestRegressor on lbp_vgg(1024) resulting mae: 5.740594<br>RandomForestRegressor on hog_lbp_vgg(1536) resulting mae: 6.240594</p>
<h3 id="ada"><a href="#ada" class="headerlink" title="ada"></a>ada</h3><p>AdaBoostRegressor on hog(512) resulting mae: 11.469027<br>AdaBoostRegressor on lbp(512) resulting mae: 11.945927<br>AdaBoostRegressor on vgg(512) resulting mae: 6.560440<br>AdaBoostRegressor on hog_lbp(1024) resulting mae: 10.853807<br>AdaBoostRegressor on hog_vgg(1024) resulting mae: 6.464129<br>AdaBoostRegressor on lbp_vgg(1024) resulting mae: 6.640677<br>AdaBoostRegressor on hog_lbp_vgg(1536) resulting mae: 6.807597</p>
<h2 id="直接串联融合"><a href="#直接串联融合" class="headerlink" title="直接串联融合"></a>直接串联融合</h2><p>先全部pca skb-f_regression skb-mutual_info_regression</p>
<h3 id="LinearSVR-1"><a href="#LinearSVR-1" class="headerlink" title="LinearSVR"></a>LinearSVR</h3><p>LinearSVR on hog_lbp(300) resulting mae: 6.277855<br>LinearSVR on hog_vgg(300) resulting mae: 5.596323<br>LinearSVR on lbp_vgg(300) resulting mae: 6.167967<br>LinearSVR on hog_lbp_vgg(300) resulting mae: 5.759966</p>
<p>LinearSVR on hog_lbp(150) resulting mae: 5.891156<br>LinearSVR on hog_vgg(150) resulting mae: 5.809739<br>LinearSVR on lbp_vgg(150) resulting mae: 5.940609<br>LinearSVR on hog_lbp_vgg(150) resulting mae: 5.626772</p>
<p>LinearSVR on hog_lbp(60) resulting mae: 5.666367<br>LinearSVR on hog_vgg(60) resulting mae: 5.797798<br>LinearSVR on lbp_vgg(60) resulting mae: 6.250504<br>LinearSVR on hog_lbp_vgg(60) resulting mae: 5.709871</p>
<h2 id="hog-pca512，lbp-pac512，vgg512后融合"><a href="#hog-pca512，lbp-pac512，vgg512后融合" class="headerlink" title="hog-pca512，lbp-pac512，vgg512后融合"></a>hog-pca512，lbp-pac512，vgg512后融合</h2><p>PCA30+LDA30+f_regression30+mutual_info_regression30<br>LinearSVR on hog_lbp(120) resulting mae: 2.708872<br>LinearSVR on hog_vgg(120) resulting mae: 2.525526<br>LinearSVR on lbp_vgg(120) resulting mae: 2.654724<br>LinearSVR on hog_lbp_vgg(120) resulting mae: 4.254801</p>
<h2 id="hog-1700-，-lbp-16000-，-vgg512融合"><a href="#hog-1700-，-lbp-16000-，-vgg512融合" class="headerlink" title="hog-1700+， lbp-16000+， vgg512融合"></a>hog-1700+， lbp-16000+， vgg512融合</h2><p>PCA30+LDA30+f_regression30+mutual_info_regression30<br>LinearSVR on hog_lbp(120) resulting mae: 3.564676<br>LinearSVR on hog_vgg(120) resulting mae: 3.800873<br>LinearSVR on lbp_vgg(120) resulting mae: 5.523058<br>LinearSVR on hog_lbp_vgg(120) resulting mae: 5.760532&gt;</p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>人脸</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 笔记</title>
    <url>/2018/04/25/ops/Docker/Docker%20%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>docker的配置要点、常见问题、命令、姿势。</p>
<span id="more"></span>

<h1 id="安装-amp-配置"><a href="#安装-amp-配置" class="headerlink" title="安装&amp;配置"></a>安装&amp;配置</h1><h2 id="docker-ce"><a href="#docker-ce" class="headerlink" title="docker-ce"></a>docker-ce</h2><p>官网指南：<a href="https://docs.docker.com/install/">https://docs.docker.com/install/</a><br>中文翻译：<a href="https://yeasy.gitbooks.io/docker_practice/content/install/ubuntu.html">https://yeasy.gitbooks.io/docker_practice/content/install/ubuntu.html</a></p>
<h2 id="docker-compose"><a href="#docker-compose" class="headerlink" title="docker-compose"></a>docker-compose</h2><p><a href="https://github.com/docker/compose/releases/">https://github.com/docker/compose/releases/</a><br>sudo chmod +x /usr/local/bin/docker-compose</p>
<h2 id="docker-machine"><a href="#docker-machine" class="headerlink" title="docker-machine"></a>docker-machine</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">base=https://github.com/docker/machine/releases/download/v0.14.0 &amp;&amp;</span><br><span class="line">  curl -L <span class="variable">$base</span>/docker-machine-$(<span class="built_in">uname</span> -s)-$(<span class="built_in">uname</span> -m) &gt;/tmp/docker-machine &amp;&amp;</span><br><span class="line">  sudo install /tmp/docker-machine /usr/local/bin/docker-machine</span><br></pre></td></tr></table></figure>

<h2 id="配置代理"><a href="#配置代理" class="headerlink" title="配置代理"></a>配置代理</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/systemd/system/docker.service.d/http-proxy.conf &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">Environment=&quot;HTTP_PROXY=http://100.100.154.250:3128&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/systemd/system/docker.service.d/https-proxy.conf &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">Environment=&quot;HTTP_PROXY=http://100.100.154.250:3128&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>
<h2 id="仓库改源-信任源"><a href="#仓库改源-信任源" class="headerlink" title="仓库改源 信任源"></a>仓库改源 信任源</h2><p>如果在公司代理之后，https使用ssl链接经常会出现证书问题(如<code>x509: certificate signed by unknown authority</code>)，可以选择其他镜像，或忽略安全证书。<br>参考：<a href="https://docs.docker.com/registry/insecure/#use-self-signed-certificates">https://docs.docker.com/registry/insecure/#use-self-signed-certificates</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">mkdir</span> -p /etc/docker</span><br><span class="line">sudo <span class="built_in">tee</span> /etc/docker/daemon.json &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;registry-mirrors&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;https://1nj0zren.mirror.aliyuncs.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.mirrors.ustc.edu.cn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;http://f1361db2.m.daocloud.io&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://dockerhub.azk8s.cn&quot;</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>
<h2 id="安全证书"><a href="#安全证书" class="headerlink" title="安全证书"></a>安全证书</h2><p>如果在公司代理之后，https使用ssl链接经常会出现证书问题(如<code>x509: certificate signed by unknown authority</code>)，也可以选择添加证书到系统。<br>以<code>docker pull docker.elastic.co/elasticsearch/elasticsearch:6.3.0</code>为例，会出现<code>Error response from daemon: Get https://docker.elastic.co/v2/: x509: certificate signed by unknown authority</code>可以看到主域名为<code>elastic.co</code></p>
<ol>
<li>打开浏览器 <a href="https://docker.elastic.co/v2/">https://docker.elastic.co/v2/</a></li>
<li>(以windows的chrome为例)，点击地址栏左侧绿色的安全两字–&gt;证书–&gt;详细信息–&gt;复制到文件–&gt;选择Base64的cer，导出为elastic.cer文件</li>
<li>在docker宿主机<code>mkdir -p /etc/docker/certs.d/elastic.co</code>，elastic.co为对应的主域名</li>
<li>将elastic.cer文件拷贝到/etc/docker/certs.d/elastic.co/elastic.crt</li>
<li>重启docker，<code>sudo systemctl restart docker</code></li>
<li>可以正常拉取了</li>
</ol>
<h2 id="重启docker-daemon以生效"><a href="#重启docker-daemon以生效" class="headerlink" title="重启docker-daemon以生效"></a>重启docker-daemon以生效</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#更新变化</span></span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line"><span class="comment">#重启docker</span></span><br><span class="line">sudo systemctl restart docker</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="挂载的volume没有写权限"><a href="#挂载的volume没有写权限" class="headerlink" title="挂载的volume没有写权限"></a>挂载的volume没有写权限</h2><p>有一类容器需要在宿主机读写文件做持久化，宿主机的目录data属于userA，然而容器内运行的用户是userB，通常会造成没有写权限而报错。更准确地说，不是根据用户名，而是根据uid/gid来判断权限的。</p>
<p><code>cat /etc/passwd</code>可以看出系统所有用户，<code>whoami</code>可以查看当前的用户名，<code>id username</code>可以查看username的用户uid和gid。通常来说，宿主机和容器内的uid/gid有以下对应关系：</p>
<table>
<thead>
<tr>
<th>用户</th>
<th>宿主机</th>
<th>容器内</th>
</tr>
</thead>
<tbody><tr>
<td>root</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>nobody</td>
<td>99</td>
<td>65534</td>
</tr>
<tr>
<td>第一个useradd的用户</td>
<td>1000</td>
<td>1000</td>
</tr>
</tbody></table>
<p>通常来说，我们将要挂载的目录的属主在为1000，一般就没问题。例如将<code>~/data</code>改为容器内的用户</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chown</span> -R 1000:1000 ~/data</span><br></pre></td></tr></table></figure>
<h2 id="proxy环境与docker-network"><a href="#proxy环境与docker-network" class="headerlink" title="proxy环境与docker network"></a>proxy环境与docker network</h2><p>这不是常见问题，但如果你在一家需要代理上网的公司，你有可能遇上。</p>
<h3 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h3><p>众所周知，docker容器内的ip默认是<code>172.17.0.0</code>网段，新建一个docker network的网段是<code>172.18.0.0</code>。非常巧的是，我司的代理服务器的ip刚好是<code>172.18.xx.xx</code>。此时如果用docker-compose，通常会新建一个网络，然后加到linux路由中，本来应该走代理的请求走到了新建的docker网络。表现为逐个容器都能启动，一旦使用docker-compose或swarm就不行了，无法通过代理拉取新的镜像。</p>
<h3 id="手工指定docker-compose使用网络的网段对症下药"><a href="#手工指定docker-compose使用网络的网段对症下药" class="headerlink" title="手工指定docker-compose使用网络的网段对症下药"></a>手工指定docker-compose使用网络的网段对症下药</h3><p>知道原因之后就好办了，规避的方法很简单，指定使用默认的网卡docker0。或者手工指定新建网络的网段。<br>手工指定docker-compose使用网络的网段：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">default:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">bridge</span></span><br><span class="line">    <span class="attr">ipam:</span></span><br><span class="line">      <span class="attr">config:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">subnet:</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.0</span><span class="string">/24</span></span><br><span class="line">          <span class="attr">gateway:</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span></span><br></pre></td></tr></table></figure>
<h3 id="指定使用默认的网络"><a href="#指定使用默认的网络" class="headerlink" title="指定使用默认的网络"></a>指定使用默认的网络</h3><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">zookeeper:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">confluentinc/cp-zookeeper:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/tony/kafka/zk-data:/var/lib/zookeeper/data</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/tony/kafka/zk-txn-logs:/var/lib/zookeeper/log</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">ZOOKEEPER_CLIENT_PORT:</span> <span class="number">32181</span></span><br><span class="line">      <span class="attr">ZOOKEEPER_TICK_TIME:</span> <span class="number">2000</span></span><br><span class="line">    <span class="attr">extra_hosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;moby:127.0.0.1&quot;</span></span><br></pre></td></tr></table></figure>


<h1 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h1><h2 id="调试-amp-生产启动命令"><a href="#调试-amp-生产启动命令" class="headerlink" title="调试&amp;生产启动命令"></a>调试&amp;生产启动命令</h2><h3 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h3><p>在调试的时候，经常要修改启动的命令和参数，希望能看到实时控制台信息。</p>
<blockquote>
<p>docker run –rm -it mysql</p>
</blockquote>
<h3 id="生产"><a href="#生产" class="headerlink" title="生产"></a>生产</h3><p>在实际生产环境使用时，希望以daemon形式、固定的名字运行，最好能自动重启。</p>
<blockquote>
<p>docker run -d -name mysql5.6 –restart always mysql</p>
</blockquote>
<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><h3 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build -t target_name &lt;directory&gt;</span><br><span class="line">docker build -t friendlyhello .</span><br></pre></td></tr></table></figure>
<h3 id="打包镜像"><a href="#打包镜像" class="headerlink" title="打包镜像"></a>打包镜像</h3><blockquote>
<p>docker save -o outputImage.tar <repo>/<image>:<tag></p>
</blockquote>
<h3 id="加载镜像"><a href="#加载镜像" class="headerlink" title="加载镜像"></a>加载镜像</h3><blockquote>
<p>docker load –input some_image.tar</p>
</blockquote>
<h3 id="重命名镜像"><a href="#重命名镜像" class="headerlink" title="重命名镜像"></a>重命名镜像</h3><blockquote>
<p>docker tag <image_id> <repo>/<image>:<tag></p>
</blockquote>
<h3 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -p 4000:80 friendlyhello</span><br><span class="line">docker run -d -p 4000:80 friendlyhello <span class="comment">#后台形式</span></span><br></pre></td></tr></table></figure>
<h3 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -ti &lt;containerName&gt; bash</span><br><span class="line">docker <span class="built_in">exec</span> -ti &lt;containerId&gt; bash</span><br><span class="line">docker <span class="built_in">exec</span> -ti –user nobody vbadaemon1 bash <span class="comment"># 以nobody用户进入容器</span></span><br></pre></td></tr></table></figure>

<h3 id="查看容器"><a href="#查看容器" class="headerlink" title="查看容器"></a>查看容器</h3><blockquote>
<p>docker ps</p>
</blockquote>
<h3 id="停止容器"><a href="#停止容器" class="headerlink" title="停止容器"></a>停止容器</h3><blockquote>
<p>docker stop 1fa4ab2cf395  #刚才ps的container id</p>
</blockquote>
<h3 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h3><blockquote>
<p>docker rm 1fa4ab2cf395  #刚才ps的container id</p>
</blockquote>
<h3 id="批量删除"><a href="#批量删除" class="headerlink" title="批量删除"></a>批量删除</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">rm</span> $(docker ps -a | grep <span class="string">&#x27;node-&#x27;</span> | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>) -f</span><br><span class="line">docker <span class="built_in">rm</span> $(docker ps -a | grep <span class="string">&#x27;selenium/hub&#x27;</span> | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>) -f</span><br></pre></td></tr></table></figure>
<h3 id="删除未使用的镜像"><a href="#删除未使用的镜像" class="headerlink" title="删除未使用的镜像"></a>删除未使用的镜像</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker ps -a | grep <span class="string">&quot;Exited&quot;</span> | awk <span class="string">&#x27;&#123;print $1 &#125;&#x27;</span>|xargs docker stop</span><br><span class="line">docker ps -a | grep <span class="string">&quot;Exited&quot;</span> | awk <span class="string">&#x27;&#123;print $1 &#125;&#x27;</span>|xargs docker <span class="built_in">rm</span></span><br><span class="line">docker images|grep none|awk <span class="string">&#x27;&#123;print $3 &#125;&#x27;</span>|xargs docker rmi</span><br></pre></td></tr></table></figure>

<h3 id="网络相关"><a href="#网络相关" class="headerlink" title="网络相关"></a>网络相关</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker network <span class="built_in">ls</span></span><br><span class="line"><span class="comment">#(默认有host bridge none三个)</span></span><br><span class="line">docker network <span class="built_in">rm</span></span><br><span class="line"><span class="comment">#容器内获取宿主机ip, 容器内执行</span></span><br><span class="line">ip route|awk <span class="string">&#x27;/default/ &#123; print $3 &#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>docker network rm xxx<br>报错&gt;daemon: network docker_gwbridge id b5ec2be36c4cd7f3dc0b04e3a20ed3e5a193985ed543a29a751b9740fef896ae has active endpoints<br>此时需要看看谁在用这个网络<br>docker inspect </p>
<h2 id="swarm集群命令"><a href="#swarm集群命令" class="headerlink" title="swarm集群命令"></a>swarm集群命令</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker swarm init  <span class="comment">#(在manager节点输入，此时会建两个网络)</span></span><br><span class="line">docker swarm leave -f </span><br><span class="line">docker stack deploy --compose-file=docker-compose.yml cluster-name</span><br><span class="line">docker stack <span class="built_in">rm</span> cluster-name</span><br><span class="line">docker stack ps cluster-name</span><br></pre></td></tr></table></figure>

<p>如果需要指定swarm使用的网络, 需要在所有节点先创建docker_gwbridge, 再使用.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker network create \</span><br><span class="line">--subnet=192.168.2.0/24 \</span><br><span class="line">--gateway 192.168.2.1 \</span><br><span class="line">-o com.docker.network.bridge.enable_icc=<span class="literal">false</span> \</span><br><span class="line">-o com.docker.network.bridge.name=docker_gwbridge \</span><br><span class="line">-o com.docker.network.bridge.enable_ip_masquerade=<span class="literal">true</span> \</span><br><span class="line">docker_gwbridge</span><br></pre></td></tr></table></figure>

<h2 id="docker-compose-1"><a href="#docker-compose-1" class="headerlink" title="docker-compose"></a>docker-compose</h2><p>###查看 </p>
<blockquote>
<p>docker-compose ls</p>
</blockquote>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><blockquote>
<p>docker-compose up</p>
</blockquote>
<h3 id="停止"><a href="#停止" class="headerlink" title="停止"></a>停止</h3><blockquote>
<p>docker-compose down</p>
</blockquote>
<h2 id="docker-machine-1"><a href="#docker-machine-1" class="headerlink" title="docker-machine"></a>docker-machine</h2><h3 id="管理远程主机"><a href="#管理远程主机" class="headerlink" title="管理远程主机"></a>管理远程主机</h3><p>堡垒机(docker-machine所在机器)能免密登录远程主机, 登陆后要有免密sudo权限. 可用ssh-keygen和ssh-copy-id达成.<br>generic的driver适合现成的主机, 以上命令执行后则可将远程主机纳入docker-machine管理.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker-machine create --driver generic --generic-ip-address=100.100.154.250 se-hub</span><br><span class="line">docker-machine create --driver generic --generic-ip-address=100.100.154.150 se-node</span><br></pre></td></tr></table></figure>

<h3 id="切换机器"><a href="#切换机器" class="headerlink" title="切换机器"></a>切换机器</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker-machine <span class="built_in">env</span> se-hub</span><br><span class="line">  <span class="built_in">eval</span> $(docker-machine <span class="built_in">env</span> se-hub)</span><br></pre></td></tr></table></figure>

<h1 id="私人容器"><a href="#私人容器" class="headerlink" title="私人容器"></a>私人容器</h1><h2 id="cntlm"><a href="#cntlm" class="headerlink" title="cntlm"></a>cntlm</h2><p>公司代理使用ntlm认证，cntlm是跨系统的一个代理，容器需要自己build一下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM jaschac/cntlm:latest</span><br><span class="line">ADD cntlm.conf /etc/cntlm.conf</span><br><span class="line"><span class="comment"># docker build -t &quot;hwcntlm&quot; .</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name hwcntlm --restart always -d \</span><br><span class="line">-p 3128:3128 \</span><br><span class="line">-e CNTLM_PROXY_URL=<span class="string">&quot;proxyhk.example.com:8080&quot;</span> \</span><br><span class="line">-e CNTLM_USERNAME=<span class="string">&quot;a00123456&quot;</span> \</span><br><span class="line">-e CNTLM_DOMAIN=<span class="string">&quot;china&quot;</span> \</span><br><span class="line">-e <span class="string">&quot;CNTLM_PASSNT=D7666F8E655613E42DBD9C186A5203B5&quot;</span> \</span><br><span class="line">-e <span class="string">&quot;CNTLM_PASSLM=49DCEDB48EC97AF583CEEC4B5E5A1C5F&quot;</span> \</span><br><span class="line">hwcntlm</span><br></pre></td></tr></table></figure>

<h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><p>max-allowed-packet=1024M这个配置给azkaban3.x使用</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name mysql --restart always -d \</span><br><span class="line">-v /home/tony/mysql_data:/var/lib/mysql \</span><br><span class="line">-p 3306:3306 \</span><br><span class="line">-e MYSQL_ROOT_PASSWORD=huawei123 \</span><br><span class="line">mysql:5.6 --max-allowed-packet=1024M</span><br></pre></td></tr></table></figure>

<h2 id="Nginx-Autoindex"><a href="#Nginx-Autoindex" class="headerlink" title="Nginx(Autoindex)"></a>Nginx(Autoindex)</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name apps-nginx --restart always -d \</span><br><span class="line">-p 80:80 \</span><br><span class="line">-v /home/tony/nginx_data:/usr/share/nginx/html:ro \</span><br><span class="line">jrelva/nginx-autoindex</span><br></pre></td></tr></table></figure>

<h2 id="Java8-apps-portal"><a href="#Java8-apps-portal" class="headerlink" title="Java8( apps-portal)"></a>Java8( apps-portal)</h2><p>用OpenJDK8跑springboot的jar包，依赖mysql容器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name apps-portal -d \</span><br><span class="line">-p 8079:8080 \</span><br><span class="line">--<span class="built_in">link</span> mysql:mysql \</span><br><span class="line">-v /home/tony/apps-portal:/usr/src/myapp \</span><br><span class="line">openjdk:8-alpine \</span><br><span class="line">java -jar /usr/src/myapp/apps-portal.jar</span><br></pre></td></tr></table></figure>
<h2 id="Tomcat"><a href="#Tomcat" class="headerlink" title="Tomcat"></a>Tomcat</h2><ol>
<li>CCM联调自动诊断</li>
<li>iSales快速下PO</li>
<li>API监控<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CCM联调自动诊断</span></span><br><span class="line">docker run -d --name autocheck --restart always \</span><br><span class="line">-p 8080:8080 \</span><br><span class="line">-v /home/tony/autocheck:/usr/local/tomcat/webapps/autocheck \</span><br><span class="line">tomcat:9-jre8-alpine</span><br><span class="line"></span><br><span class="line"><span class="comment"># 快速下PO，功能已坏，未更新</span></span><br><span class="line">docker run -d --name fastpo --restart always \</span><br><span class="line">-p 8081:8080 \</span><br><span class="line">-v /home/tony/fastpo:/usr/local/tomcat/webapps/fastpo \</span><br><span class="line">tomcat:9-jre8-alpine</span><br><span class="line"></span><br><span class="line"><span class="comment"># API监控， 依赖mysql</span></span><br><span class="line">docker run -d --name apimonitor \</span><br><span class="line">-p 8082:8080 \</span><br><span class="line">--<span class="built_in">link</span> mysql:mysql \</span><br><span class="line">-v /home/tony/apimonitor:/usr/local/tomcat/webapps \</span><br><span class="line">tomcat:9-jre8-alpine</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="Jenkins容器"><a href="#Jenkins容器" class="headerlink" title="Jenkins容器"></a>Jenkins容器</h2><ol>
<li>映射的目录赋予一样的用户属主</li>
<li>因为公司环境有代理，link了代理跳板</li>
<li>时区用了两种<code>映射了时区文件</code>和<code>JAVA_OPTS</code>方法</li>
<li>对接RobotFramework的插件需要允许js执行，通过<code>JAVA_OPTS</code>方法放松安全限制<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">chown</span> -R 1000:1000 /home/tony/jenkins   <span class="comment">#赋权，容器内是1000的root</span></span><br><span class="line"></span><br><span class="line">docker run -u root --name jenkins --restart always -d \</span><br><span class="line">-p 8083:8080 -p 50000:50000 \</span><br><span class="line">--add-host szxsvn02-ex:172.30.45.47 \</span><br><span class="line">-v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime \</span><br><span class="line">-v /home/tony/jenkins-blueocean-data:/var/jenkins_home \</span><br><span class="line">-v /home/tony/jenkins-blueocean-data/.ssh:/root/.ssh \</span><br><span class="line">-v /var/run/docker.sock:/var/run/docker.sock \</span><br><span class="line">-e http_proxy=10.75.76.163hwcntlm:3128 \</span><br><span class="line">-e https_proxy=10.75.76.163hwcntlm:3128 \</span><br><span class="line">-e JAVA_OPTS=<span class="string">&quot;-DproxyHost=10.75.76.163hwcntlm -DproxyPort=3128 -Dhudson.model.DirectoryBrowserSupport.CSP= -Duser.timezone=Asia/Shanghai&quot;</span> \</span><br><span class="line">jenkinsci/blueocean</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="GIT-gogs"><a href="#GIT-gogs" class="headerlink" title="GIT(gogs)"></a>GIT(gogs)</h2><ol>
<li>页面访问使用localhost:3000</li>
<li>ssh登录使用localhost:1022<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name gogs --restart always \</span><br><span class="line">-p 10022:22 \</span><br><span class="line">-p 3000:3000 \</span><br><span class="line">-v /home/tony/gogs:/data \</span><br><span class="line">-v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime \</span><br><span class="line">gogs/gogs</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="semaphore-ansible-tower替代者"><a href="#semaphore-ansible-tower替代者" class="headerlink" title="semaphore(ansible-tower替代者)"></a>semaphore(ansible-tower替代者)</h2><ol>
<li>Ansible官网推荐的最佳实践在semaphore上不能很好实践</li>
<li>必须从git上取ansible的代码</li>
<li>不能指定inventory文件，需要复制粘贴到界面<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name semaphore --restart always \</span><br><span class="line">--<span class="built_in">link</span> mysql:mysql_host \</span><br><span class="line">-p 13000:3000 \</span><br><span class="line">-e SEMAPHORE_DB=semaphore \</span><br><span class="line">-e SEMAPHORE_DB_HOST=mysql_host \</span><br><span class="line">-e SEMAPHORE_DB_PORT=3306 \</span><br><span class="line">-e SEMAPHORE_DB_USER=semaphore \</span><br><span class="line">-e SEMAPHORE_DB_PASS=huawei123 \</span><br><span class="line">-e SEMAPHORE_PLAYBOOK_PATH=/etc/semaphore \</span><br><span class="line">-e SEMAPHORE_ADMIN=admin \</span><br><span class="line">-e SEMAPHORE_ADMIN_NAME=admin \</span><br><span class="line">-e SEMAPHORE_ADMIN_EMAIL=admin@admin.local \</span><br><span class="line">-e SEMAPHORE_ADMIN_PASSWORD=admin \</span><br><span class="line">-e ANSIBLE_HOST_KEY_CHECKING=False \</span><br><span class="line">--volume=/home/tony/semaphore/playbook_repo:/etc/playbook_repo \</span><br><span class="line">semaphore</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="Zabbix"><a href="#Zabbix" class="headerlink" title="Zabbix"></a>Zabbix</h2><ol>
<li>zabbix服务器端应该启动三个模块，数据库、server、web</li>
<li>服务器依赖数据库</li>
<li>Web依赖数据库和server</li>
<li>Agent几乎无依赖，不用docker部署，而且部署后默认采集是容器内指标，意义不大</li>
<li>Web端图表如果是中文标题，会因为缺少字体而显示为小的长方形，故映射一个字体文件</li>
</ol>
<h3 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name zabbix-server-mysql --restart always \</span><br><span class="line">--<span class="built_in">link</span> mysql:mysql_host \</span><br><span class="line">-p 10051:10051 \</span><br><span class="line">-e DB_SERVER_HOST=<span class="string">&quot;mysql_host&quot;</span> \</span><br><span class="line">-e MYSQL_USER=<span class="string">&quot;root&quot;</span> \</span><br><span class="line">-e MYSQL_PASSWORD=<span class="string">&quot;huawei123&quot;</span> \</span><br><span class="line">-v /home/tony/zabbix/externalscripts:/usr/lib/zabbix/externalscripts \</span><br><span class="line">zabbix/zabbix-server-mysql</span><br></pre></td></tr></table></figure>

<h3 id="Web"><a href="#Web" class="headerlink" title="Web"></a>Web</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name zabbix-web-nginx-mysql --restart always \</span><br><span class="line">--<span class="built_in">link</span> mysql:mysql_host \</span><br><span class="line">--<span class="built_in">link</span> zabbix-server-mysql:zabbix-server-mysql \</span><br><span class="line">-p 81:80 \</span><br><span class="line">-e DB_SERVER_HOST=<span class="string">&quot;mysql_host&quot;</span> \</span><br><span class="line">-e MYSQL_USER=<span class="string">&quot;root&quot;</span> \</span><br><span class="line">-e MYSQL_PASSWORD=<span class="string">&quot;huawei123&quot;</span> \</span><br><span class="line">-e ZBX_SERVER_HOST=<span class="string">&quot;zabbix-server-mysql&quot;</span> \</span><br><span class="line">-e PHP_TZ=<span class="string">&quot;Asia/Shanghai&quot;</span> \</span><br><span class="line">-v /home/tony/zabbix/msyh.ttf:/usr/share/zabbix/fonts/graphfont.ttf \</span><br><span class="line">-d zabbix/zabbix-web-nginx-mysql:latest</span><br></pre></td></tr></table></figure>

<h2 id="7z压缩镜像"><a href="#7z压缩镜像" class="headerlink" title="7z压缩镜像"></a>7z压缩镜像</h2><p>-w是工作目录，这里是/t。 a是add，压缩的意思，e是extract，解压的意思。最后两个参数是输出文件和压缩目录</p>
<blockquote>
<p>docker run -it –rm -v $(pwd):/t -w /t izotoff/7zip a test1.7z .</p>
</blockquote>
<h2 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h2><blockquote>
<p>mkdir -p /home/tony/zookeeper/data /home/tony/zookeeper/datalog</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --restart always --name zookeeper \</span><br><span class="line">-p 2181:2181 \</span><br><span class="line">-v /home/tony/zookeeper/data:/data \</span><br><span class="line">-v /home/tony/zookeeper/datalog:/datalog \</span><br><span class="line">zookeeper:3.4</span><br></pre></td></tr></table></figure>

<h2 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h2><h3 id="confluent公司的开源版"><a href="#confluent公司的开源版" class="headerlink" title="confluent公司的开源版"></a>confluent公司的开源版</h3><p>confluent是kafka原创团队自己出来的干的公司，围绕kafka构建相关组件，其中监控模块是收费的企业版，其他好像都有开源部分，我也仅适用开源部分。最主要看中了schema-registry维护avro的元数据，还有proxy估计也能简化一定调试、展示的工作量。相比hub.docker.com上个人维护的版本，在版本更新速度、兼容性也有更好的保障。<br><a href="https://docs.confluent.io/current/installation/docker/docs/index.html">官方docker操作指南
</a>默认的getting started部分未添加持久化-v和端口映射，生产使用应该还需要修改配置。</p>
<h3 id="为zookeeper和kafka准备持久化目录"><a href="#为zookeeper和kafka准备持久化目录" class="headerlink" title="为zookeeper和kafka准备持久化目录"></a>为zookeeper和kafka准备持久化目录</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/tony/kafka/zk-data</span><br><span class="line"><span class="built_in">mkdir</span> -p /home/tony/kafka/zk-txn-logs</span><br><span class="line"><span class="built_in">mkdir</span> -p /home/tony/kafka/kafka-data</span><br><span class="line"><span class="comment"># 不用赋权改用户，容器内是root权限，启动用户有读写权限就好了</span></span><br></pre></td></tr></table></figure>
<h3 id="准备docker-compose-yaml文件和环境变量"><a href="#准备docker-compose-yaml文件和环境变量" class="headerlink" title="准备docker-compose.yaml文件和环境变量"></a>准备docker-compose.yaml文件和环境变量</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/confluentinc/cp-docker-images</span><br><span class="line">vim /home/tony/kafka/cp-docker-images/examples/kafka-single-node.</span><br><span class="line"><span class="built_in">export</span> localhost_ip=10.75.76.163</span><br></pre></td></tr></table></figure>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">zookeeper:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">confluentinc/cp-zookeeper:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/tony/kafka/zk-data:/var/lib/zookeeper/data</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/tony/kafka/zk-txn-logs:/var/lib/zookeeper/log</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">ZOOKEEPER_CLIENT_PORT:</span> <span class="number">32181</span></span><br><span class="line">      <span class="attr">ZOOKEEPER_TICK_TIME:</span> <span class="number">2000</span></span><br><span class="line">    <span class="attr">extra_hosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;moby:127.0.0.1&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">kafka:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">confluentinc/cp-kafka:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/tony/kafka/kafka-data:/var/lib/kafka/data</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;29092:29092&quot;</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zookeeper</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">KAFKA_BROKER_ID:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">KAFKA_ZOOKEEPER_CONNECT:</span> <span class="string">localhost:32181</span></span><br><span class="line">      <span class="attr">KAFKA_ADVERTISED_LISTENERS:</span> <span class="string">PLAINTEXT://$&#123;localhost_ip&#125;:29092</span></span><br><span class="line">      <span class="attr">KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zookeeper</span></span><br><span class="line">    <span class="attr">extra_hosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;moby:127.0.0.1&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">schema-reristry:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">confluentinc/cp-schema-registry:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8081:8081&quot;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL:</span> <span class="string">localhost:32181</span></span><br><span class="line">      <span class="attr">SCHEMA_REGISTRY_HOST_NAME:</span> <span class="string">localhost</span></span><br><span class="line">      <span class="attr">SCHEMA_REGISTRY_LISTENERS:</span> <span class="string">http://$&#123;localhost_ip&#125;:8081</span></span><br><span class="line">      <span class="attr">SCHEMA_REGISTRY_DEBUG:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zookeeper</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">kafka-rest:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">confluentinc/cp-kafka-rest:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8082:8082&quot;</span></span><br><span class="line">    <span class="attr">network_mode:</span> <span class="string">host</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">KAFKA_REST_ZOOKEEPER_CONNECT:</span> <span class="string">localhost:32181</span></span><br><span class="line">      <span class="attr">KAFKA_REST_LISTENERS:</span> <span class="string">http://$&#123;localhost_ip&#125;:8082</span></span><br><span class="line">      <span class="attr">KAFKA_REST_SCHEMA_REGISTRY_URL:</span> <span class="string">http://localhost:8081</span></span><br><span class="line">      <span class="attr">KAFKA_REST_HOST_NAME:</span> <span class="string">kafka-rest</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zookeeper</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">schema-reristry</span></span><br></pre></td></tr></table></figure>

<h2 id="selenium-hub"><a href="#selenium-hub" class="headerlink" title="selenium-hub"></a>selenium-hub</h2><h3 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h3><p>这个文件是v3版本, 适用于docker stack部署.</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">hub:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">selenium/hub</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;4444:4444&quot;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">GRID_BROWSER_TIMEOUT=60</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">GRID_TIMEOUT=90</span></span><br><span class="line">    <span class="attr">deploy:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">global</span></span><br><span class="line">      <span class="attr">placement:</span></span><br><span class="line">        <span class="attr">constraints:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">node.role</span> <span class="string">==</span> <span class="string">manager</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">chrome:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">gzwjs/node-chrome-cn</span> <span class="comment"># 仅在selenium/node-chrome上加入中文</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">hub</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">HUB_PORT_4444_TCP_ADDR=hub</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">HUB_PORT_4444_TCP_PORT=4444</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SCREEN_WIDTH=1920</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SCREEN_HEIGHT=1080</span></span><br><span class="line">     <span class="comment"># - SE_OPTS=-host $$HOSTNAME</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/dev/shm:/dev/shm</span></span><br><span class="line">    <span class="attr">deploy:</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">24</span></span><br><span class="line">    <span class="attr">entrypoint:</span> <span class="string">bash</span> <span class="string">-c</span> <span class="string">&#x27;SE_OPTS=&quot;-host $$HOSTNAME -port 5556&quot; /opt/bin/entry_point.sh&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="cheat-sheet"><a href="#cheat-sheet" class="headerlink" title="cheat sheet"></a>cheat sheet</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker stack deploy se -c docker-compose.yml</span><br><span class="line">docker stack ps se</span><br><span class="line">docker service scale --detach=<span class="literal">false</span> se_chrome=12</span><br><span class="line">docker stack <span class="built_in">rm</span> se</span><br></pre></td></tr></table></figure>

<h1 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h1><h2 id="RobotFramework执行器"><a href="#RobotFramework执行器" class="headerlink" title="RobotFramework执行器"></a>RobotFramework执行器</h2><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</span></span><br><span class="line"><span class="comment"># This container is made to execute RobotFramework test.</span></span><br><span class="line"><span class="comment"># !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> python:<span class="number">2.7</span>-slim</span><br><span class="line"></span><br><span class="line"><span class="keyword">MAINTAINER</span> Wu Jiansong &lt;<span class="number">360517703</span>@<span class="number">163</span>.com&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> http_proxy=http://<span class="number">100.100</span>.<span class="number">154.250</span>:<span class="number">3128</span></span><br><span class="line"><span class="keyword">ENV</span> http_proxy=http://<span class="number">100.100</span>.<span class="number">154.250</span>:<span class="number">3128</span></span><br><span class="line"><span class="keyword">ENV</span> REMOTE_URL=http://<span class="number">100.100</span>.<span class="number">154.250</span>localhost:<span class="number">4444</span>/wd/hub</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install Ubuntu packages</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; apt-get install -y --no-install-recommends \</span></span><br><span class="line"><span class="language-bash">                alien \</span></span><br><span class="line"><span class="language-bash">                dpkg-dev \</span></span><br><span class="line"><span class="language-bash">                debhelper \</span></span><br><span class="line"><span class="language-bash">                build-essential \</span></span><br><span class="line"><span class="language-bash">                libaio1 \</span></span><br><span class="line"><span class="language-bash">                wget \</span></span><br><span class="line"><span class="language-bash">            &amp;&amp; <span class="built_in">rm</span> -rf /var/lib/apt/lists/* </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install oracle</span></span><br><span class="line"><span class="comment"># Reference: https://help.ubuntu.com/community/Oracle%20Instant%20Client</span></span><br><span class="line"><span class="comment"># Download RPM files from http://www.oracle.com/technetwork/topics/linuxx86-64soft-092277.html</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> wget --no-check-certificate https://raw.githubusercontent.com/bumpx/oracle-instantclient/master/oracle-instantclient12.2-basiclite-12.2.0.1.0-1.x86_64.rpm \</span></span><br><span class="line"><span class="language-bash"></span></span><br><span class="line"><span class="comment"># Alien RPM package installer</span></span><br><span class="line"> &amp;&amp; alien -i *.rpm \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Cleaning up the packages downloaded</span></span><br><span class="line"> &amp;&amp; rm *.rpm \</span><br><span class="line"> &amp;&amp; apt-get purge -y --auto-remove wget alien</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">echo</span> <span class="string">&quot;/usr/lib/oracle/12.2/client64/lib/&quot;</span> &gt;&gt; /etc/ld.so.conf.d/oracle.conf \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; <span class="built_in">echo</span> <span class="string">&#x27;#!/bin/bash\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">export ORACLE_HOME=/usr/lib/oracle/12.2/client64\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">export PATH=$PATH:$ORACLE_HOME/bin&#x27;</span> &gt;&gt; /etc/profile.d/oracle.sh \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; <span class="built_in">chmod</span> +x /etc/profile.d/oracle.sh \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; /etc/profile.d/oracle.sh \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; ldconfig</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install -U pip \</span></span><br><span class="line"><span class="language-bash">    requests \</span></span><br><span class="line"><span class="language-bash">    selenium \</span></span><br><span class="line"><span class="language-bash">    xlrd \</span></span><br><span class="line"><span class="language-bash">    cx-Oracle \</span></span><br><span class="line"><span class="language-bash">    pyhive \</span></span><br><span class="line"><span class="language-bash">    pymysql==0.8.0 \</span></span><br><span class="line"><span class="language-bash">    robotframework \</span></span><br><span class="line"><span class="language-bash">    dbbot \</span></span><br><span class="line"><span class="language-bash">    robotframework-selenium2library==3.0.0 \</span></span><br><span class="line"><span class="language-bash">    robotframework-pageobjectlibrary \</span></span><br><span class="line"><span class="language-bash">    robotframework-databaselibrary \</span></span><br><span class="line"><span class="language-bash">    robotframework-requests \</span></span><br><span class="line"><span class="language-bash">    robotframework-sshlibrary \</span></span><br><span class="line"><span class="language-bash">    robotframework-excelLibrary &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    sed -i <span class="string">&quot;s#formatting_info=True,##g&quot;</span> /usr/local/lib/python2.7/site-packages/ExcelLibrary/ExcelLibrary.py &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    sed -i <span class="string">&quot;s#remote_url=False#remote_url=&#x27;<span class="variable">$REMOTE_URL</span>&#x27;#g&quot;</span> /usr/local/lib/python2.7/site-packages/SeleniumLibrary/keywords/browsermanagement.py &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="built_in">echo</span> <span class="string">&quot;\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">    def switch_base_url(self, alias, url):\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">        &#x27;&#x27;&#x27;\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">        change base_url of current session. add by w00406273\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">        &#x27;&#x27;&#x27;\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">        session = self._cache.switch(alias)\n\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">        session.url = url\n&quot;</span>\</span></span><br><span class="line"><span class="language-bash">    &gt;&gt; /usr/local/lib/python2.7/site-packages/RequestsLibrary/RequestsKeywords.py &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="built_in">echo</span> Asia/Shanghai &gt; /etc/timezone &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="built_in">mv</span> /etc/localtime /etc/localtime.bak &amp;&amp; <span class="built_in">cp</span> /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span></span><br><span class="line"><span class="keyword">ENV</span> http_proxy= \</span><br><span class="line">    https_proxy=</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
</search>
